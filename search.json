[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "WIO-fish",
    "section": "",
    "text": "This is a tutorial for beginning to learn the R programming language. It is a tree of pages — move through the pages in whatever way best suits your style of learning. You are probably impatient to learn R — most people are. That’s fine. But note that trying to skim past the basics that are presented here will almost surely take longer in the end. This page has several sections, they can be put into the four categories: General, Objects, Actions, Help.\n\nThe wio-fishStats guide and course provide an introduction to data science that is tailored to the needs of fisheries, but is also suitable for freshwater and marine scientists and other biological or social sciences. This audience typically has some knowledge of statistics, but rarely an idea how data is prepared and shaped to allow for statistical testing.\nBy using various data types and working with many examples, the book will guide on transforming, summarizing, and visualizing data. By keeping our eyes open for the perils of misleading representations, the book fosters fundamental skills of data literacy and cultivates reproducible research practices that enable and precede any practical use of statistics.\nThis guide provides datasets and functions that help people want to code fisheries data in R language. Its source code is hosted at https://github.com/lugoga/fishstats. The book and course introduce the principles and methods of data science for fisheries scientists and other biological or social sciences. The guide is available at https://github.com/lugoga/fishstats/manual.\n\n\n\nScan the qrcode to access the interactive web app"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "To raise awareness of countries in the Western Indian Ocean (WIO) in monitoring their progress toward the achievement of the Sustainable Development Goals (SDGs), the FAO has partnered with WIOMSA to support capacity-building activities in collection, monitoring, and assessment of fisheries data for the WIO region. In general, these activities aim to strengthen the workflow from fisheries data collection to support the monitoring and reporting of SDG 14.4.1.\nThe prime goal of this initiative align with the the United Nations Decade of Ocean Science for Sustainable Development (2021-2030, Ocean Decade for short), which focus to support a new cooperative framework to ensure that global ocean science provides greater benefits for ocean ecosystems and wider society.\nDecade provides a common framework to ensure that ocean science can fully support countries’ actions to sustainably manage the ocean and more particularly to achieve the 2030 Agenda for Sustainable Development – through the creation of a new foundation, across the science-policy interface, to strengthen the management of the ocean and coasts for the benefit of humanity.\nA vast majority of the ocean remains unmapped, unobserved and unexplored. Our understanding of the ocean and its contribution to sustainability largely depends on our capacity to conduct effective ocean science - through research and sustained observations, supported by adequate infrastructures and investments.\nThis decade of the ocean comes down with a slogan the science we want for the ocean we need! But we flip it a little bit and should read the information we want for the ocean we need, why. Because we are at the time of precedented generation of data than ever before. Data generated from sensors to satellite is enormous.\nIn the WIO, small-scale fisheries dominate and are crucial for the livelihoods of coastal communities in the region, contributing to the twin imperatives of poverty reduction and economic development. However, these fisheries are dispersed, open-access in nature, multispecies and multi-gear, making their monitoring and determination of stock status for individual species incredibly challenging as data are insufficient for conventional stock assessment routines.\nEfforts to determine stock status and provide evidence-based fisheries management advice are beset with problems, including insufficient or inadequate scientific data and expertise, which are compromised by economic and socio-political realities. For example, the regional state of the coast report for the western Indian Ocean (WIO) states that almost all countries in the region cannot adequately assess their marine resources and lack the financial capacity and technical expertise for effective management. Important impediments to fisheries management in the region relate to the following aspects:\nThese have been highlighted as some of the impediments to meeting the targets of SDG 14.\nAlthough the national fisheries institutes in the region do collect data on their fisheries, these data are often not detailed to an adequate granularity (e.g. regarding time, space, fleet or species levels), are not properly organized or linked, lack sufficient quality assurance and control, or are very difficult to retrieve for analysis. Additionally, there is often very limited technical capacity for managing, accessing and extracting data in a way that can be used for analysis.\nThus, even though data may exist, they often remain underutilized, strongly limiting the possibility of applying even data-limited approaches to stock monitoring. As such, analyses of stock status may be missing or be based on inappropriate metrics and methods, thereby hindering the formulation of relevant policies for the sector.\nIn its role as custodian agency of the SDG 14 indicators, FAO has a mandate to support countries to strengthen their capacities to collect, process, analyse and report data while ensuring that different national data sets are comparable and can be aggregated at sub-regional, regional and global levels to monitor the SDGs."
  },
  {
    "objectID": "intro.html#initiatives-conducted-in-the-wio",
    "href": "intro.html#initiatives-conducted-in-the-wio",
    "title": "1  Introduction",
    "section": "Initiatives conducted in the WIO",
    "text": "Initiatives conducted in the WIO\nTwo workshops have been undertaken in the WIO/East African region, first a project kick-off meeting of the Fishing Data East Africa (FIDEA) project (Dar es Salaam, Tanzania, 16-17 September 2019), focused on Tanzania-Mainland, Tanzania-Zanzibar and Mozambique, at which FAO agreed to partner with FIDEA to support a capacity development workshop in the East Africa region. This led to a mission by FAO staff to investigate the data infrastructure in Tanzania-Mainland, Tanzania-Zanzibar and Mozambique, as well as the SDG 14.4.1 reporting capacity development workshop in Zanzibar from 2-14 March 2020, which included 10 East African countries and WIO island nations.\nThe report of this second workshop recommended some key actions to support countries in improving the collection and use of data for monitoring the SDG 14.4 target. A common point in these recommendations is a greater need to provide long-term support for developing appropriate data management systems. This goes beyond collection to focus particularly on validation, organization, protection, retrieval and summary of the data, essential steps for allowing reliable estimation and reporting of the SDG14.4.1 indicator.\nIt has been stated many times that The collection of data is not an end in itself, but is essential for informed decision-making, and data can only be useful for supporting decision-making if they are properly stored, managed, and curated so that they have the quality necessary for providing meaningful and reliable advice. The report also recommended stronger collaboration between the SWIOFC regional process in monitoring the status of stocks and national processes in developing capacities for the monitoring of SDG14.4.1."
  },
  {
    "objectID": "intro.html#objectives",
    "href": "intro.html#objectives",
    "title": "1  Introduction",
    "section": "Objectives",
    "text": "Objectives\nThe objective of this consultancy is to support development and refining of training tools related to fisheries data management workflow. This will involve working closely with the fisheries expert towards the development of training tools for enhancing stock monitoring status and national processes for SDG14.4.1 monitoring."
  },
  {
    "objectID": "intro.html#scope-of-the-work",
    "href": "intro.html#scope-of-the-work",
    "title": "1  Introduction",
    "section": "Scope of the work",
    "text": "Scope of the work\nIn executing this consultancy, the Consultant will work closely with WIOMSA and FAO and the following tasks will be undertaken for guided data management, analysis and reporting for decision making and management of the fisheries resources in the region using Excel spreadsheet and R language tools. This will include development of the Excel and R tools that help to reproduce lecture material and tutorials."
  },
  {
    "objectID": "Rlanguage.html",
    "href": "Rlanguage.html",
    "title": "2  R as a Programming Language",
    "section": "",
    "text": "You may or may not have used other programming languages before coming to R. Either way, R has several distinctive features which are worth noting. The primary purpose of this tutorial is — in the first few days of your contact with R — to help you become as comfortable with R as possible. I asked R users what their biggest stumbling blocks were in learning R. A common answer that surprised me was:\nOn reflection perhaps I shouldn’t have been so surprised by that answer. The vastness of the functionality of R can be quite intimidating (even to those of us who have been around it for years), but doing a single task in R is a logical and often simple process."
  },
  {
    "objectID": "Rlanguage.html#what-happens-at-r-startup",
    "href": "Rlanguage.html#what-happens-at-r-startup",
    "title": "2  R as a Programming Language",
    "section": "2.1 What happens at R startup",
    "text": "2.1 What happens at R startup\nR is mainly used as an interactive program — you give R a command and it responds to that command. The result may influence the next command that you give R.\nBetween the time you start R and it gives you the first prompt, any number of things might happen (depending on your installation). But the thing that always happens is that some number of packages are attached to the search list.\nYou can see what those packages are in your case with the command:\n\nsearch()\n\n\n\n\n\n\n\nTip\n\n\n\nYou don’t type the “>” — that is the R prompt, but you do hit the return key at the end of the line\n\n\nThe first item on the search list is the “global environment”. This is your work space where the objects that you create during the R session will be.\nYou quit R with the command:\n\nq()\n\nR will ask you if you want to save or delete the global environment when you quit. If you do save the global environment, then you can start another R session with those objects in the global environment at the start of the new session. You are saving the objects in the global environment, you are not saving the session. In particular, you are not saving the search list."
  },
  {
    "objectID": "Rlanguage.html#key-objects",
    "href": "Rlanguage.html#key-objects",
    "title": "2  R as a Programming Language",
    "section": "2.2 Key objects",
    "text": "2.2 Key objects\nAn important strength of R is that it is very rich in the types of objects that it supports. That strength is rather a disadvantage when you are first learning R.\nBut to start, you only need to get your head around a few types of objects.\n\n2.2.1 basic objects\nHere are three important basic objects:\n\natomic vector\nlist\nNULL\n\n\n\n2.2.2 atomic vector\nThere are three varieties of atomic vector that you are likely to encounter:\n\nnumeric\nlogical\ncharacter\n\nThe thing to remember about atomic vectors is that all of the elements in them are only of one type. There can not be an atomic vector that has both numbers and character strings, for instance.\n\n\n2.2.3 list\nLists can have different types of items in different components. A component of a list is allowed to be another list as well as an atomic vector (and other things).\n\n\n2.2.4 NULL\nThe final object in the list above is NULL. This is an object that has zero length. Virtually all of the other objects that you deal with will have length greater than zero.\n\n\n2.2.5 derived objects\nThere are three important types of what might be called derived — or non-basic — objects.\n\nmatrix\ndata frame\nfactor\n\n\n2.2.5.1 matrix and data frame\nMatrices and data frames are both rectangular data objects. The difference between them is that everything in a matrix has to be of the same atomic type, but data frames can have different types in different columns. Each column of a data frame has to be of a single type.\nA matrix can look exactly like a data frame, but they are implemented entirely differently.\nSometimes it doesn’t matter whether you have a matrix or a data frame. Other times it is very important to know which you have.\n\n\n2.2.5.2 factor\nFactors represent categorical data. (You might ask why they aren’t called something like category — yeah, well, long story …)\nFactors are often easily confused with character vectors. In particular, columns of data frames that you might think of as character are many times actually factors.\n\n\n\n\n\n\nTip\n\n\n\nSometimes it doesn’t matter whether you have a factor or a character vector. Other times it is very important to know which you have."
  },
  {
    "objectID": "Rlanguage.html#key-actions",
    "href": "Rlanguage.html#key-actions",
    "title": "2  R as a Programming Language",
    "section": "2.3 Key actions",
    "text": "2.3 Key actions\nThree basic actions in R are assignment, subscripting and random generation.\n\n2.3.1 assignment\nThe action in R is precipitated by function calls. Most functions return a value (that is, some data object). You will often want to assign that result to a name. There are two ways of doing that. You can do:\n\n meanx <- mean(x)\n\nor\n\nmeanx = mean(x)\n\nOnce you have executed one of those commands, then meanx will be an object in your global environment.\nThere is a shocking amount of controversy over which form of assignment to use. The position I’ll take here is to say to use whichever one you are more comfortable with. There are ways of running into trouble with either one, but using the arrow surrounded by spaces is probably the safest approach by a slight margin.\nNote that R is case-sensitive. The two names meanx and Meanx are different.\n\n\n2.3.2 subscripting\nSubscripting is important. This is the act of extracting pieces from objects. Subscripting is done with square brackets:\n\nx[1]\n\nextracts the first element from x.\n\nx[1,3]\n\nextracts the element in the first row and third column of a matrix or data frame.\nSubscripting also includes replacing pieces of an object. The command:\n\nx[1] = 9\n\nwill change the first element of x to 9."
  },
  {
    "objectID": "Rlanguage.html#random-generation",
    "href": "Rlanguage.html#random-generation",
    "title": "2  R as a Programming Language",
    "section": "2.4 random generation",
    "text": "2.4 random generation\nThere is a variety of functions that produce randomness. For example, the command:\n\nrunif(n = 9)\n\ncreates a vector of 9 numbers that are uniformly distributed between 0 and 1. You will get different answers from this command if you do it again.\nrunif function is also used to randomly generate element of vector when the minimum and maximum values are provided.\n\nrunif(n = 9, min = 20, max = 100)"
  },
  {
    "objectID": "Rlanguage.html#probability-distributions",
    "href": "Rlanguage.html#probability-distributions",
    "title": "2  R as a Programming Language",
    "section": "2.5 Probability distributions",
    "text": "2.5 Probability distributions\nR has functions for a number of probability distributions. In general, there are four functions for each distribution as shown in Table 2.1.\n\n\n\n\nTable 2.1:  Prefix name of probability distributions functions in R \n \n  \n    Function name \n    Description \n  \n \n\n  \n    rxxx \n    random generation \n  \n  \n    dxxx \n    density function \n  \n  \n    pxxx \n    cumulative probability function \n  \n  \n    qxxx \n    quantile function \n  \n\n\n\n\n\n\nFor example rnorm is the random generation function for the normal distribution. dnorm is the density for the normal. pnorm is the cumulative probability function for the normal — that is, this gives the probability of being less than or equal to a given quantile. qnorm is the quantile function — the inverse of the probability function (that is, it returns a quantile given a probability).\n\n\n\n\nTable 2.2:  Probility distribution functions in R \n \n  \n    Distribution \n    Functioons \n  \n \n\n  \n    Uniform \n    runif, dunif, punif, qunif \n  \n  \n    Normal \n    rnorm, dnorm, pnorm, qnorm \n  \n  \n    Student’s t \n    rt, dt, pt, qt \n  \n  \n    F \n    rf, df, pf, qf \n  \n  \n    Exponential \n    rexp, dexp, pexp, qexp \n  \n  \n    Log normal \n    rlnorm, dlnorm, plnorm, qlnorm \n  \n  \n    Beta \n    rbeta, dbeta, pbeta, qbeta \n  \n  \n    Binomial \n    rbinom, dbinom, pbinom, qbinom \n  \n  \n    Poisson \n    rpois, dpois, ppois, qpois \n  \n\n\n\n\n\n\nYou can see a more complete list with the command:\n\n??distributions\n\nThe ecdf function takes a data vector as an argument and returns a function that is the cumulative probability function of the data.\nMany contributed packages contain functions for additional distributions."
  },
  {
    "objectID": "Rlanguage.html#pseudorandomness",
    "href": "Rlanguage.html#pseudorandomness",
    "title": "2  R as a Programming Language",
    "section": "2.6 Pseudorandomness",
    "text": "2.6 Pseudorandomness\nIn a certain sense most of what is said on this page is a lie. When you use a function like rnorm or sample, you are not generating randomness at all. These are pseudorandom functions. Technically you are generating chaos when you use them, not randomness. There are two main reasons to use pseudorandomness rather than randomness.\n\nThe first is convenience. In the early days of computing there was no way to actually get true random values, so they had to invent pseudorandom methods. Now there is the possibility of using truly random values, but it is generally harder to do and seldom offers an advantage.\nThe second reason to prefer pseudorandomness is reproducibility. Random numbers (by definition) are not reproducible. A program without reproducible results is a program that can not be debugged.\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is largely accidental that we have pseudorandom functions and not truly random functions. It\\’s a happy accident."
  },
  {
    "objectID": "Rlanguage.html#errors-and-such",
    "href": "Rlanguage.html#errors-and-such",
    "title": "2  R as a Programming Language",
    "section": "2.7 Errors and such",
    "text": "2.7 Errors and such\nSometime, probably soon, you are going to get an error in R.\nHint: the universe doesn’t collapse into a singularity just because of an error in R. Actually, it builds character — see Make mistakes on purpose.\nR produces errors and warnings. Both errors and warnings write a message — the difference is that errors halt the execution of the command but warnings do not.\nWe’ll categorize errors into three types: syntax errors, object-not-found errors, and all the rest.\n\n2.7.1 syntax errors\nIf you get a syntax error, then you’ve entered a command that R can’t understand. Generally the error message is pretty good about pointing to the approximate point in the command where the error is.\nCommon syntax mistakes are missing commas, unmatched parentheses, and the wrong type of closing brace for example, an opening square bracket but a closing parenthesis).\n\n\n2.7.2 object not found\nErrors of the object-not-found variety can have one of several causes:\n\nthe name is not spelled correctly, or the capitalization is wrong\nthe package or file containing the object is not on the search list\nsomething else (let your imagination run wild)\n\n\n\n2.7.3 other errors\nThere are endless other ways of getting an error. Hence some detective work is generally necessary — think of it as a crossword puzzle that needs solving.\nIt should become a reflex reaction to type:\nThe results might not mean much to you at the moment, but they will at some point. The traceback tells you what functions were in effect at the time of the error. This can give you a hint of what is going wrong.\n\n\n\n\n\n\nImportant\n\n\n\ntraceback()\nwhenever you get an error.\n\n\n\n\n2.7.4 warnings\nA warning is not as serious as an error in that the command runs to completion. But that can mean that ignoring a warning can be very, very serious if it is suggesting to you that the answer you got was bogus.\nIt is good policy to understand warning messages to see if they indicate a real problem or not."
  },
  {
    "objectID": "dataTypes.html",
    "href": "dataTypes.html",
    "title": "3  Understanding Data in R",
    "section": "",
    "text": "In tutorial @ref(intro), we got a glimpse of GIS and the software used in this field. In this tutorial we focus on lower level data types that R handles. This includes understanding how to manage the numeric type (integer vs. double) and strings. The series of data called vectors and tabular format of data storage called data frames. But before we move further, let’s us clean our working environment by clicking a combination of Ctrl+L. Clearing the workspace is always recommended before working on a new R project to avoid name conflicts with provious projects. We can also clear all figures using graphics.off() function. It is a good code practice that a new R project start with the code in the chunk below:"
  },
  {
    "objectID": "dataTypes.html#data-types",
    "href": "dataTypes.html#data-types",
    "title": "3  Understanding Data in R",
    "section": "3.1 Data Types",
    "text": "3.1 Data Types\nR language is a flexible language that allows people to work with different kind of data format (R-base?). This include integer, numeric, character, complex, dates and logical. The default data type or class in R is double precision—numeric. In a nutshell, R treats all kind of data into five categories but we deal with only four in this book. Before proceeding, we need to clear the workspace by typing rm(list = ls()) after the prompt in the in a console."
  },
  {
    "objectID": "dataTypes.html#vectors",
    "href": "dataTypes.html#vectors",
    "title": "3  Understanding Data in R",
    "section": "3.2 Vectors",
    "text": "3.2 Vectors\nOfen times we want to store a set of numbers in once place. One way to do this is using the vectors in R. Vector is the most basic data structure in R. It is a sequence of elements of the same data type. if the elements are of different data types, they be coerced to a commontype that can accommodate all the elelements. Vector are generally created using the c() function widely called concatenate, though depending on the type vector being created, other method. Vectors store several numbers– a set of numbers in one container. let us look on the example below\n\nid = c(1,2,3,4,5)\npeople = c(158,659,782,659,759)\nstreet = c(\"Dege\", \"Mchikichini\", \"Mwembe Mdogo\", \"Mwongozo\",  \"Cheka\")\n\nNotice that the c() function, which is short for concatenate wraps the list of numbers. The c() function combines all numbers together into one container. Notice also that all the individual numbers are separated with a comma. The comma is referred to an an item-delimiter. It allows R to hold each of the numbers separately. This is vital as without the item-delimiter, R will treat a vector as one big, unseperated number.\n\n3.2.1 Numeric Vector\nThe numeric class holds the set of real numbers — decimal place numbers. The numeric class is more general than the integer class, and inclused the integer numbers. We create a numeric vector using a c() function but you can use any function that creates a sequence of numbers. These could be any number (whole or decimal number). You can check if the data is integer with is.integer()\n\nsst = c(25.4, 26, 28, 27.8, 29, 24.8, 22.3)\nis.numeric(sst)\n\n[1] TRUE\n\n\n\n\n3.2.2 Integer vector\nUnlike numeric, integer values do not have decimal places. They are commonly used for counting or indexing. Creating an integer vector is similar to numeric vector except that we need to instruct R to treat the data as integer and not numeric or double. To command R creating integer, we specify a suffix L to an element\n\ndepth = c(5L, 10L, 15L, 20L, 25L,30L)\nis.vector(depth);class(depth)\n\n[1] TRUE\n\n\n[1] \"integer\"\n\n\n\naa = c(20,68,78,50)\n\nYou can check if the data is integer with is.integer() and can convert numeric value to an integer with as.integer()\n\nis.integer(aa)\n\n[1] FALSE\n\n\nYou can query the class of the object with the class() to know the class of the object\n\nclass(aa)\n\n[1] \"numeric\"\n\n\nAlthough the object bb is integer as confirmed with as.integer() function, the class() ouput the answer as numeric. This is because the defaul type of number in r is numeric. However, you can use the function as.integer() to convert numeric value to integer\n\nclass(as.integer(aa))\n\n[1] \"integer\"\n\n\n\n\n3.2.3 Character vector\nIn programming terms, we usually call text as string. This often are text data like names. A character vector may contain a single character , a word or a group of words. The elements must be enclosed with a single or double quotations mark.\n\nsites = c(\"Pemba Channel\", \"Zanzibar Channnel\", \"Pemba Channel\")\nis.vector(sites); class(sites)\n\n[1] TRUE\n\n\n[1] \"character\"\n\n\nWe can be sure whether the object is a string with is.character() or check the class of the object with class().\n\ncountries = c(\"Kenya\", \"Uganda\", \"Rwanda\", \"Tanzania\")\nclass(countries)\n\n[1] \"character\"\n\n\n\n\n3.2.4 Factor vector\nThese are strings from finite set of values. For example, we might wish to store a variable that records gender of people. You can check if the data is factor with is.factor() and use as.factor() to convert string to factor\n\nsex = c(\"Male\", \"Female\", \"Male\", \"Male\", \"Female\")\nsex = as.factor(sex)\nclass(sex)\n\n[1] \"factor\"\n\n\nOften times we need to know the possible groups that are in the factor data. This can be achieved with the levels() function\n\nlevels(sex)\n\n[1] \"Female\" \"Male\"  \n\nlevels(countries)\n\nNULL\n\n\nOften we wish to take a continuous numerical vector and transform it into a factor. The function cut() takes a vector of numerical data and creates a factor based on your give cut-points. Let us make a fictional income of 508 people with rnorm() function.\n\nincome = rnorm(n = 508, mean = 500, sd = 80)\nhist(income, col = \"green\", main = \"\", las = 1, xlab = \"Individual Income\")\n\n\n\n\nIncome distribution\n\n\n\n#mosaic::plotDist(dist = \"norm\", mean = 500, sd = 80)\n\nWe can now breaks the distribution into groups and make a simple plot as shown in figure @ref(fig:fig21), where those with income less than 400 were about 50, followed with a group with income range between 400 and 500 of about 200 and 250 people receive income above 500\n\ngroup = cut(income, breaks = c(300,400,500,800),\n            labels = c(\"Below 400\", \"400-500\", \"Above 500\"))\nis.factor(group)\n\n[1] TRUE\n\nlevels(group)\n\n[1] \"Below 400\" \"400-500\"   \"Above 500\"\n\n\n\nbarplot(table(group), las = 1, horiz = FALSE, col = c(\"blue\", \"red\", \"blue\"), ylab = \"Frequency\", xlab = \"Group of Income\")\n\n\n\n\nBarplot of grouped income\n\n\n\n\n\ndata = data.frame(group, income)\n\n\n\n3.2.5 Logical Vector\nA vector of logical values will either contain TRUE or FALSE or both. This is a special case of a factor that can only take on the values TRUE and FALSE. R is case-sensitive, therefore you must always capitalize TRUE and FALSE in function in R.\n\npresence = c(TRUE,TRUE, FALSE, TRUE, FALSE)\nis.vector(presence);class(presence)\n\n[1] TRUE\n\n\n[1] \"logical\"\n\n\n\n\n3.2.6 Date and Time\nDate and time are also treated as vector in R\n\ndate.time = seq(lubridate::dmy(010121), \n                lubridate::dmy(250121), \n                length.out = 5)\ndate.time\n\n[1] \"2021-01-01\" \"2021-01-07\" \"2021-01-13\" \"2021-01-19\" \"2021-01-25\"\n\n\n\n\n3.2.7 Indexing the element\nOne advantage of vector is that you can extract individual element in the vector object by indexing, which is accomplished using the square bracket as illustrated below.\n\nid[5]\n\n[1] 5\n\npeople[5]\n\n[1] 759\n\nstreet[5]\n\n[1] \"Cheka\"\n\n\nApart from extracting single element, indexing allows to extract a range of element in a vector. This is extremely important because it allows to subset a portion of data in a vector. A colon operator is used to extract a range of data\n\nstreet[2:4]\n\n[1] \"Mchikichini\"  \"Mwembe Mdogo\" \"Mwongozo\"    \n\n\n\n\n3.2.8 Adding and Replacing an element in a vector\nIt is possible to add element of an axisting vecor. Here ia an example\n\nid[6] = 6\npeople[6] = 578\nstreet[6] = \"Mwongozo\"\n\nSometimes you may need to replace an element from a vector, this can be achieved with indexing\n\npeople[1] = 750\n\n\n\n3.2.9 Number of elements in a vector\nSometimes you may have a long vector and want to know the numbers of elements in the object. R has length() function that allows you to query the vector and print the answer\n\nlength(people)\n\n[1] 6\n\n\n\n\n3.2.10 Generating sequence of vectors Numbers\nThere are few R operators that are designed for creating vecor of non-random numbers. These functions provide multiple ways for generating sequences of numbers\nThe colon : operator, explicitly generate regular sequence of numbers between the lower and upper boundary numbers specified. For example, generating number beween 0 and 10, we simply write;\n\nvector.seq = 0:10\nvector.seq\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\n\nHowever, if you want to generate a vector of sequence number with specified interval, let say we want to generate number between 0 and 10 with interval of 2, then the seq() function is used\n\nregular.vector = seq(from = 0,to = 10, by = 2)\nregular.vector\n\n[1]  0  2  4  6  8 10\n\n\nunlike the seq() function and : operator that works with numbers, the rep() function generate sequence of repeated numbers or strings to create a vector\n\nid = rep(x = 3, each = 4)\nstation = rep(x = \"Station1\", each = 4)\nid;station\n\n[1] 3 3 3 3\n\n\n[1] \"Station1\" \"Station1\" \"Station1\" \"Station1\"\n\n\nThe rep() function allows to parse each and times arguments. The each argument allows creation of vector that that repeat each element in a vector according to specified number.\n\nsampled.months = c(\"January\", \"March\", \"May\")\nrep(x = sampled.months, each = 3)\n\n[1] \"January\" \"January\" \"January\" \"March\"   \"March\"   \"March\"   \"May\"    \n[8] \"May\"     \"May\"    \n\n\nBut the times argument repeat the whole vector to specfied times\n\nrep(x = sampled.months, times = 3)\n\n[1] \"January\" \"March\"   \"May\"     \"January\" \"March\"   \"May\"     \"January\"\n[8] \"March\"   \"May\"    \n\n\n\n\n3.2.11 Generating vector of normal distribution\nThe central limit theorem that ensure the data is normal distributed is well known to statistician. R has a rnorm() function which makes vector of normal distributed values. For example to generate a vector of 40 sea surface temperature values from a normal distribution with a mean of 25, and standard deviation of 1.58, we simply type this expression in console;\n\nsst = rnorm(n = 40, mean = 25,sd = 1.58)\nsst\n\n [1] 26.21110 25.67502 25.89921 26.71775 26.74563 24.43163 26.36921 22.85633\n [9] 25.72942 27.23735 25.41624 26.00035 25.68146 24.34351 23.65122 24.55130\n[17] 25.49577 21.43839 25.05154 24.32014 24.77623 25.27196 24.95411 22.60759\n[25] 27.33788 25.22028 26.56987 24.02304 24.01213 21.20578 22.99257 21.60608\n[33] 23.63081 22.34868 27.51112 21.69982 26.06324 24.42032 24.78187 23.59410\n\n\n\n\n3.2.12 Rounding off numbers\nThere are many ways of rounding off numerical number to the nearest integers or specify the number of decimal places. the code block below illustrate the common way to round off:\n\nrequire(magrittr)\nchl = rnorm(n = 20, mean = .55, sd = .2)\nchl %>% round(digits = 2)\n\n [1] 0.54 0.91 0.64 0.56 0.59 0.46 0.47 0.82 0.37 0.55 0.36 0.59 0.56 0.31 0.46\n[16] 0.27 0.20 0.26 0.45 0.61"
  },
  {
    "objectID": "dataTypes.html#data-frame",
    "href": "dataTypes.html#data-frame",
    "title": "3  Understanding Data in R",
    "section": "3.3 Data Frame",
    "text": "3.3 Data Frame\ndata.frame is very much like a simple Excel spreadsheet where each column represents a variable type and each row represent observations. A data frame is the most common way of storing data in R and, generally, is the data structure most often used for data analyses. A data frame is a list of equal–length vectors with rows as records and columns as variables. This makes data frames unique in data storing as it can store different classes of objects in each column (i.e. numeric, character, factor, logic, etc). In this section, we will create data frames and add attributes to data frames.\nPerhaps the easiest way to create a data frame is to parse vectors in a data.frame() function. For instance, in this case we create a simple data frame dt and assess its internal structure\n\n# create vectors\nName  = c('Bob','Jeff','Mary')\nScore = c(90, 75, 92)\nGrade = c(\"A\", \"B\", \"A\")\n\n## use the vectors to make a data frame\ndt = data.frame(Name, Score, Grade)\n\n## assess the internal structure\nstr(dt)\n\n'data.frame':   3 obs. of  3 variables:\n $ Name : chr  \"Bob\" \"Jeff\" \"Mary\"\n $ Score: num  90 75 92\n $ Grade: chr  \"A\" \"B\" \"A\"\n\n\nNote how Variable Name in dt was converted to a column of factors . This is because there is a default setting in data.frame() that converts character columns to factors . We can turn this off by setting the stringsAsFactors = FALSE argument:\n\n## use the vectors to make a data frame\ndf = data.frame(Name, Score, Grade, stringsAsFactors = FALSE)\ndf %>% str()\n\n'data.frame':   3 obs. of  3 variables:\n $ Name : chr  \"Bob\" \"Jeff\" \"Mary\"\n $ Score: num  90 75 92\n $ Grade: chr  \"A\" \"B\" \"A\"\n\n\nNow the variable Name is of character class in the data frame. The inherited problem of data frame to convert character columns into a factor is resolved by introduction f advanced data frames called tibble (Müller and Wickham 2018), which provides sticker checking and better formating than the traditional data.frame.\n\n## use the vectors to make a tibble\ntb = tibble(Name, Score, Grade) \n## check the internal structure of the tibble\ntb%>% glimpse()\n\nRows: 3\nColumns: 3\n$ Name  <chr> \"Bob\", \"Jeff\", \"Mary\"\n$ Score <dbl> 90, 75, 92\n$ Grade <chr> \"A\", \"B\", \"A\"\n\n\nTable @ref(tab:tab301) show the the data frame created by fusing the two vectors together.\n\n\n\n\nVariables in the data frame\n \n  \n    Name \n    Score \n    Grade \n  \n \n\n  \n    Bob \n    90 \n    A \n  \n  \n    Jeff \n    75 \n    B \n  \n  \n    Mary \n    92 \n    A \n  \n\n\n\n\n\nBecause the columns have meaning and we have given them column names, it is desirable to want to access an element by the name of the column as opposed to the column number.In large Excel spreadsheets I often get annoyed trying to remember which column something was. The $sign and []are used in R to select variable from the data frame.\n\ndt$Name\n\n[1] \"Bob\"  \"Jeff\" \"Mary\"\n\ndt[,1]\n\n[1] \"Bob\"  \"Jeff\" \"Mary\"\n\n\n\ndt$Score\n\n[1] 90 75 92\n\ndt[,2]\n\n[1] 90 75 92\n\n\nR has build in dataset that we can use for illustration. For example, (longley?) created a longley dataset, which is data frame with 7 economic variables observed every year from 1947 ti 1962 (Table @ref(tab:tab22)). We can add the data in the workspace with data() function\n\ndata(longley)\n\nlongley %>% \n  kableExtra::kable(caption = \"Longleys' Economic dataset\", \n                    align = \"c\", row.names = F) %>%\n  kableExtra::column_spec(1:7, width = \"3cm\")\n\n\n\nLongleys' Economic dataset\n \n  \n    GNP.deflator \n    GNP \n    Unemployed \n    Armed.Forces \n    Population \n    Year \n    Employed \n  \n \n\n  \n    83.0 \n    234.289 \n    235.6 \n    159.0 \n    107.608 \n    1947 \n    60.323 \n  \n  \n    88.5 \n    259.426 \n    232.5 \n    145.6 \n    108.632 \n    1948 \n    61.122 \n  \n  \n    88.2 \n    258.054 \n    368.2 \n    161.6 \n    109.773 \n    1949 \n    60.171 \n  \n  \n    89.5 \n    284.599 \n    335.1 \n    165.0 \n    110.929 \n    1950 \n    61.187 \n  \n  \n    96.2 \n    328.975 \n    209.9 \n    309.9 \n    112.075 \n    1951 \n    63.221 \n  \n  \n    98.1 \n    346.999 \n    193.2 \n    359.4 \n    113.270 \n    1952 \n    63.639 \n  \n  \n    99.0 \n    365.385 \n    187.0 \n    354.7 \n    115.094 \n    1953 \n    64.989 \n  \n  \n    100.0 \n    363.112 \n    357.8 \n    335.0 \n    116.219 \n    1954 \n    63.761 \n  \n  \n    101.2 \n    397.469 \n    290.4 \n    304.8 \n    117.388 \n    1955 \n    66.019 \n  \n  \n    104.6 \n    419.180 \n    282.2 \n    285.7 \n    118.734 \n    1956 \n    67.857 \n  \n  \n    108.4 \n    442.769 \n    293.6 \n    279.8 \n    120.445 \n    1957 \n    68.169 \n  \n  \n    110.8 \n    444.546 \n    468.1 \n    263.7 \n    121.950 \n    1958 \n    66.513 \n  \n  \n    112.6 \n    482.704 \n    381.3 \n    255.2 \n    123.366 \n    1959 \n    68.655 \n  \n  \n    114.2 \n    502.601 \n    393.1 \n    251.4 \n    125.368 \n    1960 \n    69.564 \n  \n  \n    115.7 \n    518.173 \n    480.6 \n    257.2 \n    127.852 \n    1961 \n    69.331 \n  \n  \n    116.9 \n    554.894 \n    400.7 \n    282.7 \n    130.081 \n    1962 \n    70.551 \n  \n\n\n\n\n\nSometimes you may need to create set of values and store them in vectors, then combine the vectors into a data frame. Let us see how this can be done. First create three vectors. One contains id for ten individuals, the second vector hold the time each individual signed in the attendane book and the third vector is the distance of each individual from office. We can concatenate the set of values to make vectors.\n\nid  = c(1,2,3,4,5,6,7,8,9,10)\n\ntime = lubridate::ymd_hms(c(\"2018-11-20 06:35:25 EAT\", \"2018-11-20 06:52:05 EAT\", \n                 \"2018-11-20 07:08:45 EAT\", \"2018-11-20 07:25:25 EAT\", \n                 \"2018-11-20 07:42:05 EAT\", \"2018-11-20 07:58:45 EAT\", \n                 \"2018-11-20 08:15:25 EAT\", \"2018-11-20 08:32:05 EAT\", \n                 \"2018-11-20 08:48:45 EAT\", \"2018-11-20 09:05:25 EAT\"), tz = \"\")\n\ndistance = c(20, 85, 45, 69, 42,  52, 6, 45, 36, 7)\n\nOnce we have the vectors that have the same length dimension, we can use the function data.frame() to combine the the three vectors into one data frame shown in table @ref(tab:tab23)\n\narrival = data.frame(id, time, distance)\n\n\n\n\n\nThe time employees enter into the office with the distance from their residential areas to the office\n \n  \n    IDs \n    Time \n    Distance \n  \n \n\n  \n    1 \n    2018-11-20 06:35:25 \n    20 \n  \n  \n    2 \n    2018-11-20 06:52:05 \n    85 \n  \n  \n    3 \n    2018-11-20 07:08:45 \n    45 \n  \n  \n    4 \n    2018-11-20 07:25:25 \n    69 \n  \n  \n    5 \n    2018-11-20 07:42:05 \n    42 \n  \n  \n    6 \n    2018-11-20 07:58:45 \n    52 \n  \n  \n    7 \n    2018-11-20 08:15:25 \n    6 \n  \n  \n    8 \n    2018-11-20 08:32:05 \n    45 \n  \n  \n    9 \n    2018-11-20 08:48:45 \n    36 \n  \n  \n    10 \n    2018-11-20 09:05:25 \n    7"
  },
  {
    "objectID": "dataTypes.html#matrix",
    "href": "dataTypes.html#matrix",
    "title": "3  Understanding Data in R",
    "section": "3.4 Matrix",
    "text": "3.4 Matrix\nA matrix is defined as a collection of data elements arranged in a two–dimensional rectangular layout. R is very strictly when you make up a matrix as it must be with equal dimension—all columns in a matrix must be of the same length. Unlike data frame and list that can store numeric or character.etc in columns, matrix columns must be numeric or characters in a matrix file.\n\n3.4.1 Creating Matrices\nThe base R has a matrix() function that construct matrices column–wise. In other language, element in matrix are entered starting from the upper left corner and running down the columns. Therefore, one should take serious note of specifying the value to fill in a matrix and the number of rows and columns when using the matrix() function.For example in the code block below, we create an imaginary month sst value for five years and obtain an atomic vector of 60 observation.\n\nsst = rnorm(n = 60, mean = 25, 3)\n\nOnce we have the atomic vector of sst value, we can convert it to matrix with the matrix() function. We put the observation as rows—months and the columns as years. Therefore, we have 12 rows and 5 years and the product of number of months and years we get 60—equivalent to our sst atomic vector we just created above.\n\nsst.matrix = matrix(data = sst, nrow = 12, ncol = 5)\n\nWe then check whether we got the matrix with is.matrix() function\n\nis.matrix(sst);is.matrix(sst.matrix)\n\n[1] FALSE\n\n\n[1] TRUE\n\nsst\n\n [1] 28.82872 26.78172 27.80504 25.47608 28.67766 25.38229 28.25001 24.31878\n [9] 24.90837 25.38768 19.47475 23.00008 31.66327 21.45813 25.27089 22.17760\n[17] 24.56211 24.44773 23.50963 21.48565 29.46540 20.27727 25.94891 24.77219\n[25] 27.07925 25.01276 25.72521 19.50245 22.42675 28.61962 25.32111 25.09477\n[33] 24.41171 29.64493 28.43283 27.73797 22.77303 24.69497 24.86942 25.46890\n[41] 26.14124 23.22980 23.70522 22.31969 21.34177 23.44300 18.90685 27.29107\n[49] 26.05681 24.97376 27.47287 25.72672 25.47556 27.52945 25.66604 24.54226\n[57] 26.06462 27.21253 26.40662 25.75130\n\n\nWe can check whether the dimension we just defined while creating this matrix is correct. This is done with the dim() function from base R.\n\ndim(sst.matrix)\n\n[1] 12  5\n\n\nIf you have large vector and you you want the matrix() function to figure out the number of columns, you simply define the nrow and tell the function that you do not want those element arranged by rows —i.e you want them in column-wise. That is done by parsing the argument byrow = FALSE inside the matrixt() function.\n\nsst.matrixby = sst %>% matrix(nrow = 12, byrow = FALSE)\n\n\n\n3.4.2 Adding attributes to Matrices\nOften times you may need to add additional attributes to the maxtrix—observation names, variable names and comments in the matrix.\nWe can add columns, which are years from 2014 to 2018\n\nyears = 2014:2018\ncolnames(sst.matrix) = years\nsst.matrix\n\n          2014     2015     2016     2017     2018\n [1,] 28.82872 31.66327 27.07925 22.77303 26.05681\n [2,] 26.78172 21.45813 25.01276 24.69497 24.97376\n [3,] 27.80504 25.27089 25.72521 24.86942 27.47287\n [4,] 25.47608 22.17760 19.50245 25.46890 25.72672\n [5,] 28.67766 24.56211 22.42675 26.14124 25.47556\n [6,] 25.38229 24.44773 28.61962 23.22980 27.52945\n [7,] 28.25001 23.50963 25.32111 23.70522 25.66604\n [8,] 24.31878 21.48565 25.09477 22.31969 24.54226\n [9,] 24.90837 29.46540 24.41171 21.34177 26.06462\n[10,] 25.38768 20.27727 29.64493 23.44300 27.21253\n[11,] 19.47475 25.94891 28.43283 18.90685 26.40662\n[12,] 23.00008 24.77219 27.73797 27.29107 25.75130\n\n\nand add the month for rows, which is January to December. Now the matrix has names for the rows—records and for columns—variables\n\nmonths = seq(from = lubridate::dmy(010115), to = lubridate::dmy(311215), \n             by = \"month\") %>% lubridate::month(abbr = TRUE, \n                                     label = TRUE)\nrownames(sst.matrix) = months\nsst.matrix\n\n        2014     2015     2016     2017     2018\nJan 28.82872 31.66327 27.07925 22.77303 26.05681\nFeb 26.78172 21.45813 25.01276 24.69497 24.97376\nMar 27.80504 25.27089 25.72521 24.86942 27.47287\nApr 25.47608 22.17760 19.50245 25.46890 25.72672\nMay 28.67766 24.56211 22.42675 26.14124 25.47556\nJun 25.38229 24.44773 28.61962 23.22980 27.52945\nJul 28.25001 23.50963 25.32111 23.70522 25.66604\nAug 24.31878 21.48565 25.09477 22.31969 24.54226\nSep 24.90837 29.46540 24.41171 21.34177 26.06462\nOct 25.38768 20.27727 29.64493 23.44300 27.21253\nNov 19.47475 25.94891 28.43283 18.90685 26.40662\nDec 23.00008 24.77219 27.73797 27.29107 25.75130"
  },
  {
    "objectID": "dataTypes.html#arrays",
    "href": "dataTypes.html#arrays",
    "title": "3  Understanding Data in R",
    "section": "3.5 Arrays",
    "text": "3.5 Arrays\n\narray(data = sst, dim = c(3,5,4))\n\n, , 1\n\n         [,1]     [,2]     [,3]     [,4]     [,5]\n[1,] 28.82872 25.47608 28.25001 25.38768 31.66327\n[2,] 26.78172 28.67766 24.31878 19.47475 21.45813\n[3,] 27.80504 25.38229 24.90837 23.00008 25.27089\n\n, , 2\n\n         [,1]     [,2]     [,3]     [,4]     [,5]\n[1,] 22.17760 23.50963 20.27727 27.07925 19.50245\n[2,] 24.56211 21.48565 25.94891 25.01276 22.42675\n[3,] 24.44773 29.46540 24.77219 25.72521 28.61962\n\n, , 3\n\n         [,1]     [,2]     [,3]     [,4]     [,5]\n[1,] 25.32111 29.64493 22.77303 25.46890 23.70522\n[2,] 25.09477 28.43283 24.69497 26.14124 22.31969\n[3,] 24.41171 27.73797 24.86942 23.22980 21.34177\n\n, , 4\n\n         [,1]     [,2]     [,3]     [,4]     [,5]\n[1,] 23.44300 26.05681 25.72672 25.66604 27.21253\n[2,] 18.90685 24.97376 25.47556 24.54226 26.40662\n[3,] 27.29107 27.47287 27.52945 26.06462 25.75130\n\n\nThis can be done with the indexing. For example, in the sst.matrix we just create, it has twelve rows representing monthly average and five columns representing years. We then obtain data for the six year and we want to add it into the matrix. Simply done with indexing\n\nsst.matrix[1:12,5]\n\n     Jan      Feb      Mar      Apr      May      Jun      Jul      Aug \n26.05681 24.97376 27.47287 25.72672 25.47556 27.52945 25.66604 24.54226 \n     Sep      Oct      Nov      Dec \n26.06462 27.21253 26.40662 25.75130"
  },
  {
    "objectID": "dataTypes.html#dealing-with-misiing-values",
    "href": "dataTypes.html#dealing-with-misiing-values",
    "title": "3  Understanding Data in R",
    "section": "3.6 Dealing with Misiing Values",
    "text": "3.6 Dealing with Misiing Values\nJust as we can assign numbers, strings, list to a variable, we can also assign nothing to an object, or an empty value to a variable. IN R, an empty object is defined with NULL. Assigning a value oof NULL to an object is one way to reset it to its original, empty state. You might do this when you wanto to pre–allocate an object without any value, especially when you iterate the process and you want the outputs to be stored in the empty object.\n\nsst.container = NULL\n\nYou can check whether the object is an empty with the is.null() function, which return a logical ouputs indicating whther is TRUE or FALSE\n\nis.null(sst.container)\n\n[1] TRUE\n\n\nYou can also check for NULL in an if satement as well, as highlighted in the following example;\n\nif (is.null(sst.container)){\n  print(\"The object is empty and hence you can use to store looped outputs!!!\")\n}\n\n[1] \"The object is empty and hence you can use to store looped outputs!!!\"\n\n\nAnd empty element (value) in object is represented with NA in R, and it is the absence of value in an object or variable.\n\nsst.sample = c(26.78, 25.98,NA, 24.58, NA)\nsst.sample\n\n[1] 26.78 25.98    NA 24.58    NA\n\n\nTo identify missing values in a vector in R, use the is.na() function, which returns a logical vector with TRUE of the corresponding element(s) with missing value\n\nis.na(sst.sample)\n\n[1] FALSE FALSE  TRUE FALSE  TRUE\n\n\nand computing statistics of the variable with NA always will give out the NA ouputs\n\nmean(sst.sample); sd(sst.sample);range(sst.sample)\n\n[1] NA\n\n\n[1] NA\n\n\n[1] NA NA\n\n\nHowever, we can exclude missing value in these mathematical operations by parsing , na.rm = TRUE argument\n\nmean(sst.sample, na.rm = TRUE);sd(sst.sample, na.rm = TRUE);range(sst.sample, na.rm = TRUE)\n\n[1] 25.78\n\n\n[1] 1.113553\n\n\n[1] 24.58 26.78\n\n\nyou can also exclude the element with NA value using the `na.omit()\n\nsst.sample %>% na.omit()\n\n[1] 26.78 25.98 24.58\nattr(,\"na.action\")\n[1] 3 5\nattr(,\"class\")\n[1] \"omit\"\n\n\nFinally is a NaN, which is closely related to NA, which is used to assign non-floating numbers. For example when we have the anomaly of sea surface temperature and we are interested to use sqrt() function to reduce the variability of the dataset.\n\nsst.anomaly = c(2.3,1.25,.8,.31,0,-.21)\nsqrt(sst.anomaly)\n\nWarning in sqrt(sst.anomaly): NaNs produced\n\n\n[1] 1.5165751 1.1180340 0.8944272 0.5567764 0.0000000       NaN\n\n\nWe notice that the sqrt of -0.21 gives us a NaN elements.\n\n\n\n\nMüller, Kirill, and Hadley Wickham. 2018. Tibble: Simple Data Frames. https://CRAN.R-project.org/package=tibble."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "4  Reading data into R",
    "section": "",
    "text": "You can lean R with the dataset it comes with when you install it in your machine. But sometimes you want to use the real data you or someone gathered already. One of critical steps for data processing is to import data with special format into R workspace.Data import refers to read data from the working directory into the workspace (Wickham, Hester, and Francois 2017). In this chapter you will learn how to import common files into R. We will only focus on two common types of tabular data storage format—The comma-seprated .csv and excell spreadsheet (.xlsx). In later chapter we will explain how to read other types of data into R.\nTransferring data from one place to another is always fraught with danger. Expecting it to always be smooth is just setting yourself up for disappointment. But sometimes getting data into R does go smoothly.\nIf you are trying to get rectangular data (something that looks like a matrix or a data frame) into R, then the read.table function or one of its relatives will be what you want to use. This function returns a data frame. Note: a data frame, not a matrix.\nThe two common rectangular data are:\nBoth of the above assume that the data are of a rectangular form. In the unlikely event you have non-rectangular data to read in, that is possible as well but the best way to do that depends on the form of your data."
  },
  {
    "objectID": "data.html#getting-data-into-r",
    "href": "data.html#getting-data-into-r",
    "title": "4  Reading data into R",
    "section": "4.1 Getting Data into R",
    "text": "4.1 Getting Data into R\nMuch of the data we download or receive from researchers is in the form of delimited files. Whether that be a comma separated (csv) or a tab delimited file, there are multiple functions that can read these data into R. We will stick to loading these data from the tidyverse packages but be aware these are not the only methods for doing this. We will use the tidyverse functions just to maintain consistency with everything else we do.\nThe first package in tidyverse we will use is called readr (Wickham, Hester, and Francois 2017), which is a collection of functions to load the tabular data from working directory in our machine into R session. Some of its functions include:\n\nread_csv(): comma separated (CSV) files\nread_tsv(): tab separated files\nread_delim(): general delimited files\nread_fwf(): fixed width files\nread_table(): tabular files where columns are separated by white-space.\nread_log(): web log files\nreadxl reads in Excel files.\n\nBefore we import the data, we need to load the packages that we will use their functions in this chapter\n\nrequire(tidyverse)\nrequire(magrittr)"
  },
  {
    "objectID": "data.html#dataset",
    "href": "data.html#dataset",
    "title": "4  Reading data into R",
    "section": "4.2 Dataset",
    "text": "4.2 Dataset\nFor us to demonstrate how to import data into R, we are going to use the penguin dataset Figure 4.1. The penguin dataset is a collection of images of penguin colonies in Antarctica coming from the larger penguin watch project, which was setup with the purpose of monitoring their changes in population. The images are taken by fixed cameras in over 40 different locations, which have been capturing an image per hour for several years. In order to track the colony sizes, the number of penguins in each of the images in the dataset is required. So far, the penguin count has been done with the help of citizen scientists on the Penguin Watch site by Zooniverse, where interested users can place dots on top of the penguins. Here we release part of this data to the vision community in order to learn from the crowd-sourced dot-annotations to automatically annotate these images.\n\n\n\n\n\nFigure 4.1: penguins data"
  },
  {
    "objectID": "data.html#comma-separated-.csv",
    "href": "data.html#comma-separated-.csv",
    "title": "4  Reading data into R",
    "section": "4.3 Comma-Separated (.csv)",
    "text": "4.3 Comma-Separated (.csv)\nThe most commonly format that R like is the comma-separated files. Although Base R provides various functions like read.table(), read.csv(), read.table() and read.csv2() to import data from the local directories into R workspace, for this book we use an read_csv() function from readr. If you have a tabular data stored in your working directory as.csv format, You simply import it into R with the read_csv() and specify the path to the file in your working directory as:\n\npenguins = readr::read_csv(file = \"assets/penguins.csv\")\n\nTo visualize the data we just imported, we simply type the name in console and click ENTER\n\npenguins\n\n# A tibble: 344 x 8\n   species island    bill_length_mm bill_depth_mm flipper_~1 body_~2 sex    year\n   <chr>   <chr>              <dbl>         <dbl>      <dbl>   <dbl> <chr> <dbl>\n 1 Adelie  Torgersen           39.1          18.7        181    3750 male   2007\n 2 Adelie  Torgersen           39.5          17.4        186    3800 fema~  2007\n 3 Adelie  Torgersen           40.3          18          195    3250 fema~  2007\n 4 Adelie  Torgersen           NA            NA           NA      NA <NA>   2007\n 5 Adelie  Torgersen           36.7          19.3        193    3450 fema~  2007\n 6 Adelie  Torgersen           39.3          20.6        190    3650 male   2007\n 7 Adelie  Torgersen           38.9          17.8        181    3625 fema~  2007\n 8 Adelie  Torgersen           39.2          19.6        195    4675 male   2007\n 9 Adelie  Torgersen           34.1          18.1        193    3475 <NA>   2007\n10 Adelie  Torgersen           42            20.2        190    4250 <NA>   2007\n# ... with 334 more rows, and abbreviated variable names 1: flipper_length_mm,\n#   2: body_mass_g\n\n\nBy simply print the loaded dataset, we a tabular shape data frame with eight variables (fields) and 344 rows (records)."
  },
  {
    "objectID": "data.html#microsoft-excel.xlsx",
    "href": "data.html#microsoft-excel.xlsx",
    "title": "4  Reading data into R",
    "section": "4.4 Microsoft Excel(.xlsx)",
    "text": "4.4 Microsoft Excel(.xlsx)\nCommonly our data is stored as a MS Excel file. we can import the file with read_xlsx() function of readxl package. The readxl package provides a function read_exel() that allows us to specify which sheet within the Excel file to read and what character specifies missing data (it assumes a blank cell is missing data if you don’t specifying anything). The function automatically convert the worksheet into a .csv file and read it. Let’s us import the the data in first sheet of the primary_productivity.xlsx. The dataset contain primary productivity value. We will use this file to illustrate how to import the excel file into R workspace with readxl package (Wickham and Bryan 2018).\n\npenguins = readxl::read_excel(\"assets/penguins.xlsx\")\npenguins\n\n# A tibble: 344 x 8\n   species island    bill_length_mm     bill_depth~1 flipp~2 body_~3 sex    year\n   <chr>   <chr>     <chr>              <chr>        <chr>   <chr>   <chr> <dbl>\n 1 Adelie  Torgersen 39.1               18.7         181     3750    male   2007\n 2 Adelie  Torgersen 39.5               17.39999999~ 186     3800    fema~  2007\n 3 Adelie  Torgersen 40.299999999999997 18           195     3250    fema~  2007\n 4 Adelie  Torgersen NA                 NA           NA      NA      NA     2007\n 5 Adelie  Torgersen 36.700000000000003 19.3         193     3450    fema~  2007\n 6 Adelie  Torgersen 39.299999999999997 20.6         190     3650    male   2007\n 7 Adelie  Torgersen 38.9               17.8         181     3625    fema~  2007\n 8 Adelie  Torgersen 39.200000000000003 19.60000000~ 195     4675    male   2007\n 9 Adelie  Torgersen 34.1               18.10000000~ 193     3475    NA     2007\n10 Adelie  Torgersen 42                 20.2         190     4250    NA     2007\n# ... with 334 more rows, and abbreviated variable names 1: bill_depth_mm,\n#   2: flipper_length_mm, 3: body_mass_g\n\n\nBy printing the penguin dataset imported with read_excel, we notice that the that some of the variable in the dataset columns were imported as character while they are suppose to be numerical."
  },
  {
    "objectID": "data.html#writing-t-a-file",
    "href": "data.html#writing-t-a-file",
    "title": "4  Reading data into R",
    "section": "4.5 Writing t a File",
    "text": "4.5 Writing t a File\nSometimes you work in the document and you want to export to a file. readr has write_csv() and write_tsv() functions that allows to export data frames from workspace to working directory\n\nwrite_csv(x = penguins, path = \"assets/penguins_clean.csv\")\n\nWickham and Bryan (2018) recommend the use of write_excel_csv() function when you want to export a data frame to Excel. readr has other tools that export files to other software like SAS, SPSS and more …\n\nwrite_excel_csv(x = penguins, path = \"assets/penguins_clean.csv\")"
  },
  {
    "objectID": "data.html#basic-data-manipulation",
    "href": "data.html#basic-data-manipulation",
    "title": "4  Reading data into R",
    "section": "4.6 Basic Data Manipulation",
    "text": "4.6 Basic Data Manipulation\nIn this section, we briefly introduce some basic data handling and manipulation techniques, which are mostly associated with data frame. A data frame is a a tabular shaped contains columns and rows of equal length. In general a data frame structure with rows representing observations or measurements and with columns containing variables.\n\n4.6.1 Explore the Data Frame\nWe can visualize the table by simply run the name of the data flights\n\noctopus = read_csv(\"assets/octopus_data.csv\")\n\nRows: 1079 Columns: 10\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr  (4): village, port, ground, sex\ndbl  (5): dml, tl, weight, lat, lon\ndate (1): date\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nwe can use class() to check if the data is data frame\n\noctopus %>% class()\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nWe can use names() to extract the variable names\n\noctopus %>% names()\n\n [1] \"date\"    \"village\" \"port\"    \"ground\"  \"sex\"     \"dml\"     \"tl\"     \n [8] \"weight\"  \"lat\"     \"lon\"    \n\n\nWe can explore the internal structure of flights object with a dplyr()’s function glimpse()\n\noctopus %>% glimpse()\n\nRows: 1,079\nColumns: 10\n$ date    <date> 2018-02-12, 2018-01-30, 2018-02-01, 2018-01-21, 2018-03-03, 2~\n$ village <chr> \"Somanga\", \"Bwejuu\", \"Somanga\", \"Somanga\", \"Somanga\", \"Somanga~\n$ port    <chr> \"Mbuyuni\", \"Kusini\", \"Mbuyuni\", \"Mbuyuni\", \"Mbuyuni\", \"Mbuyuni~\n$ ground  <chr> \"CHAMBA CHA MACHANGE\", \"NYAMALILE\", \"BANIANI\", \"CHAMBA CHA SEL~\n$ sex     <chr> \"F\", \"M\", \"M\", \"M\", \"M\", \"F\", \"M\", \"M\", \"M\", \"F\", \"F\", \"F\", \"M~\n$ dml     <dbl> 14.0, 14.5, 17.0, 20.0, 12.0, 16.0, 15.0, 17.0, 12.0, 12.0, 9.~\n$ tl      <dbl> 110.0, 115.0, 115.0, 130.0, 68.0, 90.0, 96.0, 110.0, 79.0, 84.~\n$ weight  <dbl> 1.385, 1.750, 1.000, 2.601, 0.670, 0.870, 1.020, 1.990, 0.730,~\n$ lat     <dbl> -8.397838, -7.915809, -8.392644, -8.391614, -8.391146, -8.3881~\n$ lon     <dbl> 39.28079, 39.65424, 39.28153, 39.28089, 39.28251, 39.28196, 39~\n\n\nWe can check how rows (observations/measurements) and columns (variables/fields) are in the data\n\noctopus %>% dim()\n\n[1] 1079   10\n\n\nThe number of rows (observation) can be obtained using nrow() function\n\noctopus %>% nrow()\n\n[1] 1079\n\n\nThe number of columns (variables) can be obtained using ncol() function\n\noctopus %>% ncol()\n\n[1] 10\n\n\nThe length of the data frame is given by\n\noctopus %>% length()\n\n[1] 10\n\n\nCount the number of sample at each sex of octopus\n\noctopus %$% table(sex) \n\nsex\n  F   M \n581 498 \n\n\nCount the number and compute the proportion of sample at each sex of octopus\n\noctopus %$% table(sex) %>% prop.table() %>% round(digits = 2)\n\nsex\n   F    M \n0.54 0.46 \n\n\n\n\n4.6.2 Simple summary statistics\nThe most helpful function for for summarizing rows and columns is summary(), which gives a collection of basim cummary statistics. The first method is to calculate some basic summary statistics (minimum, 25th, 50th, 75th percentiles, maximum and mean) of each column. If a column is categorical, the summary function will return the number of observations in each category.\n\noctopus %>% summary()\n\n      date              village              port              ground         \n Min.   :2017-12-18   Length:1079        Length:1079        Length:1079       \n 1st Qu.:2018-01-14   Class :character   Class :character   Class :character  \n Median :2018-01-20   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2018-01-26                                                           \n 3rd Qu.:2018-02-15                                                           \n Max.   :2018-03-12                                                           \n     sex                 dml             tl             weight     \n Length:1079        Min.   : 6.0   Min.   : 11.00   Min.   :0.055  \n Class :character   1st Qu.:10.0   1st Qu.: 68.00   1st Qu.:0.600  \n Mode  :character   Median :12.0   Median : 82.00   Median :0.915  \n                    Mean   :12.8   Mean   : 86.01   Mean   :1.232  \n                    3rd Qu.:15.0   3rd Qu.:100.00   3rd Qu.:1.577  \n                    Max.   :24.0   Max.   :180.00   Max.   :5.210  \n      lat              lon       \n Min.   :-8.904   Min.   : 0.00  \n 1st Qu.:-8.523   1st Qu.:39.28  \n Median :-8.392   Median :39.50  \n Mean   :-8.069   Mean   :38.69  \n 3rd Qu.:-7.973   3rd Qu.:39.67  \n Max.   : 0.000   Max.   :39.75  \n\n\nYou noticed that the summary() function provide the common metric for central tendency and measure of dispersion. We will look at them later. Now we turn to our favorite package for data manipulation dplyr (Wickham et al. 2018)."
  },
  {
    "objectID": "data.html#references",
    "href": "data.html#references",
    "title": "4  Reading data into R",
    "section": "References",
    "text": "References\n\n\n\n\nWickham, Hadley, and Jennifer Bryan. 2018. Readxl: Read Excel Files. https://CRAN.R-project.org/package=readxl.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2018. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Romain Francois. 2017. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr."
  },
  {
    "objectID": "dataManipulation.html",
    "href": "dataManipulation.html",
    "title": "5  Manipulating Data with dplyr",
    "section": "",
    "text": "Before a dataset can be analysed in R, its often manipulated or transformed in various ways. For years manipulating data in R required more programming than actually analyzing data. That has improved dramatically with the dplyr package. It provides programmers with an intuitive vocabulary for executing data management and analysis tasks. Hadley Wickham (2018), the original creator of the dplyr package, refers to it as a Grammar of Data Manipulation. Because the package provides a set of functions (verbs) that let you modify data and perform common data preparation tasks. The key challenge in programming is mapping from questions about a data set to specific programming operations. With dplyr’s verbs, makes this process smoother, as it enables you to use the same vocabulary to both ask questions and write your code. In other words, the dplyr verbs lets you easily talk with data and transform a dataset in various ways with easy."
  },
  {
    "objectID": "dataManipulation.html#why-use-dplyr",
    "href": "dataManipulation.html#why-use-dplyr",
    "title": "5  Manipulating Data with dplyr",
    "section": "5.1 Why use dplyr?",
    "text": "5.1 Why use dplyr?\nUsing this package’s functions will allow you to code expressively—code that are easy to write and read, which make you effective and efficient data scientists.\n\nGreat for data exploration and manipulation\nIntuitive to write and easy to read, especially when using the chaining syntax\nFast on data frame—tabular dataset"
  },
  {
    "objectID": "dataManipulation.html#core-dplyr-functions",
    "href": "dataManipulation.html#core-dplyr-functions",
    "title": "5  Manipulating Data with dplyr",
    "section": "5.2 Core dplyr Functions",
    "text": "5.2 Core dplyr Functions\nI will not go through all of the dplyr functions in this chapter. I will demonstrate the core functions that are used regularly for manipulating data. The five core functions also called verbs include:\n\nselect() to select columns based on their names\nfilter() to rows in data frame\narrange() to re-order or arrange the rows in ascending or descending order\nmutate() to create new columns—add new variable\nsummarise() to make a summary of variable(s)\ngroup_by() to group observation\nsample_n() and rename()to make random sample from the data set\n\nThe group_by() function perform other common task which are related to the split-apply-combine concept. You can use these verbs when you describe the algorithm or process for interrogating data, and then use dplyr verbs to write code that will closely follow your “plain language” description because it uses functions and procedures that share the same language.\nFor most of us who are familiar with the R base function, you will find that most dplyr functions on data frames can be expressed succinctly because you don’t need to repeat the name of the data frame. This becomes handy in operation, because dplyr package comes with the pipe operateor %>% from the magrittr package (magrittr?), which allows to combine several functions in a chain to manipulate data.\nTo use dplyr functions to manipulate your data, it must be already installed in your machine so that you can load with a require () function. Once the package is loaded, its functions are available for use. dplyr is a key package of the tidyverse ecosystem—a collection of R packages, which also includes other packages like, readr (Wickham, Hester, and Francois 2017), purr,tibble (Müller and Wickham 2018), stringr (stringr?), forcats, tidyr (Wickham and Henry 2018) and ggplot2 (Wickham 2016).\n\nrequire(tidyverse)"
  },
  {
    "objectID": "dataManipulation.html#data",
    "href": "dataManipulation.html#data",
    "title": "5  Manipulating Data with dplyr",
    "section": "5.3 Data",
    "text": "5.3 Data\nData frames are ideal for representing data where each row is an observations and each column is a variable. Nearly all packages in a tidyverse work on data frames new version called tibble. A tibble provides stricter checking and better formatting than the traditional data frame.\nTo demonstrate the usefulness of the dplyr package for manipulating data, we will use the CTD data of 22 stations casted along the coastal water of Tanzania. I have prepared the data, cleaned and align the profile into 5 meter standard depth for each cast and merged them into a single .csv file. You need to load the file into your R session. We can import the file with read_csv() function from the readr package (Wickham, Hester, and Francois 2017). The read_csv() function gives out a tibble (Müller and Wickham 2018)."
  },
  {
    "objectID": "dataManipulation.html#choosing-rows-filtering-observations",
    "href": "dataManipulation.html#choosing-rows-filtering-observations",
    "title": "5  Manipulating Data with dplyr",
    "section": "5.4 Choosing rows: Filtering observations",
    "text": "5.4 Choosing rows: Filtering observations\nThe first dplyr verb we’ll explore is filter(). This function is primarily used to create a subset of observations that meet a specified conditions. The filter() function lets you pick out rows based on logical expressions. You give the function a predicate, specifying what a row should satisfy to be included. For instance, take a look at the chunk below:\n\nctd %>% \n  filter(pressure < 150)\n\n# A tibble: 637 x 12\n   station time                  lon   lat pressure temperature salinity oxygen\n   <chr>   <dttm>              <dbl> <dbl>    <dbl>       <dbl>    <dbl>  <dbl>\n 1 st1     2004-08-18 15:27:46  40.6 -10.5        5        25.2     33.9   3.93\n 2 st1     2004-08-18 15:27:46  40.6 -10.5       10        25.1     34.9   4.49\n 3 st1     2004-08-18 15:27:46  40.6 -10.5       15        25.1     34.9   4.50\n 4 st1     2004-08-18 15:27:46  40.6 -10.5       20        25.0     34.9   4.51\n 5 st1     2004-08-18 15:27:46  40.6 -10.5       25        24.9     34.9   4.51\n 6 st1     2004-08-18 15:27:46  40.6 -10.5       30        24.9     34.9   4.50\n 7 st1     2004-08-18 15:27:46  40.6 -10.5       35        24.9     34.9   4.49\n 8 st1     2004-08-18 15:27:46  40.6 -10.5       40        24.9     34.9   4.48\n 9 st1     2004-08-18 15:27:46  40.6 -10.5       45        24.8     34.9   4.46\n10 st1     2004-08-18 15:27:46  40.6 -10.5       50        24.6     34.9   4.44\n# ... with 627 more rows, and 4 more variables: fluorescence <dbl>, spar <dbl>,\n#   par <dbl>, density <dbl>\n\n\nThe expression calls the ctd dataset and feed into the filter()and pick all observations with pressure below 150meters and create a new datase called surface. This is an expression where a single conditional statement is used.\nWe can also limit the of the variable of interest by combining multiple conditional expressions as part of the filter(). Each expression (argument) is combined with an “AND” clause by default. This means that all expressions must be matched for a recorded to be returned. For instance we want to pick observations that were measured between 5 and 10 meters water only. We combine theses expressions with & operator;\n\nctd %>% \n  filter(pressure >= 0 & pressure <= 10)\n\n# A tibble: 44 x 12\n   station time                  lon   lat pressure temperature salinity oxygen\n   <chr>   <dttm>              <dbl> <dbl>    <dbl>       <dbl>    <dbl>  <dbl>\n 1 st1     2004-08-18 15:27:46  40.6 -10.5        5        25.2     33.9   3.93\n 2 st1     2004-08-18 15:27:46  40.6 -10.5       10        25.1     34.9   4.49\n 3 st2     2004-08-18 17:00:01  40.8 -10.5        5        25.2     34.8   4.47\n 4 st2     2004-08-18 17:00:01  40.8 -10.5       10        25.2     34.8   4.47\n 5 st3     2004-08-18 20:32:54  41.0 -10.5        5        NA       NA    NA   \n 6 st3     2004-08-18 20:32:54  41.0 -10.5       10        25.0     34.9   4.49\n 7 st4     2004-08-18 22:44:56  41.1 -10.5        5        NA       NA    NA   \n 8 st4     2004-08-18 22:44:56  41.1 -10.5       10        NA       NA    NA   \n 9 st5     2004-08-19 00:59:59  41.3 -10.5        5        NA       NA    NA   \n10 st5     2004-08-19 00:59:59  41.3 -10.5       10        NA       NA    NA   \n# ... with 34 more rows, and 4 more variables: fluorescence <dbl>, spar <dbl>,\n#   par <dbl>, density <dbl>\n\n\nWe can also use the between() function, which is equivalent to pressure >= 0 & pressure <= 10 in above chunk to achive the same result.\n\nctd %>% \n  filter(between(pressure, 5,10))\n\n# A tibble: 44 x 12\n   station time                  lon   lat pressure temperature salinity oxygen\n   <chr>   <dttm>              <dbl> <dbl>    <dbl>       <dbl>    <dbl>  <dbl>\n 1 st1     2004-08-18 15:27:46  40.6 -10.5        5        25.2     33.9   3.93\n 2 st1     2004-08-18 15:27:46  40.6 -10.5       10        25.1     34.9   4.49\n 3 st2     2004-08-18 17:00:01  40.8 -10.5        5        25.2     34.8   4.47\n 4 st2     2004-08-18 17:00:01  40.8 -10.5       10        25.2     34.8   4.47\n 5 st3     2004-08-18 20:32:54  41.0 -10.5        5        NA       NA    NA   \n 6 st3     2004-08-18 20:32:54  41.0 -10.5       10        25.0     34.9   4.49\n 7 st4     2004-08-18 22:44:56  41.1 -10.5        5        NA       NA    NA   \n 8 st4     2004-08-18 22:44:56  41.1 -10.5       10        NA       NA    NA   \n 9 st5     2004-08-19 00:59:59  41.3 -10.5        5        NA       NA    NA   \n10 st5     2004-08-19 00:59:59  41.3 -10.5       10        NA       NA    NA   \n# ... with 34 more rows, and 4 more variables: fluorescence <dbl>, spar <dbl>,\n#   par <dbl>, density <dbl>\n\n\nIn the next example, two conditional expressions are passed. The first is used to filter surface water below 200 m, and the second statement filter records that above latitude 6°S\n\nctd %>% \n  filter(pressure < 200 & lat > -6)\n\n# A tibble: 223 x 12\n   station time                  lon   lat pressure temperature salinity oxygen\n   <chr>   <dttm>              <dbl> <dbl>    <dbl>       <dbl>    <dbl>  <dbl>\n 1 st17    2004-08-23 19:42:30  40.1 -5.49        5        25.6     35.2   4.40\n 2 st17    2004-08-23 19:42:30  40.1 -5.49       10        25.4     35.1   4.45\n 3 st17    2004-08-23 19:42:30  40.1 -5.49       15        25.3     35.1   4.48\n 4 st17    2004-08-23 19:42:30  40.1 -5.49       20        25.4     35.2   4.48\n 5 st17    2004-08-23 19:42:30  40.1 -5.49       25        25.4     35.2   4.48\n 6 st17    2004-08-23 19:42:30  40.1 -5.49       30        25.4     35.2   4.48\n 7 st17    2004-08-23 19:42:30  40.1 -5.49       35        25.4     35.2   4.46\n 8 st17    2004-08-23 19:42:30  40.1 -5.49       40        25.4     35.2   4.48\n 9 st17    2004-08-23 19:42:30  40.1 -5.49       45        25.4     35.2   4.47\n10 st17    2004-08-23 19:42:30  40.1 -5.49       50        25.4     35.2   4.45\n# ... with 213 more rows, and 4 more variables: fluorescence <dbl>, spar <dbl>,\n#   par <dbl>, density <dbl>\n\n\nIn this case, the surface.transect dataset has records where both conditions are met—the pressure is blow 200 meter and latitude above -6. Note that when two or more conditions are paased, the & operator is used.\nYou may sometimes want to know stations and at what depth a particular variable has missing values. You can pick all variable in the data frame using is.na() function.\n\nctd %>% \n  filter(is.na(fluorescence))\n\n# A tibble: 7 x 12\n  station time                  lon    lat pressure temperature salinity oxygen\n  <chr>   <dttm>              <dbl>  <dbl>    <dbl>       <dbl>    <dbl>  <dbl>\n1 st3     2004-08-18 20:32:54  41.0 -10.5         5          NA       NA     NA\n2 st4     2004-08-18 22:44:56  41.1 -10.5         5          NA       NA     NA\n3 st4     2004-08-18 22:44:56  41.1 -10.5        10          NA       NA     NA\n4 st5     2004-08-19 00:59:59  41.3 -10.5         5          NA       NA     NA\n5 st5     2004-08-19 00:59:59  41.3 -10.5        10          NA       NA     NA\n6 st10    2004-08-19 19:36:50  39.7  -8.83        5          NA       NA     NA\n7 st10    2004-08-19 19:36:50  39.7  -8.83       10          NA       NA     NA\n# ... with 4 more variables: fluorescence <dbl>, spar <dbl>, par <dbl>,\n#   density <dbl>\n\n\nYou can also drop the observation with missing values in the data frame using the !is.na() operator\n\nctd %>% \n  filter(!is.na(fluorescence))\n\n# A tibble: 2,789 x 12\n   station time                  lon   lat pressure temperature salinity oxygen\n   <chr>   <dttm>              <dbl> <dbl>    <dbl>       <dbl>    <dbl>  <dbl>\n 1 st1     2004-08-18 15:27:46  40.6 -10.5        5        25.2     33.9   3.93\n 2 st1     2004-08-18 15:27:46  40.6 -10.5       10        25.1     34.9   4.49\n 3 st1     2004-08-18 15:27:46  40.6 -10.5       15        25.1     34.9   4.50\n 4 st1     2004-08-18 15:27:46  40.6 -10.5       20        25.0     34.9   4.51\n 5 st1     2004-08-18 15:27:46  40.6 -10.5       25        24.9     34.9   4.51\n 6 st1     2004-08-18 15:27:46  40.6 -10.5       30        24.9     34.9   4.50\n 7 st1     2004-08-18 15:27:46  40.6 -10.5       35        24.9     34.9   4.49\n 8 st1     2004-08-18 15:27:46  40.6 -10.5       40        24.9     34.9   4.48\n 9 st1     2004-08-18 15:27:46  40.6 -10.5       45        24.8     34.9   4.46\n10 st1     2004-08-18 15:27:46  40.6 -10.5       50        24.6     34.9   4.44\n# ... with 2,779 more rows, and 4 more variables: fluorescence <dbl>,\n#   spar <dbl>, par <dbl>, density <dbl>\n\n\nWhen you have string variable in the data frame with character or factor format, you can filter the certain observation with %in% statement. For example, to obtain profiles from three stations: st1, st8, and st13, we can write the code as;\n\nctd %>% \n  filter(station %in% c(\"st1\", \"st8\", \"st13\"))\n\n# A tibble: 347 x 12\n   station time                  lon   lat pressure temperature salinity oxygen\n   <chr>   <dttm>              <dbl> <dbl>    <dbl>       <dbl>    <dbl>  <dbl>\n 1 st1     2004-08-18 15:27:46  40.6 -10.5        5        25.2     33.9   3.93\n 2 st1     2004-08-18 15:27:46  40.6 -10.5       10        25.1     34.9   4.49\n 3 st1     2004-08-18 15:27:46  40.6 -10.5       15        25.1     34.9   4.50\n 4 st1     2004-08-18 15:27:46  40.6 -10.5       20        25.0     34.9   4.51\n 5 st1     2004-08-18 15:27:46  40.6 -10.5       25        24.9     34.9   4.51\n 6 st1     2004-08-18 15:27:46  40.6 -10.5       30        24.9     34.9   4.50\n 7 st1     2004-08-18 15:27:46  40.6 -10.5       35        24.9     34.9   4.49\n 8 st1     2004-08-18 15:27:46  40.6 -10.5       40        24.9     34.9   4.48\n 9 st1     2004-08-18 15:27:46  40.6 -10.5       45        24.8     34.9   4.46\n10 st1     2004-08-18 15:27:46  40.6 -10.5       50        24.6     34.9   4.44\n# ... with 337 more rows, and 4 more variables: fluorescence <dbl>, spar <dbl>,\n#   par <dbl>, density <dbl>"
  },
  {
    "objectID": "dataManipulation.html#select",
    "href": "dataManipulation.html#select",
    "title": "5  Manipulating Data with dplyr",
    "section": "5.5 select",
    "text": "5.5 select\nThe second verb we are going to demonstrate is the select() function. Often you work with large datasets with many columns but only a few are actually of interest to you. The select() function selects columns of the data frame. select() function allows you to choose variables that are of interest. You can use it to pick out a some columns from the dataset. For instance, fi we want pressure, temprature, salinity, fluorescence and ovygen variables from the data frame, we can simply write a code as;\n\nctd %>% \n  select (pressure, temperature, salinity, fluorescence, oxygen)\n\n# A tibble: 2,796 x 5\n   pressure temperature salinity fluorescence oxygen\n      <dbl>       <dbl>    <dbl>        <dbl>  <dbl>\n 1        5        25.2     33.9        0.560   3.93\n 2       10        25.1     34.9        0.599   4.49\n 3       15        25.1     34.9        0.650   4.50\n 4       20        25.0     34.9        0.678   4.51\n 5       25        24.9     34.9        0.760   4.51\n 6       30        24.9     34.9        0.729   4.50\n 7       35        24.9     34.9        0.740   4.49\n 8       40        24.9     34.9        0.693   4.48\n 9       45        24.8     34.9        0.703   4.46\n10       50        24.6     34.9        0.752   4.44\n# ... with 2,786 more rows\n\n\nBesides just selecting columns, you can use a minus sign to remove variables you do not need from the data frame.\n\nctd %>% \n  select(-spar, -par, -density, -time) \n\n# A tibble: 2,796 x 8\n   station   lon   lat pressure temperature salinity oxygen fluorescence\n   <chr>   <dbl> <dbl>    <dbl>       <dbl>    <dbl>  <dbl>        <dbl>\n 1 st1      40.6 -10.5        5        25.2     33.9   3.93        0.560\n 2 st1      40.6 -10.5       10        25.1     34.9   4.49        0.599\n 3 st1      40.6 -10.5       15        25.1     34.9   4.50        0.650\n 4 st1      40.6 -10.5       20        25.0     34.9   4.51        0.678\n 5 st1      40.6 -10.5       25        24.9     34.9   4.51        0.760\n 6 st1      40.6 -10.5       30        24.9     34.9   4.50        0.729\n 7 st1      40.6 -10.5       35        24.9     34.9   4.49        0.740\n 8 st1      40.6 -10.5       40        24.9     34.9   4.48        0.693\n 9 st1      40.6 -10.5       45        24.8     34.9   4.46        0.703\n10 st1      40.6 -10.5       50        24.6     34.9   4.44        0.752\n# ... with 2,786 more rows\n\n## or you can bind the variable you want to remove\nctd %>% \n  select(-c(spar, par, density, time))\n\n# A tibble: 2,796 x 8\n   station   lon   lat pressure temperature salinity oxygen fluorescence\n   <chr>   <dbl> <dbl>    <dbl>       <dbl>    <dbl>  <dbl>        <dbl>\n 1 st1      40.6 -10.5        5        25.2     33.9   3.93        0.560\n 2 st1      40.6 -10.5       10        25.1     34.9   4.49        0.599\n 3 st1      40.6 -10.5       15        25.1     34.9   4.50        0.650\n 4 st1      40.6 -10.5       20        25.0     34.9   4.51        0.678\n 5 st1      40.6 -10.5       25        24.9     34.9   4.51        0.760\n 6 st1      40.6 -10.5       30        24.9     34.9   4.50        0.729\n 7 st1      40.6 -10.5       35        24.9     34.9   4.49        0.740\n 8 st1      40.6 -10.5       40        24.9     34.9   4.48        0.693\n 9 st1      40.6 -10.5       45        24.8     34.9   4.46        0.703\n10 st1      40.6 -10.5       50        24.6     34.9   4.44        0.752\n# ... with 2,786 more rows\n\n\nYou can drop a range of variables in the data frame with select() function. For instance, the code below drop all variables beween temperature to fluorescence. You can also select those variables in range by removing the negative sign\n\n# hide a range of columns\nctd %>% \n  select(-(temperature:fluorescence))\n\n# A tibble: 2,796 x 8\n   station time                  lon   lat pressure  spar   par density\n   <chr>   <dttm>              <dbl> <dbl>    <dbl> <dbl> <dbl>   <dbl>\n 1 st1     2004-08-18 15:27:46  40.6 -10.5        5 1177. 53.9    1022.\n 2 st1     2004-08-18 15:27:46  40.6 -10.5       10 1151. 40.3    1023.\n 3 st1     2004-08-18 15:27:46  40.6 -10.5       15 1135. 31.3    1023.\n 4 st1     2004-08-18 15:27:46  40.6 -10.5       20 1124. 25.6    1023.\n 5 st1     2004-08-18 15:27:46  40.6 -10.5       25 1111. 21.1    1023.\n 6 st1     2004-08-18 15:27:46  40.6 -10.5       30 1103. 17.2    1023.\n 7 st1     2004-08-18 15:27:46  40.6 -10.5       35 1097. 13.9    1023.\n 8 st1     2004-08-18 15:27:46  40.6 -10.5       40 1091. 11.2    1023.\n 9 st1     2004-08-18 15:27:46  40.6 -10.5       45 1087.  9.05   1024.\n10 st1     2004-08-18 15:27:46  40.6 -10.5       50 1084.  7.30   1024.\n# ... with 2,786 more rows\n\n\nJust like you can pick columns with the matching name, you can also drop any column with a matching name\n\nctd %>% \n  select(-contains(\"t\"))\n\n# A tibble: 2,796 x 6\n     lon pressure oxygen fluorescence  spar   par\n   <dbl>    <dbl>  <dbl>        <dbl> <dbl> <dbl>\n 1  40.6        5   3.93        0.560 1177. 53.9 \n 2  40.6       10   4.49        0.599 1151. 40.3 \n 3  40.6       15   4.50        0.650 1135. 31.3 \n 4  40.6       20   4.51        0.678 1124. 25.6 \n 5  40.6       25   4.51        0.760 1111. 21.1 \n 6  40.6       30   4.50        0.729 1103. 17.2 \n 7  40.6       35   4.49        0.740 1097. 13.9 \n 8  40.6       40   4.48        0.693 1091. 11.2 \n 9  40.6       45   4.46        0.703 1087.  9.05\n10  40.6       50   4.44        0.752 1084.  7.30\n# ... with 2,786 more rows\n\n\nBecause of the naming conventions, many of the column names that you import dont make sense. You will often need to change the name of the variable. select() function allows you to accomplish that. For example, we want to select station, pressure and fluoresence, but we need also change the name of station to be Cast, pressure to Depth and fluorescence to Chlorophyll. You can achieve that with code written as;\n\nctd %>% \n  select(Cast = station, \n         Depth = pressure, \n         Chlorophyll = fluorescence)\n\n# A tibble: 2,796 x 3\n   Cast  Depth Chlorophyll\n   <chr> <dbl>       <dbl>\n 1 st1       5       0.560\n 2 st1      10       0.599\n 3 st1      15       0.650\n 4 st1      20       0.678\n 5 st1      25       0.760\n 6 st1      30       0.729\n 7 st1      35       0.740\n 8 st1      40       0.693\n 9 st1      45       0.703\n10 st1      50       0.752\n# ... with 2,786 more rows\n\n\n\nThere are also a number of handy helper functions that you can use with the select() function to filter the returned columns. These include starts_with(), ends_with(), contains(), matches(), and num_range(). I wont illustrate them here, however, you can consult the help document for more information.\n\n\n5.5.1 Adding new variables: mutate, transmute, add_rownames\nBesides selecting sets of existing columns, it’s often useful to add new columns that are functions of existing columns. This is the job of mutate(): Any new variable created with the mutate() function will be added to the end of the data frame. For example, raw fluorescence values are often skewed (Figure 5.1 a) and we often transform them to have normal distribution (Figure 5.1 b).\n\n\n\n\n\nFigure 5.1: ?(caption)\n\n\n\n\nAt this situation, its handy to add a new column with transformed values in the data frame as shown in the code;\n\nctd %>% \n  select(pressure, fluorescence) %>%\n  mutate(log.fluorescence = fluorescence %>% log10())\n\nWarning in fluorescence %>% log10(): NaNs produced\n\n\n# A tibble: 2,796 x 3\n   pressure fluorescence log.fluorescence\n      <dbl>        <dbl>            <dbl>\n 1        5        0.560           -0.251\n 2       10        0.599           -0.223\n 3       15        0.650           -0.187\n 4       20        0.678           -0.169\n 5       25        0.760           -0.119\n 6       30        0.729           -0.138\n 7       35        0.740           -0.131\n 8       40        0.693           -0.159\n 9       45        0.703           -0.153\n10       50        0.752           -0.124\n# ... with 2,786 more rows\n\n\nThe code tells important two steps: the first steps involved selecting the pressure and fluorescence variables, once these variables were selected fromt he ctd data frame were fed into a mutate() function, which computed the logarithmic of fluorescence and assign a new log.fluorescence variable into the data frame.\nIn a similar way above, we can create a new variable of anomaly as the code below shows;\n\nctd %>% \n  select(pressure, fluorescence) %>%\n  mutate(anomaly = fluorescence - mean(fluorescence, na.rm = TRUE))\n\n# A tibble: 2,796 x 3\n   pressure fluorescence anomaly\n      <dbl>        <dbl>   <dbl>\n 1        5        0.560   0.425\n 2       10        0.599   0.464\n 3       15        0.650   0.515\n 4       20        0.678   0.542\n 5       25        0.760   0.624\n 6       30        0.729   0.593\n 7       35        0.740   0.604\n 8       40        0.693   0.557\n 9       45        0.703   0.568\n10       50        0.752   0.617\n# ... with 2,786 more rows\n\n\n\n\n5.5.2 Arranging rows\nThe arrange() function in the dplyr package can be used to order the rows in a data frame. This function accepts a set of columns to order by with the default row ordering being in ascending order.\n\nctd %>% \n  arrange(pressure)\n\n# A tibble: 2,796 x 12\n   station time                  lon    lat pressure temperature salinity oxygen\n   <chr>   <dttm>              <dbl>  <dbl>    <dbl>       <dbl>    <dbl>  <dbl>\n 1 st1     2004-08-18 15:27:46  40.6 -10.5         5        25.2     33.9   3.93\n 2 st2     2004-08-18 17:00:01  40.8 -10.5         5        25.2     34.8   4.47\n 3 st3     2004-08-18 20:32:54  41.0 -10.5         5        NA       NA    NA   \n 4 st4     2004-08-18 22:44:56  41.1 -10.5         5        NA       NA    NA   \n 5 st5     2004-08-19 00:59:59  41.3 -10.5         5        NA       NA    NA   \n 6 st6     2004-08-19 11:49:08  40.3  -8.83        5        25.2     34.9   4.48\n 7 st7     2004-08-19 13:33:31  40.2  -8.83        5        25.3     34.9   4.52\n 8 st8     2004-08-19 15:28:18  40.0  -8.83        5        25.0     34.9   4.59\n 9 st9     2004-08-19 17:39:39  39.8  -8.83        5        25.1     34.9   4.64\n10 st10    2004-08-19 19:36:50  39.7  -8.83        5        NA       NA    NA   \n# ... with 2,786 more rows, and 4 more variables: fluorescence <dbl>,\n#   spar <dbl>, par <dbl>, density <dbl>\n\n\nBy default, it orders numerical values in increasing order, but you can ask for decreasing order using the desc() function:\n\nctd %>% \n  arrange(pressure %>% desc())\n\n# A tibble: 2,796 x 12\n   station time                  lon   lat pressure temperature salinity oxygen\n   <chr>   <dttm>              <dbl> <dbl>    <dbl>       <dbl>    <dbl>  <dbl>\n 1 st3     2004-08-18 20:32:54  41.0 -10.5     1015        6.43     34.8   2.13\n 2 st3     2004-08-18 20:32:54  41.0 -10.5     1010        6.45     34.8   2.13\n 3 st3     2004-08-18 20:32:54  41.0 -10.5     1005        6.45     34.8   2.13\n 4 st3     2004-08-18 20:32:54  41.0 -10.5     1000        6.45     34.8   2.13\n 5 st3     2004-08-18 20:32:54  41.0 -10.5      995        6.46     34.8   2.13\n 6 st3     2004-08-18 20:32:54  41.0 -10.5      990        6.48     34.8   2.13\n 7 st3     2004-08-18 20:32:54  41.0 -10.5      985        6.55     34.8   2.11\n 8 st3     2004-08-18 20:32:54  41.0 -10.5      980        6.60     34.8   2.14\n 9 st3     2004-08-18 20:32:54  41.0 -10.5      975        6.60     34.8   2.17\n10 st3     2004-08-18 20:32:54  41.0 -10.5      970        6.62     34.8   2.17\n# ... with 2,786 more rows, and 4 more variables: fluorescence <dbl>,\n#   spar <dbl>, par <dbl>, density <dbl>"
  },
  {
    "objectID": "dataManipulation.html#summarizing-and-grouping",
    "href": "dataManipulation.html#summarizing-and-grouping",
    "title": "5  Manipulating Data with dplyr",
    "section": "5.6 Summarizing and Grouping",
    "text": "5.6 Summarizing and Grouping\n\n\n\nSummary statistics for a data frame can be produced with the summarise() function. The summarise() function produces a single row of data containing summary statistics from a data frame. For example, you can compute for the mean of fluorescence values:\n\nctd %>% \n  summarise(fl.mean = mean(fluorescence, na.rm = TRUE))\n\n# A tibble: 1 x 1\n  fl.mean\n    <dbl>\n1   0.118\n\n\nBy itself, it’s not that useful until chained with the group_by() verb to compute summary statistics. There you can split the data into different groups and compute the summaries for each group.For example, you can ask for the mean of and standard deviation values of fluorescence for each station in the data frame:\n\nctd %>% group_by(station) %>%\n  summarise(Mean = mean(fluorescence, na.rm = TRUE),\n           STD = sd(fluorescence, na.rm = TRUE))\n\n# A tibble: 5 x 3\n  station   Mean   STD\n  <chr>    <dbl> <dbl>\n1 st1     0.304  0.319\n2 st13    0.0897 0.179\n3 st18    0.101  0.287\n4 st4     0.0970 0.233\n5 st8     0.125  0.381\n\n\nYou can group by one or more variables; you just specify the columns you want to separate into different subsets to the function. It works best when grouping by factors or discrete numbers; there isn’t much fun in grouping by real numbers.\n\nctd %>% group_by(station, lon)%>%\n  summarise(Mean = mean(fluorescence, na.rm = TRUE),\n           STD = sd(fluorescence, na.rm = TRUE))\n\n`summarise()` has grouped output by 'station'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 x 4\n# Groups:   station [5]\n  station   lon   Mean   STD\n  <chr>   <dbl>  <dbl> <dbl>\n1 st1      40.6 0.304  0.319\n2 st13     40.1 0.0897 0.179\n3 st18     39.9 0.101  0.287\n4 st4      41.1 0.0970 0.233\n5 st8      40.0 0.125  0.381\n\n\nsummarise() can be used to count the number of rows in each group with nc()—which just counts how many observations you have in a subset of your data: You only need to parse the argument n() in the summarise()` function as;\n\nctd %>% \n  group_by(station) %>% \n  summarise(frequency = n())\n\n# A tibble: 5 x 2\n  station frequency\n  <chr>       <int>\n1 st1            50\n2 st13          135\n3 st18          163\n4 st4           186\n5 st8           162"
  },
  {
    "objectID": "dataManipulation.html#references",
    "href": "dataManipulation.html#references",
    "title": "5  Manipulating Data with dplyr",
    "section": "References",
    "text": "References\n\n\n\n\nMüller, Kirill, and Hadley Wickham. 2018. Tibble: Simple Data Frames. https://CRAN.R-project.org/package=tibble.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. http://ggplot2.org.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2018. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, and Lionel Henry. 2018. Tidyr: Easily Tidy Data with ’Spread()’ and ’Gather()’ Functions. https://CRAN.R-project.org/package=tidyr.\n\n\nWickham, Hadley, Jim Hester, and Romain Francois. 2017. Readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr."
  },
  {
    "objectID": "plotting.html",
    "href": "plotting.html",
    "title": "6  Plotting in R with ggplot2",
    "section": "",
    "text": "ggplot2 is a package we’ll be using a lot for graphing our education datasets. ggplot2 is designed to build graphs layer by layer, where each layer is a building block for your graph. Making graphs in layers is useful because we can think of building up our graphs in separate parts: the data comes first, then the x-axis and y-axis, and finally other components like text labels and graph shapes. When something goes wrong and your ggplot2 code returns an error, you can learn about what’s happening by removing one layer at a time and running it again until the code works properly. Once you know which line is causing the problem, you can focus on fixing it.\nThe ability to create visualizations—graphical representations of data is an important step to convey your results—information and findings to others. In this chapter, we illustrate how you can use visualize your data and create elegant graphics. One of things that makes R such a great tools is it’s data visualization capabilities. R has many systems for visualization and creating plots, some of which are—base R graphics, lattice and ggplot2, but we focus on the use of ggplot2. The ggplot2 package is a phenomenal tool for creating graphics in R. It provide a unifying framework—a grammar of graphics for describing and building graphs.\nJust as the grammar of language helps you construct meaningful sentences out of words, the Grammar of Graphics helps you construct graphics out of different visual elements. This grammar provides a way to talk about parts of a visual plot: all the circles, lines, arrows, and text that are combined into a diagram for visualizing data. Originally developed by Leland Wilkinson, the Grammar of Graphics was adapted by Hadley Wickham (2016) to describe the components of a plot\nThe ggplot2 package provides a powerful and flexible approach to data visualization, and its is suitable both for rapdi exploration of different visualization approaches and for producing carefully crafted publication–quality figures. However, getting ggplot2 to make figures that look exactly the way you want them to, can sometimes be challenging and beginners and expert alike can get consufed by themes, scales, coords, guides or facets. ggplot2 further organizes these components into layers, where each layer displays a single type of (highly configurable) geometric object.\nEven the most experienced R users need to refer to ggplot2 Cheat Sheet while creating elegant graphics, we will demonstrate step–by–step how to get the most out of ggplot2 package, including how to choose and customize scales, how to theme plots, and when to use add-in packages that extend the ggplot2 capabilities. Some of the extension of ggplot2 that we will introuduce to your include ggspatial (ggspatial?), metR (Campitelli 2019), ggrepel (ggrepel?), cowplot (Wilke 2018), patchwork (patchwork?), etc. Rather than loading these extension packages with require() function, we’ll call their functions using the :: notation. This will help make it clear which funcions are built into ggplot2, and which comes from extensions.\nload addition functions"
  },
  {
    "objectID": "plotting.html#a-dataset",
    "href": "plotting.html#a-dataset",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.1 A dataset",
    "text": "6.1 A dataset\nWe’re using a CTD profile data along the coastal water of Tanzania collected in August 2004 with Algoa. I have processed and cleaned the profile data from a CTD instrument, and created a very basic and simple dataset for us to start with. I have tidy the data into a data frame and it contains 10 variables collected at 22 stations (Table 6.1). These variables include the time, longitude and latitude coordinates and the name at each station. It also contains the measured profile of temperature, salinity, oxygen, and fluorescence, spar, par and density as function of pressure.\n\n\nRows: 2796 Columns: 12\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr   (1): station\ndbl  (10): lon, lat, pressure, temperature, salinity, oxygen, fluorescence, ...\ndttm  (1): time\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nTable 6.1:  A sample of CTD profile dataset. For visibility of all the 22 stations, only variables measured at 5 meter standard depth are shown \n \n\n\nCast Time\nCast Location\nMeasured Variabes\n\n  \n    Station \n    Date \n    Hour \n    Lon \n    Lat \n    Pressure \n    Temperature \n    Salinity \n    Oxygen \n    Fluorescence \n  \n \n\n  \n    st1 \n    2004-08-18 \n    15 \n    40.61 \n    -10.54 \n    5 \n    25.17 \n    33.92 \n    3.93 \n    0.56 \n  \n  \n    st2 \n    2004-08-18 \n    17 \n    40.77 \n    -10.54 \n    5 \n    25.16 \n    34.85 \n    4.47 \n    0.62 \n  \n  \n    st3 \n    2004-08-18 \n    20 \n    40.95 \n    -10.54 \n    5 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    st4 \n    2004-08-18 \n    22 \n    41.12 \n    -10.54 \n    5 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    st5 \n    2004-08-19 \n    0 \n    41.28 \n    -10.54 \n    5 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    st6 \n    2004-08-19 \n    11 \n    40.34 \n    -8.83 \n    5 \n    25.21 \n    34.86 \n    4.48 \n    0.24 \n  \n  \n    st7 \n    2004-08-19 \n    13 \n    40.18 \n    -8.83 \n    5 \n    25.25 \n    34.87 \n    4.52 \n    0.44 \n  \n  \n    st8 \n    2004-08-19 \n    15 \n    40.00 \n    -8.83 \n    5 \n    25.02 \n    34.86 \n    4.59 \n    1.14 \n  \n  \n    st9 \n    2004-08-19 \n    17 \n    39.82 \n    -8.83 \n    5 \n    25.11 \n    34.86 \n    4.64 \n    1.53 \n  \n  \n    st10 \n    2004-08-19 \n    19 \n    39.67 \n    -8.83 \n    5 \n    NA \n    NA \n    NA \n    NA \n  \n  \n    st11 \n    2004-08-22 \n    16 \n    39.60 \n    -9.03 \n    5 \n    25.44 \n    34.91 \n    4.98 \n    1.71 \n  \n  \n    st12 \n    2004-08-23 \n    3 \n    40.26 \n    -7.04 \n    5 \n    25.12 \n    34.87 \n    4.50 \n    0.99 \n  \n  \n    st13 \n    2004-08-23 \n    6 \n    40.10 \n    -7.05 \n    5 \n    25.18 \n    34.87 \n    4.49 \n    0.45 \n  \n  \n    st14 \n    2004-08-23 \n    7 \n    39.93 \n    -7.05 \n    5 \n    25.28 \n    34.88 \n    4.60 \n    0.84 \n  \n  \n    st15 \n    2004-08-23 \n    9 \n    39.76 \n    -7.04 \n    5 \n    25.26 \n    34.89 \n    4.66 \n    1.06 \n  \n  \n    st16 \n    2004-08-23 \n    11 \n    39.59 \n    -7.04 \n    5 \n    25.92 \n    34.88 \n    4.31 \n    0.62 \n  \n  \n    st17 \n    2004-08-23 \n    19 \n    40.07 \n    -5.49 \n    5 \n    25.64 \n    35.19 \n    4.40 \n    0.82 \n  \n  \n    st18 \n    2004-08-23 \n    22 \n    39.90 \n    -5.49 \n    5 \n    25.28 \n    34.90 \n    4.52 \n    0.85 \n  \n  \n    st19 \n    2004-08-24 \n    1 \n    39.56 \n    -5.49 \n    5 \n    25.27 \n    34.90 \n    4.53 \n    0.98 \n  \n  \n    st20 \n    2004-08-24 \n    3 \n    39.40 \n    -5.47 \n    5 \n    25.23 \n    34.89 \n    4.81 \n    1.11 \n  \n  \n    st21 \n    2004-08-24 \n    4 \n    39.24 \n    -5.48 \n    5 \n    25.82 \n    34.93 \n    4.34 \n    0.21 \n  \n  \n    st22 \n    2004-08-24 \n    5 \n    39.10 \n    -5.48 \n    5 \n    26.05 \n    34.95 \n    4.32 \n    0.42 \n  \n\n\n\n\n\n\n\n## make a variable with labelled latitude\nctd = ctd %>% filter(lat > -6) %>% mutate(transect = \"transect 1\", Lat.label = median(lat)) %>%\n  bind_rows(ctd %>% filter(lat > -8 & lat < -6) %>% mutate(transect = \"transect 2\", Lat.label = median(lat)),\n            ctd %>% filter(lat > -10 & lat < -8) %>% mutate(transect = \"transect 3\", Lat.label = median(lat)),\n            ctd %>% filter(lat < -10) %>% mutate(transect = \"transect 4\",  Lat.label = median(lat))) %>%\n  mutate(Lat.label = metR::LatLabel(Lat.label%>% round(2)) %>%as.factor())"
  },
  {
    "objectID": "plotting.html#components-of-ggplot-objects-components",
    "href": "plotting.html#components-of-ggplot-objects-components",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.2 Components of ggplot objects {components}",
    "text": "6.2 Components of ggplot objects {components}\nI have created a simple plot of this data that show scatterplot of temperature versus fluorescence at the four different transects (Figure 6.1). The plot show the concentration of fluorescence against temperature for the twenty one stations along the coastal water of Tanzania.\n\nggplot(data = ctd %>% filter(pressure == 10),\n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  theme(legend.key = element_blank())+\n  scale_colour_discrete(name = \"Transects\")+\n  scale_x_continuous(breaks = seq(25,26,0.25))+\n  scale_y_continuous(breaks = seq(0.2,1.8,.2))+\n  labs(x = expression(Temperature~(degree*C)),\n       y = expression(Fluorescence~(mgm^{-3})), \n       title = \"Association of Temperature and Profile\",\n       subtitle = \"The plot indicat a remarkable sign of transect dependency\", \n       caption = \"Courtesy of IIOE-2\")+\n  coord_cartesian()\n\nWarning: Removed 3 rows containing missing values (geom_point).\n\n\n\n\n\nFigure 6.1: Association of fluorescence concentration per temperature collected in August 2004 standard depth are shown\n\n\n\n\nLet’s explore in details the key elements used to make figure @ref(fig:fig1299):\n\ndata: The data like the one illustrated in table @ref(tab:tabE01). It must be a data frame for ggplot2 read and understand.\naesthetics: is used to map the x and y axis for 2–dimensional plot and add the z value for 3–dimensionla plots. It is also used to define visual properties like color, size, shapes or height etc, and. For instance in the figure @ref(fig:fig1299), the position along the y-axis is mapped to the concentration of fluorescence and the x - axis is mapped to temperature values. For the points, the color is mapped to the geogrphical location along the transects. Other aesthetics—like size, shape, and transparency have been left at their default settings.\ngeometry; a layer which define the type of plot you want to make, whether is histogram, boxplot, barplot, scatterplot, lineplot etc.\ncoordinate system: used to set a limit for the plot. The cartesian coordinate is the most familiar and common system that is widely used to zoom the plot and does not change the underlying data.\nscales: scales allows to customize the plot. For instance in figure @ref(fig:fig1299) both x and y-axis used continuous data and hence the scale_x_continuous() and scale_y_continuous() were used to modiy the values of the axis. For color, I simply stick on scale_colour_discrete() and customize the legend name.\nlabels: The plot is well labelled and easy to understand. It has title, subtitle, axes and caption for the courtesy of the data.\ntheme: the plot stick on the default theme_gray theme, which has a gray background color and white gridlines, a sans serif font family, and a base font size of 11. We can customize all the propoerties in the theme to suit our standard."
  },
  {
    "objectID": "plotting.html#building-a-plot",
    "href": "plotting.html#building-a-plot",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.3 Building a plot",
    "text": "6.3 Building a plot\nSince you now have a clue of the different layers added to create a plot, its time to work around to create a plot with the ggplot2 package. We use the same profile dataset that used to make figure @ref(fig:fig1299). First, you neeed to import the data into your R session.\n\n6.3.1 Plotting layers\nTo create a data visualization using ggplot2 package, we will add layers for each of the plot elements described in section @ref(components). I will take you through step by step of the key ines needed to make such a plot. First make sure the ggplot2 or tidyverse packages are loaded in your R’s session. You can load the package with this code;\n\nrequire(tidyverse)\n\nThe ggplot2 create a ggplot object, and you initialize the object with the ggplot() function\n\nggplot()\n\n\n\n\nThe plot above is black with grey background. This is because we have not specified the data and aesthetic arguments inside the ggplot() function. Let’s specify the data, which in our case is the ctd dataset and also specify the x-axis with temperature and y-axis with fluorescence.\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence))\n\n\n\n\nNow the plot has gridlines and axis with values and labels—x-axis show the value of temperature and the y-axis show the value of fluorescence concentrations. However, there is no graphics. This is because we have not added any geom yet. Therefore, since we have already specified the data and the aesthetic values, now we can add the geom where we map the aesthetics to columns in the dataset. Let’s add the geom_point() and specify the size to 3\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence)) + \n  geom_point(size  = 3)\n\n\n\n\n\n\n6.3.2 Customize legend\nThe plot now show points distributed in the panel plot. But our interest is to color the point at each transect. Next, we add an argument col in the aesthetic that map points that fall along a certain transect with similar color. Since we have a variable called transect in the dataset, we specify this as the code below\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3)\n\n\n\n\nThe plot above show the points are color–coded to refrect the transect in the legend. Note that the colors scheme used in this plot is the default one. Sometimes you will want to customize the aesthetic for all the points in the plot. To change a color scale, you can use the scale_color_viridis_d(). The _d here represent the discrete variable. If you were using the continuous data, you would use scale_color_viridis_c() scheme instead.\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d()\n\n\n\n\nTo change the title of the legend you must specify the name argument in your scale_* function. For instance, we specified scale_colour_viridis_d(name = \"Transects\") to change the legend title for this plot\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d(name = \"Transects\\n of CTD Casts\")\n\n\n\n\nIf you want to remove the legend title, we can add a theme layer and specify theme(legend.title = element_blank())\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d(name = \"Transects\") +\n  theme(legend.title = element_blank())\n\n\n\n\nWe can also change the legend title by specifying theme(legend.title = element_blank())\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d(name = \"Transects\\nof CTD Casts\") +\n  theme(legend.title = element_text(size = 12, colour = \"chocolate\", face = \"bold\"))\n\n\n\n\n\n\n6.3.3 Working with titles and labels\nOften times you need to customize the axis labels. By default, the scale label for each scale is the name of the variable in the dataset. We can change the labels with labs() function. The other elements we would like to add are the plot title and subtitle. If you want to label SI unit in the ggplot, use the expression() function. Note that I used the expression() function to express mathematical symbols in the x and y–axis of the plot.\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d(name = \"Transects\")+\n  labs(x = expression(Temperature~(degree*C)),\n       y = expression(Fluorescence~(mgm^{-3})), \n       title = \"Association of Temperature and Profile\",\n       subtitle = \"The plot indicat a remarkable sign of transect dependency\", \n       caption = \"Courtesy of IIOE-2\")"
  },
  {
    "objectID": "plotting.html#customize-glidline-and-axis-labels",
    "href": "plotting.html#customize-glidline-and-axis-labels",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.4 Customize glidline and axis labels",
    "text": "6.4 Customize glidline and axis labels\nThe other layer that we would like to add to customize our plot are the scale_x_continous(), which change the gridline of the x-axis and the scale_y_continuous(), which change the gridlines of the y-axis.\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d(name = \"Transects\")+\n  labs(x = expression(Temperature~(degree*C)),\n       y = expression(Fluorescence~(mgm^{-3})), \n       title = \"Association of Temperature and Profile\",\n       subtitle = \"The plot indicat a remarkable sign of transect dependency\", \n       caption = \"Courtesy of IIOE-2\")+\n  scale_x_continuous(breaks = seq(25,26,0.25))+\n  scale_y_continuous(breaks = seq(0.2,1.8,.2))\n\n\n\n\n\n6.4.1 Remove the gray box of points on legend\nThe default ggplot always put a gray background of the scatterplot. You can remove it by adding a theme layer and specify the argument legend.key = element_blank() to get rid of them\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d(name = \"Transects\")+\n   labs(x = expression(Temperature~(degree*C)),\n       y = expression(Fluorescence~(mgm^{-3})), \n       title = \"Association of Temperature and Profile\",\n       subtitle = \"The plot indicat a remarkable sign of transect dependency\", \n       caption = \"Courtesy of IIOE-2\")+\n  scale_x_continuous(breaks = seq(25,26,0.25))+\n  scale_y_continuous(breaks = seq(0.2,1.8,.2))+ \n  theme(legend.key = element_blank())"
  },
  {
    "objectID": "plotting.html#modify-the-position-of-the-legend",
    "href": "plotting.html#modify-the-position-of-the-legend",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.5 Modify the position of the legend",
    "text": "6.5 Modify the position of the legend\nBy default, ggplot2 place the legend on the right position. You can decided to place either left, right, top or bottom. For example, if we want to place the legend at the bottom, we simply specifying the argument legend.position = \"bottom\" in the theme layer.\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d(name = \"Transects\")+\n   labs(x = expression(Temperature~(degree*C)),\n       y = expression(Fluorescence~(mgm^{-3})), \n       title = \"Association of Temperature and Profile\",\n       subtitle = \"The plot indicat a remarkable sign of transect dependency\", \n       caption = \"Courtesy of IIOE-2\")+\n  scale_x_continuous(breaks = seq(25,26,0.25))+\n  scale_y_continuous(breaks = seq(0.2,1.8,.2))+ \n  theme(legend.key = element_blank(),\n        legend.position = \"bottom\")\n\n\n\n\nWe can also position the legend insite the plot and specify the x and y coordinates. The coordinates range from 0 to 1, from left to right or bottom to top of the plot. For instance, we can place the legend at the top right corner of the plot by specifying legend.position = c(.9,.75) in the theme layer.\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d(name = \"Transects\")+\n   labs(x = expression(Temperature~(degree*C)),\n       y = expression(Fluorescence~(mgm^{-3})), \n       title = \"Association of Temperature and Profile\",\n       subtitle = \"The plot indicat a remarkable sign of transect dependency\", \n       caption = \"Courtesy of IIOE-2\")+\n  scale_x_continuous(breaks = seq(25,26,0.25))+\n  scale_y_continuous(breaks = seq(0.2,1.8,.2))+ \n  theme(legend.key = element_blank(),\n        legend.position = c(.9,.75))\n\n\n\n\n\n6.5.1 Change the legend background and stroke color\nBy default, ggplot legend has a white fill for background and without color for stroke. We can customize the look of the legend in the theme layer. For example, we want our legend to have an ivory fill and black stroke of 0.25 size. This can be achieved by adding and argumentlegend.background = element_rect(fill = \"ivory\", colour = \"black\", size = .25) in the theme layer.\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d(name = \"Transects\")+\n   labs(x = expression(Temperature~(degree*C)),\n       y = expression(Fluorescence~(mgm^{-3})), \n       title = \"Association of Temperature and Profile\",\n       subtitle = \"The plot indicat a remarkable sign of transect dependency\", \n       caption = \"Courtesy of IIOE-2\")+\n  scale_x_continuous(breaks = seq(25,26,0.25))+\n  scale_y_continuous(breaks = seq(0.2,1.8,.2))+ \n  theme(legend.key = element_blank(),\n        legend.position = c(.9,.75),\n        legend.background = element_rect(fill = \"ivory\", colour = \"black\", size = .25))\n\n\n\n\n\n\n6.5.2 Modify background colors\nYou can remove the background fill and stroke color with the panel.background = element_blank()\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d(name = \"Transects\")+\n   labs(x = expression(Temperature~(degree*C)),\n       y = expression(Fluorescence~(mgm^{-3})), \n       title = \"Association of Temperature and Profile\",\n       subtitle = \"The plot indicat a remarkable sign of transect dependency\", \n       caption = \"Courtesy of IIOE-2\")+\n  scale_x_continuous(breaks = seq(25,26,0.25))+\n  scale_y_continuous(breaks = seq(0.2,1.8,.2))+ \n  theme(legend.key = element_blank(),\n        legend.position = c(.9,.75),\n        legend.background = element_rect(fill = \"ivory\", colour = \"black\", size = .25),\n        panel.background = element_blank())\n\n\n\n\nYou can customize the the background fill and stroke colors to your what fit you best with the panel.background = element_rect() and specify the stroke with color and background with the fill arguments.\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d(name = \"Transects\")+\n   labs(x = expression(Temperature~(degree*C)),\n       y = expression(Fluorescence~(mgm^{-3})), \n       title = \"Association of Temperature and Profile\",\n       subtitle = \"The plot indicat a remarkable sign of transect dependency\", \n       caption = \"Courtesy of IIOE-2\")+\n  scale_x_continuous(breaks = seq(25,26,0.25))+\n  scale_y_continuous(breaks = seq(0.2,1.8,.2))+ \n  theme(legend.key = element_blank(),\n        legend.position = c(.9,.75),\n        legend.background = element_rect(fill = \"ivory\", colour = \"black\", size = .25),\n        panel.background = element_rect(fill = \"lightblue\", colour = \"black\"))\n\n\n\n\n\n\n6.5.3 change the gridlines\nYou can also customize the color and shape of the gridlines. You can remove the gridline with panel.grid = element_blank() argument in the theme layer. But if you want to customize the gridlines, then you use the panel.grid = element_line() and specify the color and linetype etc.\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d(name = \"Transects\")+\n   labs(x = expression(Temperature~(degree*C)),\n       y = expression(Fluorescence~(mgm^{-3})), \n       title = \"Association of Temperature and Profile\",\n       subtitle = \"The plot indicat a remarkable sign of transect dependency\", \n       caption = \"Courtesy of IIOE-2\")+\n  scale_x_continuous(breaks = seq(25,26,0.25))+\n  scale_y_continuous(breaks = seq(0.2,1.8,.2))+ \n  theme(legend.key = element_blank(),\n        legend.position = c(.9,.75),\n        legend.background = element_rect(fill = \"ivory\", colour = \"black\", size = .25),\n        panel.background = element_blank(), \n        panel.grid = element_line(colour = \"grey60\", linetype = \"dotted\", size = .25))\n\n\n\n\n\n\n6.5.4 Change the font size for axis, labels and titles\nThe fonts for axis ticks, axis-title text have a default font size of 11, if we want to increase the font size to 12 then then we can do that inside the theme(). We can also change the font size for titles, subtitles and legend text and title as the chunk below highlight.\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d(name = \"Transects\")+\n   labs(x = expression(Temperature~(degree*C)),\n       y = expression(Fluorescence~(mgm^{-3})), \n       title = \"Association of Temperature and Profile\",\n       subtitle = \"The plot indicat a remarkable sign of transect dependency\", \n       caption = \"Courtesy of IIOE-2\")+\n  scale_x_continuous(breaks = seq(25,26,0.25))+\n  scale_y_continuous(breaks = seq(0.2,1.8,.2))+ \n  theme(legend.key = element_blank(), \n        axis.text = element_text(size = 11), \n        axis.title = element_text(size = 13), \n        plot.subtitle = element_text(size = 12),\n        plot.title = element_text( size = 20), \n        legend.text = element_text(size = 11), \n        legend.title = element_text(size = 12), \n        plot.caption = element_text(size = 11))\n\n\n\n\n\n\n6.5.5 Limit axis to a range\nWe use the coord_cartesian() function to adjust the visible area of the plot. You should specify the range of the ylim=c() and xlim = c() and expand = FALSE to show only the area of the plot you want to visualize.\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d(name = \"Transects\")+\n   labs(x = expression(Temperature~(degree*C)),\n       y = expression(Fluorescence~(mgm^{-3})), \n       title = \"Association of Temperature and Profile\",\n       subtitle = \"The plot indicat a remarkable sign of transect dependency\", \n       caption = \"Courtesy of IIOE-2\")+\n  scale_x_continuous(breaks = seq(25,26,0.25))+\n  scale_y_continuous(breaks = seq(0.2,1.8,.2))+ \n  theme(legend.key = element_blank(), \n        axis.text = element_text(size = 11), \n        axis.title = element_text(size = 13), \n        plot.subtitle = element_text(size = 12),\n        plot.title = element_text( size = 20), \n        legend.text = element_text(size = 11), \n        legend.title = element_text(size = 12), \n        plot.caption = element_text(size = 11)) +\n  coord_cartesian(xlim = c(24.9,26.05), ylim = c(0.1,2), expand = FALSE)\n\n\n\n\n\n\n6.5.6 Adding labels\nggplot2 provide geom_tex() and geom_label function for adding label on the plot. geom_text() adds text directly to the plot. geom_label() draws a rectangle behind the text, making it easier to read.\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) + \n  geom_text(aes(label = station), nudge_x = 0.05, nudge_y = .04)+\n  scale_colour_viridis_d(name = \"Transects\")\n\n\n\n\nI find it difficult to position label with geom_text(), especially when you have a lot of points to label. I often use the ggrepel package, which provides text and label geoms for ggplot2 that help to avoid overlapping text labels. These function makes labels repel away from each other and away from the data points.\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) + \n  ggrepel::geom_text_repel(aes(label = station))+\n  scale_colour_viridis_d(name = \"Transects\")\n\n\n\n\n\n\n6.5.7 Add text annotation\nThere are times you may need to add a text on top of the plot. In ggplot2 you can place a label using the real values on the plot instead of the hard-core coorinates to specify the location based on scaled coordinates where 0 is low and 1 is high. This is useful for adding small annotations (such as text labels) or if you have your data in vectors, and for some reason don’t want to put them in a data frame.\n\nggplot(data = ctd %>% filter(pressure == 10), \n       aes(x = temperature, y = fluorescence, col = transect)) + \n  geom_point(size = 3) +\n  scale_colour_viridis_d(name = \"Transects\")+\n   labs(x = expression(Temperature~(degree*C)),\n       y = expression(Fluorescence~(mgm^{-3})), \n       title = \"Association of Temperature and Profile\",\n       subtitle = \"The plot indicat a remarkable sign of transect dependency\", \n       caption = \"Courtesy of IIOE-2\")+\n  scale_x_continuous(breaks = seq(25,26,0.25))+\n  scale_y_continuous(breaks = seq(0.2,1.8,.2))+ \n  theme(legend.key = element_blank(), \n        axis.text = element_text(size = 11), \n        axis.title = element_text(size = 13), \n        plot.subtitle = element_text(size = 12),\n        plot.title = element_text( size = 20), \n        legend.text = element_text(size = 11), \n        legend.title = element_text(size = 12), \n        plot.caption = element_text(size = 11)) +\n  coord_cartesian(xlim = c(24.9,26.05), ylim = c(0.1,2), expand = FALSE) + \n  annotate(geom = \"text\", x = 25.95 , y = 1.82, label = \"My label\")\n\n\n\n\n\n\n6.5.8 Make the x and y axis the same\nThe coord_cartesian() is the coordinate system that you will use most of the time because most of the plot are created from two or more variables that have different scales. However, there are situations where you create plots that use the same scale of x-and y-coordinates. For example, ploting temperature profiles from two stations, then an appropriate coordinae system in that case is the coord_equal()\n\n## tidy the temperature from long to wide format \nctd.temprature.wide = ctd %>% \n  select(station, temperature, pressure) %>% \n  spread(key = \"station\", value = \"temperature\")\n\n## make aplot\nggplot(data = ctd.temprature.wide, \n       aes(x = st3, y = st8)) + \n  geom_point() + \n  coord_equal() \n\n\n\n\n\n\n6.5.9 Faceting —Creating multi–panel plots\nFacets are ways of arranging plots into multiple different pieces (subplots). This allows you to view a separate plot for each unique value in a categorical variable. The ggplot2 package has a nice function for creating multi-panel plots. The facet_wrap creates essentially a ribbon of plots based on a single variable. For example the plot below, I first filtered only profile below 201 meters and classify them into bins of below 50 meters, 50 to 100 and above 100 meters. This computed depth class was used to make multiple plot of boxplot of fluorescence at the four transects. in the facet_wrap() layer, I specified the ~depth.class to use this variable for faceting and nrow = 1, for the canvas to have one row with multiple columns depending on the groups, four our case we get three columns from the depth classes.\n\n## filter the pressure and break them into class of 50,100,200\nctd.class.depth = ctd %>%\n  filter(pressure < 201) %>% \n  mutate(depth.class = cut(pressure, \n                           breaks = c(0,50,100,200), \n                           labels = c(\"Below 50\", \"50-100\", \"Above 100\"))) \n  \n  \n  ggplot(data = ctd.class.depth, \n         aes(x = transect,y = fluorescence, fill = transect)) + \n    geom_boxplot() + \n    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) + \n    scale_fill_discrete(limits = c(\"transect 1\", \"transect 2\", \"transect 3\", \"transect 4\"), \n                        labels = c(\"Pemba\", \"Kimbiji\", \"Lindi\", \"Mtwara\")) +\n    labs(x = NULL, y = expression(Fluorescence~(mgm^{-3})))+ \n    facet_wrap(~depth.class, nrow = 1) \n\n\n\n\nFigure 6.2: ?(caption)\n\n\n\n\n\n\n6.5.10 Allow scales to roam free (scales)\nThe default for multi-panel plots in ggplot2 is to use equivalent scales in each panel. But sometimes you want to allow a panel’s own data to determine the scale. This may mislead to the audience since it give creaes plots with different scales. You can specify the scales=\"free\" in the facet_wrap() layer written as;\n\n## filter the pressure and break them into class of 50,100,200\nctd.class.depth = ctd %>%\n  filter(pressure < 201) %>% \n  mutate(depth.class = cut(pressure, \n                           breaks = c(0,50,100,200), \n                           labels = c(\"Below 50\", \"50-100\", \"Above 100\"))) \n  \n  \n  ggplot(data = ctd.class.depth, \n         aes(x = transect,y = fluorescence, fill = transect)) + \n    geom_boxplot() + \n    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) + \n    scale_fill_discrete(limits = c(\"transect 1\", \"transect 2\", \"transect 3\", \"transect 4\"), \n                        labels = c(\"Pemba\", \"Kimbiji\", \"Lindi\", \"Mtwara\")) +\n    labs(x = NULL, y = expression(Fluorescence~(mgm^{-3})))+ \n    facet_wrap(~depth.class, nrow = 1, scales = \"free_y\") \n\n\n\n\nFigure 6.3: ?(caption)"
  },
  {
    "objectID": "plotting.html#basic-plots",
    "href": "plotting.html#basic-plots",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.6 Basic plots",
    "text": "6.6 Basic plots\nThe ggplot2 package provides a set of functions that mirror the Grammar of Graphics, enabling you to efficaciously specify what you want a plot to look like. To have a glimpse of ggplot2, we start with five basic types of plots that are familiar to most people. These include:\n\nscatterplot\nlinegraphs\nboxplots\nhistograms\nbarplots\n\n\nNote that the four graphs works with quantitative data and barplots are appropriate for categorical data. Thus, understanding the type of data you want to plot is a fundamental principle before you throw the variable into ggplot2 to make plot for you.\n\n\n6.6.1 scatterplot\nScatterplots are also called bivariate, allows you to visualize the association between two numerical variables. They are among the widely used plot because they can provide an immediate way to see the pattern of association between two numerical variables.\n\n\n\n\n\nscatterplot from base R\n\n\n\n\nMost of us are familiar with scatterplot shown in figure  and made several of them using base R, but probably you have not made one based on the fundamental theorem of grammar of graphics. We will visualize the relationship between temperature and fluorescence. Because the ctd is profile data frame with variable as function of pressure, we want to check for the association of all the 22 station but at fixed depth of 10 meters. What this means is that we will take the ctd data and filter all variable at all station measured at water depth of 10 meters from the surface and save this in a new data frame called ctd10d. This can be written as:\n\nctd10d = ctd %>% \n  filter(pressure == 10)\n\nLet’s now dive into the code of using the *grammar of graphics to create the scatterplot. We use the ggplot() function from ggplot2** package. The code to create figure @ref(fig:) is written as;\n\nggplot(data = ctd10d,\n       aes(x = temperature, y = fluorescence)) + \n  geom_point() \n\nLet’s explore the block above piece-by-piece\n\nThe plotting in ggplot2 begin with ggplot() function, where the two components of grammar of graphics are required. in the data component we specify the data frame of variables measured at 10 meter water below the surface by setting data = ctd10d. Then the second argument aesthetic that map the plot with coordinate was set by aes(x = temperature, y = fluorescence)). In a nutshell, the aes() define the variable–axis specifications. For the code above we set the variables temperature into the x coordinate and the variable fluorescence into the y-axis.\nWe then add a layer to the ggplot() function calll using the + sign. The added layer specify the third part of the *grammar—the geometric component. Becasue we want to plot scatterplot, the appropriate geom for this case is the geom_point().\n\n\n\nWarning: Removed 3 rows containing missing values (geom_point).\n\n\n\n\n\nScatterplot showing the association between temperature and fluorescence at 10 meter water from the surface\n\n\n\n\nOnce the code is run, it produce two outputs: a warning message and figure @ref(fig:). The warning message notify us that out of the 22 stations, there are three stations with missing data at 10 meter water. We can check station with missing values with code written below;\n\nctd10d %>% \n  filter(is.na(temperature)) %>% \n  select(station, pressure, temperature, fluorescence)\n\n# A tibble: 3 x 4\n  station pressure temperature fluorescence\n  <chr>      <dbl>       <dbl>        <dbl>\n1 st10          10          NA           NA\n2 st4           10          NA           NA\n3 st5           10          NA           NA\n\n\n\n\n6.6.2 adding regression line\nyou can simply add the regression line by addign a geom_smooth() layer and specify the method = \"lm\" and we dont need to show the confidence errors, hence we specify se = FALSE\n\nggplot(data = ctd10d,\n       aes(x = temperature, y = fluorescence)) + \n  geom_point()  +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\nWhile the geom_point() and geom_smooth() layers in this code both use the same aesthetic mappings, there’s no reason you couldn’t assign different aesthetic mappings to each geometry. Note that if the layers do share some aesthetic mappings, you can specify those as an argument to the ggplot() function\nLooking on the generated scatterplot (Figure @ref(fig:)), we notice a negative relation exist between temperature and fluorescence—stations with high temperature have relatively low concentration of fluorescence and viceversa. We also notice that 16 stations are clustered within \\(25-25.25^{\\circ}\\) C and only three are found at temperature range between \\(25.75-26^{\\circ}\\) C. We can identify these pattern by adding a col argument in aes by setting aes(x = temperature, y = fluorescence, col = Lat.label)). The code for creating figure @ref(fig:) is written as;\n\nggplot(data = ctd10d,\n       aes(x = temperature, y = fluorescence, col = Lat.label)) + \n  geom_point() \n\n\n\n\n\n\n\n\n\nLooking on the color of thelegend, it clearly indicate the two stations with temperatur above \\(25.75^{\\circ}\\) C are found along the transect lies along latitude 5.49°S in Pemba Channel and and one at latitde7.04°S off the Kimbiji.\nWe may also be interested to knwo whether dissolved oxygen has influrence on the the association of temperature and fluoresce. We can achieve that by simply parsing the the shape = oxygen, arguments into the aesthetic component. Figure @ref(fig:) clearly shows the stations with relatively high chlorophyll value have bigger shape (high DO value) and found in relatively less warmer waters in contrast to stations with low chl-value have smaller shape size, indicating low DO and found in relatively warmer water. The chunk for making figure @ref(fig:) is written as:\n\nggplot(data = ctd10d,\n       aes(x = temperature, y = fluorescence, size = oxygen)) + \n  geom_point() \n\nWarning: Removed 3 rows containing missing values (geom_point).\n\n\n\n\n\n\n\nWarning: Removed 3 rows containing missing values (geom_point).\n\n\n\n\n\nScatterplot showing the association between temperature and fluorescence at 10 meter water from the surface and the influence of dissolved oxygen"
  },
  {
    "objectID": "plotting.html#linegraph",
    "href": "plotting.html#linegraph",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.7 Linegraph",
    "text": "6.7 Linegraph\n\n# I donwloaded the data using the code below and save it into the project directory. This chunk will never run but rather the proceeding step will use the data that was downloade and processed with code in this chunk.\nresult = xtractomatic::searchData(\"datasetname:mday\")\n\n##  sst, Aqua MODIS, NPP, L3SMI, Global,0.041, Science Quality (Monthly Composite)\nxtractomatic::getInfo(dtype = \"mhsstdmday\")\n##  Chlorophyll-a, Aqua MODIS, NPP, L3SMI, Global,0.041, Science Quality (Monthly Composite)\nxtractomatic::getInfo(dtype = \"mhchlamday\")\n\n\nsst = xtractomatic::xtracto_3D(dtype = \"mhsstdmday\", \n                               xpos = c(38.79272,40.24292), \n                               ypos = c(-5.692232,-5.451759), \n                               tpos = c(\"2014-11-02\", \"2019-04-16\"))\n\nchl = xtractomatic::xtracto_3D(dtype = \"mhchlamday\", \n                               xpos = c(38.79272, 40.24292), \n                               ypos = c(-5.692232, -5.451759), \n                               tpos = c(\"2003-01-17\", \"2019-04-16\"))\n\nThe next basic graph of ggplot2 is the linegraph. Linegraphs is similar to drawing points, except that it conncets the points with line. often times you dont show the points. Linegraphs are commonly used to show time series data. Its inappropriate to use the linegraphs for data that has no clear sequential ordering . Let’s illustrate how to create linegraphs using another dataset ofchlorophyll concentration in the Pemba channel. This is a monthly average data from MODIS satellite. I processed the data and stored them in .RData format. We can load this dataset from the working directory with the load() function as shown in the chunk below;\n\nload(\"assets/modis_pemba.RData\")\n\nExploring further the dataset, we notice that its an array with 35 longitude spacing and 7 latitude spacing and 196 matrix collected every month from 2003-01-16 to 2019-04-16. Being an array, this dataset is not in the right format, since ggplot2 only accept the data frame format.\n\nchl$data %>% class();chl$data %>% dim()\n\n[1] \"array\"\n\n\n[1]  35   7 196\n\n\nTherefore, we need to tidy this dataset from the array into the data frame and find average chlorophyll concentration for each month for 196 months. Because there are 196 matrix, that is a lot of work to do it one after the other. The easiest solution is to loop the process with a for loop. If you are not familiar with how loop works in R, I suggest you check section__ of chapter__, which describe in details. The chunk below highlight the for loop used to convert an array to matrix\n\n## preallocate object\nsst.tb = list()\nchl.tb = list()\n\n## loop sst\nfor (i in 1:length(sst$time)){\n  \n  sst.tb[[i]] = matrix_tb(x = sst$longitude, \n                          y = sst$latitude, \n                          data = sst$data[,,i]) %>% \n    mutate(time = sst$time[i] %>%as.Date()) %>%  \n    select(date = time,lon = x, lat = y, sst = value) \n}\n\n## loop chl\nfor (j in 1:length(chl$time)){\n  chl.tb[[j]] = matrix_tb(x = chl$longitude, \n                          y = chl$latitude, \n                          data = chl$data[,,j]) %>% \n    mutate(time = chl$time[j] %>%as.Date()) %>% \n    select(date = time,lon = x, lat = y, chl = value) \n}\n## unlist the listed sst and chl files\nsst.tb = sst.tb %>% bind_rows(sst.tb)\nchl.tb = chl.tb %>% bind_rows(chl.tb)\n\nWe then used the function in lubridate::year() and lubridate::month() to create the year and month variables from the date variables\n\nchl.decompose = chl.tb %>% \n  mutate(month = lubridate::month(date, label = TRUE, abb = TRUE), \n         year = lubridate::year(date) %>% as.integer()) \n\nTo make a plot of annual average of chlorophyll concentration in the Pemba Channel, we need to monthly mean. We exclude data for year 2003 and 2019 because there only seven months in 2003 and four months in 2019, which can affect the analysis. computing annual average can be written as;\n\nchl.yearly = chl.decompose %>% \n  filter( year >= 2003 & year <= 2018)%>%\n  group_by(year) %>% \n  summarise(chl = mean(chl, na.rm = TRUE))\n\nLet’s create linegraph of annual average chlorophyll-a concentration in the Pemba Channel. Like the scatterplot we made earlier, where supply the data frame in data argument and specified the aesthetic mapping with x and y cooridnates, but instead of using geom_point(), we use the geom_line(). The code to make the line graphy of annual average chlorophyll-a conceration shown in figure @ref(fig:) are written as;\n\nggplot(data = chl.yearly, \n       aes(x = year, y = chl))+\n  geom_line()\n\n\n\n\n\n\nSince the selected area is affected with monsoon season, we can further decode the months into their respective southeast (SE) and northeast (NE) and inter-monsoon (IN) seasons using the decode() function from dplyr package as the chunk below show;\n\nchl.season = chl.decompose %>% \n  mutate(season = month %>% as.character(), \n         season = recode(.x = season, Jan = \"NE\"),\n         season = recode(.x = season, Feb = \"NE\"),\n         season = recode(.x = season, Mar = \"NE\"),\n         season = recode(.x = season, Apr = \"IN\"),\n         season = recode(.x = season, May = \"SE\"),\n         season = recode(.x = season, Jun = \"SE\"),\n         season = recode(.x = season, Jul = \"SE\"),\n         season = recode(.x = season, Aug = \"SE\"),\n         season = recode(.x = season, Sep = \"SE\"),\n         season = recode(.x = season, Oct = \"IN\"),\n         season = recode(.x = season, Nov = \"NE\"),\n         season = recode(.x = season, Dec = \"NE\"))\n\nWe then compute the year average of chlorophyll-a at each season as written in the chunk below\n\nchl.season = chl.season %>% \n  filter( year >= 2003 & year < 2019)%>%\n  group_by(year,season) %>% \n  summarise(chl = mean(chl, na.rm = TRUE))\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\n\nTo make a linegraphy that show annual average of chlorophyll-a concetration for each season as in figure @ref(fig:), we simply parse the argument col == season in the aes() component as the chunk below hightlight\n\nggplot(data = chl.season, \n       aes(x = year, y = chl, col = season))+\n  geom_line()+\n  scale_x_continuous(breaks = seq(2002,2019,2))\n\n\n\n\n\n\n\n\n\n\n6.7.1 histogram\nA histogram is a plot that can be used to examine the shape and spread of continuous data. It looks very similar to a bar graph and organized in intervals or classes. . It divides the range of the data into bin equal intervals (also called bins or classes), count the number of observations n in each bin, and display the frequency distribution of observations as a bar plot. Such histogram plots provide valuable information on the characteristics of the data, such as the central tendency, the dispersion and the general shape of the distribution.\nLet’s consider the chl variable in the chl.tb data frame. Since histogram works for single variable that contains quantitative values, you can not bother looking for relationship as we have seen in previous plots, but histogram offers an opportunity to answer question like\n\nWhat are the smallest and largest values of chl-a?\nWhat is the center value? 3 How does these values spread out?\n\nWe can make a histogram shown in figure @ref(fig:) by simply setting aes(x = chl) and add geom_histogram(). Within the geom_histogram(), we simply specify the number of bins bins = 28 and also the color seprating each column of the histogram with col == \"white\". The code to create figure @ref(fig:), which displays a histogram with twenty eight classes, is written as;\n\nggplot(data = chl.decompose %>% filter(chl < .5), \n       aes(x = chl))+\n  geom_histogram(bins = 28, col = \"white\")\n\n\n\n\n\n\nHistogram showing the distribution of chlorophyll concentration\n\n\n\n\n\n\n6.7.2 boxplot\nThe box plot is a standardized way of displaying the distribution of data based on the five number summary: minimum, first quartile, median, third quartile, and maximum. Box plots are useful for detecting outliers and for comparing distributions. These five number summary also called the 25th percentile, median, and 75th percentile of the quantitative data. The whisker (vertical lines) capture reoungly 99% of a distribution, and observaion outside this range are plottted as points representing outliers.\nBox plots can be created by using the geom_boxplot() function and specify the data variable.\n\nggplot(data = chl.decompose %>% \n         filter( chl <  .25), aes(y = chl))+\n  geom_boxplot()\n\n\n\n\nThe firstinput must be a categorical variable and the second must be a continuous variable.\n\nggplot(data = chl.season %>% \n         filter( chl <  .25), aes(x = season, y = chl))+\n  geom_boxplot()\n\n\n\n\nthe geom_boxplot() has outlier_ arguments that allows to highlight and modify the color, shape, size, alpha … etc of outliers —extreme observation. For instance, you can highlight the outlier with;\n\nggplot(data = chl.season %>% \n         filter( chl <  .25), aes(x = season, y = chl))+\n  geom_boxplot( outlier.colour = \"red\", outlier.shape = 8, outlier.size = 4)\n\n\n\n\n\n\n\nWe can also map the fill and color to variable in to distinguish boxplot. for example, we can specify the fill = season argument in the aes() to fill the boxplot based on season.\n\nggplot(data = sst.season , \n       aes(x = month, y = sst, fill = season))+\n  geom_boxplot( outlier.colour = \"black\", outlier.shape = 8, outlier.size =1.2)+\n  scale_fill_manual(values = c(4,2,3))\n\n\n\n\nWe can add the points on top of the boxplot with the geom_jitter(). It also allows for specifying other arguments like colors and width of the points.\n\nggplot(data = chl.season %>% \n         filter( chl <  .25), aes(x = season, y = chl))+\n  geom_boxplot()+\n  geom_jitter(width = .05, height = .05, col = \"blue\")\n\n\n\n\n\n\n6.7.3 barplot\nBar graphs are perhaps the widely used plot. They are typically used to display numeric values on the y-axis for different groups on the x-axis. There is an important distiction you should be aware of when making bar graphs. The heigh of a bar in barplot may represent either the counts or values of elements in the dataset. Let’s begin with the former—count. We use the drifter observations, which passed at the confluence—where the South Equatorial Current splits to form the northward flowing called the East Africa Coastal Current and the southward flowing the Mozambique Current. We first load the daset as the code highlight;\n\n\n\n\ndrifter_confluence = read_csv(\"assets//drifter_confluence.csv\")\n\n\n6.7.3.1 barplot for count\nTo make the bar graph that show the number of drifters crossed the ares per month over the entire period you you simply specify the the variable month in the x coordinates in the aesthetic and add the geom_bar()\n\ndrifter_confluence %>% \nggplot( \n       aes(x = month)) +\n  geom_bar()\n\n\n\n\nSometimes you may wish to stack bars. For instance drifter have drogued—an anchor, which reduce speed of the drifter wind effect. When the drogue is lost, drifter slip and tend to overestimate the current speed. In our dataset, the drogue are coded with 0 == Absent, and 1 = Present. Because zero and ones make no sense, we create a new variables of that replace zero with LOST and ones with PRESENT. we use the if_else() function from dplyr to convert these values and assign the object as drifter.drogue. The conversion can be attained with code written as;\n\ndrifter.drouge = drifter_confluence %>% \n  mutate(drogue.status = if_else(condition = drogue==1, true = \"PRESENT\", false = \"LOST\"))\n\nThen to stack the bar based on the drogue status, we simpy add the fill = drogue.status in aes() part\n\nggplot(data = drifter.drouge, \n       aes(x = month, fill = drogue.status))+\n  geom_bar()\n\n\n\n\nYou can flip the order of bar with position = position_stack(reverse = TRUE)\n\nggplot(data = drifter.drouge, \n       aes(x = month, fill = drogue.status))+\n  geom_bar(position = position_stack(reverse = TRUE))\n\n\n\n\nInstead of stacking, you can dodge the bar with position = position_dodge() argument\n\nggplot(data = drifter.drouge, \n       aes(x = month, fill = drogue.status))+\n  geom_bar(position = position_dodge())\n\n\n\n\nTo add a black stroke color of the bar, add the argument col = \"black\" inside the geom_bar()\n\nggplot(data = drifter.drouge, \n       aes(x = month, fill = drogue.status))+\n  geom_bar(position = position_dodge(), col = \"black\")\n\n\n\n\nAnd to specify the width of the bar you specify a value in width argument in geom_bar()\n\nggplot(data = drifter.drouge, \n       aes(x = month, fill = drogue.status))+\n  geom_bar(position = position_dodge(), col = \"black\", width = .75)\n\n\n\n\nSometimes you want to map bar with different colors for negative and positive values. For this case we will use the sea surface temperature from drifter observation and create a new variable called anomaly—indicate the temperature value above (positive value) and below (negative) the climatological mean. The code for computing anomaly is;\n\nsst.anomaly = drifter_confluence %>% \n  group_by(year) %>% \n  summarise(average = mean(sst, na.rm = TRUE)) %>%\n  mutate(anomaly = average - mean(average), \n         anomaly.status = if_else(anomaly > 0 , \"Above\", \"Below\")) %>%\n  filter(year > 1996)\n\nonce we have computed the anomaly of sea surface temperature for each year, we can plot the withe geom_col() and specify x = year, and y = anomaly and fill = anomaly.status. We also need to specify the position == \"identity\" to prevent notification message of poor defined stacking for bar with negative values.\n\n  ggplot(data =sst.anomaly,\n         aes(x = year, y = anomaly, fill = anomaly.status)) +\n  geom_col(position = \"identity\", width = .8)\n\n\n\n\nAlthough the plot looks good but sometimes we may wish to reverse the filled color.We can reorder the color with the scale layer. Because the variable used to fill the bar is categorical, the appropriate scale is scale_fill_discrete() and you specify the limits with limits =  c(\"Below\", \"Above\"). The legend is this plot is not important and we can remove from th plot with guides(fill = FALSE)\n\n  ggplot(data =sst.anomaly,\n         aes(x = year, y = anomaly, fill = anomaly.status)) +\n  geom_col(position = \"identity\", width = .8)+\n  scale_fill_discrete(limits = c(\"Below\", \"Above\"))+\n  guides(fill = FALSE)\n\nWarning: `guides(<scale> = FALSE)` is deprecated. Please use `guides(<scale> =\n\"none\")` instead.\n\n\n\n\n\nThe red\n\n\n\n6.7.4 barplot for values\nWe have seen how to make barplot that show the count with geom_bar(). You can also use the barplot to show the values with the geom_col() function and specify what variables you want on the x and y axis. For instance, we want to show how surface current varies over twelve months. Because the geom_col() requires summarized statistics, we need to compute the average current speed for each month. The chunk below highlight how to compute the mean, maximum, minimum and standard deviation of surface current velocity for each month.\n\ncurrent.speed.monthly = drifter.drouge %>% \n  filter() %>% mutate(speed = sqrt(u^2 + v^2)) %>% \n  group_by(month, drogue.status) %>% \n  summarise(speed_min = min(speed, na.rm = TRUE),\n            speed_mean = mean(speed, na.rm = TRUE),\n            speed_max = max(speed, na.rm = TRUE), \n            speed_sd = sd(speed, na.rm = TRUE)) %>%\n  ungroup()\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument.\n\n\nOnce we have computed the statistics, we can use them to make barplot. Note that unlike the geom_bar() that need only the x variable, geom_col() requires x and y variables specified. For illustration, we specified the x = month, and y = speed_mean in the aes() to make a barplot that show the monthly monthly mean surface current.\n\nggplot(data = current.speed.monthly, \n       aes(x = month,y = speed_mean))+\n  geom_col()\n\n\n\n\nAlthough ggplot2 allows to stack the barplot that present values, although they seems appealing, you must avoid making such kind of plot, because they tend to mislead and difficult to distinguish betwen the groups.\n\nggplot(data = current.speed.monthly, \n       aes(x = month,y = speed_max, fill = drogue.status))+\n  geom_col()\n\n\n\n\nThe appropriate way if you want to compare two or more groups with geom_col(), you better doge the bar instead of stacking them. This makes easier to compare. For instance, in the case here, its cleary to see months of which drifter with lost drogues move relatively faster than those with droguue.\n\nggplot(data = current.speed.monthly, \n       aes(x = month,y = speed_max, fill = drogue.status))+\n  geom_col(position = position_dodge())\n\n\n\n\nNote: the basic barplot that present count or frequency has one categorical variable on the x axis and you can make with geom_bar()And the barplot that present the values for instance the average of the variable has one categorical variable on the x axis and continuos variable on the y axis and you create them with geom_col() function. You can make a grouped bar plot by mapping that variable to fill, which represent the fill color of the bars. Like the variables mapped to the x axis, variables that are specified to the fill color of bars must be categorical instead of continuous.\n\ndrifter.interest = drifter_confluence %>% group_by(id) %>% summarise(count = n(), begin = dplyr::first(date), end = dplyr::last(date), period = lubridate::interval(start = begin, end = end, tzone = \"\") %>% lubridate::as.duration() %>% as.numeric(\"hours\")) %>% filter(period >1000)\n\ndrifter.interest.point = drifter.interest %>% left_join(drifter_confluence, by = \"id\") %>% mutate(id.drifter = paste(\"ids\", id, sep = \"\"))\n\nggplot(data = drifter.interest.point , aes(x = lon, y = lat, col = id.drifter))+geom_path()+geom_point()+\n  metR::scale_x_longitude(ticks = .3)+\n  metR::scale_y_latitude(ticks = .4)"
  },
  {
    "objectID": "plotting.html#advanced-plots",
    "href": "plotting.html#advanced-plots",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.8 Advanced plots",
    "text": "6.8 Advanced plots\nggplot2 with its add-in packages provides extensive capabilities for visualizing your data. You can produce 2D plots, 3D plots, and animations; you can view images; and you can create histograms, contour and surfaces plots, and other graphical representations of your data.\nits’s fun to explore pattern over time with linegraphy. Time is so embedded in our day–to–day life tha so many aspects of visualizing temporal data are fairly intuitive. You understand thing changing and evolving—the hard part is figuring out by how much is changing and look for that change in the graph. It’s easy to glance over some lines on a plot and say something is increasing, which is good as that is the core function of visualization to help you see the patterns. But, because of averaging, we sometimes miss some subtle changes that hidden when we lumped data together.\n\nchl.tb %>% \n  mutate(month = lubridate::month(date), year = lubridate::year(date)) %>% \n  group_by(year, month) %>% \n  summarise(chl = mean(chl, na.rm = TRUE))%>%\n  filter(year < 2019) %$%\n  interpolate2(x = year , y = month, z = chl, n = 16)%>%\n  rename(year = x, month = y, chl = z) %>%\n  filter(chl < .4)%>% \n  ggplot(aes(x =year, y = month, z = chl))+\n  metR::geom_contour_fill(na.fill = TRUE, bins = 20)+\n  scale_fill_gradientn(colours = oce::oce.colorsJet(n = 120))+\n  scale_y_reverse(breaks = 1:12, \n                  label = seq(lubridate::dmy(010119), \n                              lubridate::dmy(311219), by = \"month\") %>% \n                    lubridate::month(abbr = TRUE, label = TRUE))+\n  scale_x_continuous(breaks = seq(2002,2017,2))+\n  coord_cartesian(expand = FALSE)+\n  labs(x = NULL, y = NULL)+\n  theme_bw()%+%\n  theme(axis.text = element_text(size = 11, colour = \"black\"))+\n  guides(fill = guide_colorbar(raster = FALSE, barheight = 15, barwidth = 1.1, \n                               title.theme = element_text(angle = 90, size = 13), \n                               title.position = \"right\", title.hjust = .5,\n                               label.theme = element_text(size = 10),\n                               title = expression(Chlorophyll~concetration~(mgm^{-3}))))\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\nLoading required package: metR\nAttaching package: 'metR'\nThe following object is masked from 'package:purrr':\n\ncross\n\n\n\n\n\nI used oce::oce.colorsJet(120) and specify 120 color gradient to obtain color scheme similar to the Matlab Jet scheme. It widely used for maps but works great for general visualization like heatmaps.\n\n6.8.1 Facets\nSometimes you may wish to split your plot into facets—subplots that each display one subset of the data. Faceting is used when you wish make subplots from categorical variables. It creates multiple copies of the same type of plot with matching x and y axes. There is a scale(), which allows you to adjust the x and y axes according to groups in the categorical variable.\n\n## list files from the working directory\n\ntafiri = list.files(path = \"assets//\",pattern = \"tafiri_\", full.names = TRUE, recursive = TRUE)\n\n## make a vector of variables. The order must be consistency with the files order in \nvar = c(\"chl\", \"pp\", \"sst\")\n## make a vector of site. The order must be consistency with the sheets in files\nsites = c(\"Pemba\", \"Zanzibar\", \"Mafia\", \"EEZ\")\n\n## preallocate an empty object\ntafiri.data = NULL\n\nfor (i in 1:length(var)){\n  for (j in 1:length(sites)){\n    \n  data = readxl::read_excel(path = tafiri[i], sheet = j)%>% \n  rename(date = 1, year = 2, value = 3) %>% \n  mutate(month = lubridate::month(date), \n         day = 15,\n         site = sites[j], \n         variable = var[i],\n         date = lubridate::make_date(year = year, month = month, day = day)) %>%\n  arrange(date)\n    \n## stitch processed data frame from each sheet    \ntafiri.data = tafiri.data %>% \n  bind_rows(data)\n \n  }\n}\n\nFor instance, suppose we’re interested in looking at how the hovmoller of monthly primary productivity varies over time across the four stations, We split this heatmaps by the four stations. We achieve this by simply adding facet_wrap(~site, nrow = 2) layer;\n\nggplot()+\n  metR::geom_contour_fill(data = tafiri.data %>% filter(variable == \"pp\"),\n                          aes(x = year, y = month, z = value), na.fill = TRUE, bins = 20)+\n  coord_cartesian(expand = FALSE)+\n  scale_y_reverse(breaks = seq(2,11,2), label = c(\"February\", \"April\", \"June\", \"August\", \"October\"))+\n  scale_x_continuous(breaks = seq(2004,2017,4))+\n  scale_fill_gradientn(colors = oce::oce.colors9A(120), breaks = seq(400,1600,200))+\n  theme_bw() %+replace%\n  theme(axis.text = element_text(size = 12, colour = 1))+\n  guides(fill = guide_colorbar(title = expression(mgm^{-3}),\n                               title.position = \"top\", \n                               title.hjust = 0.5, \n                               direction = \"vertical\",\n                               reverse = FALSE, \n                               barwidth = unit(.4, \"cm\"),\n                               barheight = unit(4, \"cm\")))+\n  labs(x = NULL, y = NULL)+\n  guides(fill = guide_colorbar(raster = FALSE, barheight = 15, barwidth = 1.1, \n                               title.theme = element_text(angle = 90, size = 13), \n                               title.position = \"right\", title.hjust = .5,\n                               label.theme = element_text(size = 10),\n                               title = expression(Primary~Productivity~(Cm^{-3}~yr^{-1}))))+\n  facet_wrap(~site, nrow = 2)\n\n\n\n\nNote the use of the tilde ~ before the site in facet_wrap(). The tilde is required when you want specify the variable that will be used to split the plots into subplots. We can add other arguments in the facet_wrap() function. Let say we want our plot to be in one rows and four columns by simply adding the argument nrow = 1\n\n\n6.8.2 Sea Surface Temperature\n\nggplot()+\n  metR::geom_contour_fill(data = tafiri.data %>% filter(variable == \"sst\"),\n                          aes(x = year, y = month, z = value), na.fill = TRUE, bins = 20)+\n  coord_cartesian(expand = FALSE)+\n  scale_y_reverse(breaks = seq(2,11,2), label = c(\"February\", \"April\", \"June\", \"August\", \"October\"))+\n  scale_x_continuous(breaks = seq(2004,2017,4))+\n  scale_fill_gradientn(colors = oce::oce.colors9A(120))+\n  theme_bw() %+replace%\n  theme(axis.text = element_text(size = 11, colour = 1), axis.title = element_blank())+\n  guides(fill = guide_colorbar(title = expression(mgm^{-3}),\n                               title.position = \"top\", \n                               title.hjust = 0.5, \n                               direction = \"vertical\",\n                               reverse = FALSE, \n                               barwidth = unit(.4, \"cm\"),\n                               barheight = unit(4, \"cm\")))+\n  guides(fill = guide_colorbar(raster = FALSE, barheight = 10, barwidth = 1.1, \n                               title.theme = element_text(angle = 90, size = 13), \n                               title.position = \"right\", title.hjust = .5,\n                               label.theme = element_text(size = 10),\n                               title = expression(Sea~Surface~Temperature~(degree*C))))+\n  facet_wrap(~site, nrow = 1)\n\n\n\n\n\n\n6.8.3 Subplot\nThere are occasions when it is convenient to display several plots side-by-side. In these instances, you will want to use the cowplot package. we first create ggplot2 object of Primary productivity for the channels we are interested: for Mafia Channel we assign the name mafia.pp and for Zanzibar Channel zanzibar.pp. The chunk below show how to create the these object.\n\nmafia.pp = ggplot()+\n  metR::geom_contour_fill(data = tafiri.data %>% filter(variable == \"pp\" & site == \"Mafia\"),\n                          aes(x = year, y = month, z = value), na.fill = TRUE, bins = 20)+\n  coord_cartesian(expand = FALSE)+\n  scale_y_reverse(breaks = 1:12, label = seq(lubridate::dmy(010119), \n                                            lubridate::dmy(311219), by = \"month\") %>% \n                    lubridate::month(abbr = TRUE, label = TRUE))+ \n  scale_x_continuous(breaks = seq(2004,2017,4))+\n  scale_fill_gradientn(colors = oce::oce.colors9A(120),limits = c(300,1700), breaks = seq(400,1600,200))+\n  theme_bw() %+replace%\n  theme(axis.text = element_text(size = 12, colour = 1), legend.position = \"none\")+\n  guides(fill = guide_colorbar(title = expression(mgm^{-3}),\n                               title.position = \"top\", \n                               title.hjust = 0.5, \n                               direction = \"vertical\",\n                               reverse = FALSE, \n                               barwidth = unit(.4, \"cm\"),\n                               barheight = unit(4, \"cm\")))+\n  labs(x = NULL, y = NULL)+\n  guides(fill = guide_colorbar(raster = FALSE, barheight = 15, barwidth = 1.1, \n                               title.theme = element_text(angle = 90, size = 13), \n                               title.position = \"right\", title.hjust = .5,\n                               label.theme = element_text(size = 10),\n                               title = expression(Primary~Productivity~(Cm^{-3}~yr^{-1}))))\n\nzanzibar.pp = ggplot()+\n  metR::geom_contour_fill(data = tafiri.data %>% filter(variable == \"pp\" & site == \"Zanzibar\"),\n                          aes(x = year, y = month, z = value), na.fill = TRUE, bins = 20)+\n  coord_cartesian(expand = FALSE)+\n  scale_y_reverse(breaks = 1:12, label = seq(lubridate::dmy(010119), \n                                            lubridate::dmy(311219), by = \"month\") %>% \n                    lubridate::month(abbr = TRUE, label = TRUE))+  \n  scale_x_continuous(breaks = seq(2004,2017,4))+\n  scale_fill_gradientn(colors = oce::oce.colors9A(120), limits = c(300,1700), breaks = seq(400,1600,200))+\n  theme_bw() %+replace%\n  theme(axis.text = element_text(size = 12, colour = 1), axis.text.y = element_blank())+\n  guides(fill = guide_colorbar(title = expression(mgm^{-3}),\n                               title.position = \"top\", \n                               title.hjust = 0.5, \n                               direction = \"vertical\",\n                               reverse = FALSE, \n                               barwidth = unit(.4, \"cm\"),\n                               barheight = unit(4, \"cm\")))+\n  labs(x = NULL, y = NULL)+\n  guides(fill = guide_colorbar(raster = FALSE, barheight = 15, barwidth = 1.1, \n                               title.theme = element_text(angle = 90, size = 13), \n                               title.position = \"right\", title.hjust = .5,\n                               label.theme = element_text(size = 10),\n                               title = expression(Primary~Productivity~(Cm^{-3}~yr^{-1}))))\n\nOnce we have the ggplot2 objects, we can now combine them side by side with the cowplot::plot_grid() function.\n\ncowplot::plot_grid(mafia.pp, \n                   zanzibar.pp, \n                   nrow = 1, \n                   rel_widths = c(.8,1), \n                   labels = c(\"Mafia\", \"Zanzibar\"), \n                   label_x = c(.2,.001), \n                   label_y = .98, \n                   label_fontface = \"plain\", \n                   label_size = 12)\n\n\n\n\n\nprofile = ctd %>% filter(station == \"st2\")\n\nggplot(data = profile, \n       aes(x = temperature, y = pressure)) + \n  geom_point()\n\n\n\n\nThis produce a scatterplot shown in figure @ref(fig:), which shows a strong correlation as the water depth increase the temperature decrease. Using the *grammar of graphics of the ggplot2**, the structure of the code used to make figure @ref(fig:) is defined by;\n\nData: profile,\nAesthetic mapping: temperature values mapped to x position, pressure values mapped to y position\nGeometry: points\n\nIn ggplot2, a plot is created with the ggplot() function, where data and aesthetic mappings are supplied as arguments, then layers are added on with +."
  },
  {
    "objectID": "plotting.html#colour",
    "href": "plotting.html#colour",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.9 Colour",
    "text": "6.9 Colour\nThe aesthetic component in ggplot2 allows to add additional variables to a graph. For instance, We can map the colors of the points to the temperature variable to reveal the gradient of dissolved oxygen as a function of depth\n\nggplot(data = profile, \n       aes(x = temperature, \n           y = pressure, \n           col = oxygen)) + \n  geom_point()"
  },
  {
    "objectID": "plotting.html#size",
    "href": "plotting.html#size",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.10 size",
    "text": "6.10 size\nThe aesthetic component in ggplot2 also allows to distinguish the plot with size of the variableh. For instance, We can map the size of the points to the temperature variable to reveal the gradient of dissolved oxygen as a function of depth\n\nggplot(data = profile %>% sample_frac(.25), \n       aes(x = temperature, y = pressure, col = oxygen, size = oxygen)) + \n  geom_point()\n\n\n\n\nAlthough we can map the temperature profile as points, it is appropriate to plot this profile as line. We can replace the geom_point() with geom_path() for that purpose\n\nggplot(data = profile, \n       aes(x = temperature, y = pressure, col = oxygen)) + \n  geom_path()"
  },
  {
    "objectID": "plotting.html#scaling",
    "href": "plotting.html#scaling",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.11 scaling",
    "text": "6.11 scaling\nA scale controls the mapping from data to aesthetic attributes. Its recommended to manipulate the scale for every aesthetic used on a plot. For example we want the x-axis labels to be position at the top and reverse the y-axis. The code can be writeen as;\n\nggplot(data = profile, \n       aes(x = temperature, y = pressure, col = oxygen)) + \n  geom_path()+\n  scale_y_reverse(name = \"Pressure [m]\", \n                  breaks = seq(0,810,100))+\n  scale_x_continuous(position = \"top\", \n                     name = expression(Temperature~(degree*C)), \n                     breaks = seq(6,29,3))\n\n\n\n\nWe might want to change the default color provided with ggplot2 on the legend. Since we commanded the plot to display gradient colors from dissolved oxygen, We use the scale_color_gradientn() function. The code can be writeen as;\n\nggplot(data = profile, \n       aes(x = temperature, y = pressure, col = oxygen)) + \n  geom_path()+\n  scale_y_reverse(name = \"Pressure [m]\", \n                  breaks = seq(0,810,100))+\n  scale_x_continuous(position = \"top\", \n                     name = expression(Temperature~(degree*C)), \n                     breaks = seq(6,29,3))+\n  scale_color_gradientn(colours = rainbow(11) %>% rev())"
  },
  {
    "objectID": "plotting.html#guides",
    "href": "plotting.html#guides",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.12 Guides",
    "text": "6.12 Guides\nContext is provided by guides. A guide help a human reader to understand the meaning of the visual cues. For example\n\nggplot(data = profile, \n       aes(x = temperature, y = pressure, col = oxygen)) + \n  geom_path()+\n  scale_y_reverse(name = \"Pressure [m]\", \n                  breaks = seq(0,810,100))+\n  scale_x_continuous(position = \"top\", \n                     name = expression(Temperature~(degree*C)), \n                     breaks = seq(6,29,3))+\n  scale_color_gradientn(colours = rainbow(11) %>% rev())+\n  # theme(legend.position = \"right\") +\n  guides(color = guide_colorbar(title = \"Dissolved oxygen (ml/L)\", \n                                title.position = \"right\", \n                                title.theme = element_text(angle = 90),\n                                barheight = 15, \n                                barwidth = .95, \n                                title.hjust = .5, \n                                ticks.colour = \"black\"))\n\n\n\n\n\nggplot(data = ctd %>% filter(pressure == 10),\n             aes(x = lon, y = lat))+\n  geom_point()+\n  ggrepel::geom_text_repel(aes(label = station))"
  },
  {
    "objectID": "plotting.html#add-on-packages",
    "href": "plotting.html#add-on-packages",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.13 Add-on packages",
    "text": "6.13 Add-on packages\nThe R community has developed packages that extend the capability of ggplot2. Some of the packages include:\n\nmetR: Provide addition tools for plotting filled contour, and label contour lines\nggrepel: Contains tools for automatically position non-overlapping text labels\nggspatial: Spatial Data Framework for ggplot2\nRcolorBrewer: Contains color palettes for continuous and discrete plots\ncowplot: Contains addition themes and tools to combine ggplot2 plots in one panel\negg: Provide tools for plot aligning and symmetrised ggplot2 plots\noce: Provide color pallete for visualization of Oceanographic Data\nggsn: Provide tools for mapping North symbols and scale bars on maps created with ggplot2\ngganimate: convert static ggplot2 plots to animations\nggformula: adds some additional plot options to ggplot2\nsf : Add capabilities of ggplot2 to map spatial data such as simple features\nggthemes: contains extra themes, scales, and geoms, and functions for and related to ggplot2\nggridges: extend the geom_density function by plotiing closed polygons insted of ridgelines"
  },
  {
    "objectID": "plotting.html#ggridges",
    "href": "plotting.html#ggridges",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.14 ggridges",
    "text": "6.14 ggridges\nAlthoug ehe ggridges package provides geom_ridgeline and geom_density_ridges, we focus on the latter because it has ability to estimates data densities and then draws those using ridgelines.The geom geom_density_ridges calculates density estimates from the provided data and then plots those, using the ridgeline visualization.\n\nctd = ctd %>% \n  mutate(strata = cut(x = pressure, breaks = c(0,80,120,200), \n                      labels = c(\"Upper\", \"Middle\", \"Lower\")))\n\nctd.strata = ctd %>% \n  group_by(strata, pressure, lon,lat) %>% \n  summarise(temperature = mean(temperature, na.rm = TRUE), \n            salinity = mean(salinity, na.rm = TRUE), \n            oxygen = mean(oxygen, na.rm = TRUE), \n            fluorescence = mean(fluorescence, na.rm = TRUE)) %>%\n  ungroup() %>% \n  filter(!is.na(strata))\n\n`summarise()` has grouped output by 'strata', 'pressure', 'lon'. You can\noverride using the `.groups` argument.\n\nggplot(data = ctd.strata, aes(x = temperature, y = strata))+\n  ggridges::geom_density_ridges2()+\n  scale_y_discrete(limits = c(\"Lower\", \"Middle\", \"Upper\"))\n\nPicking joint bandwidth of 0.41\n\n\nWarning: Removed 7 rows containing non-finite values (stat_density_ridges).\n\n\n\n\n\nTrailing tails can be cut off using the rel_min_height() aesthetic. This aesthetic sets a percent cutoff relative to the highest point of any of the density curves. A value of 0.01 usually works well, but you may have to modify this parameter for different datasets.\n\nggplot(data = ctd.strata, aes(x = temperature, y = strata))+\n  ggridges::geom_density_ridges2(rel_min_height = 0.01)+\n  scale_y_discrete(limits = c(\"Lower\", \"Middle\", \"Upper\"))\n\nPicking joint bandwidth of 0.41\n\n\nWarning: Removed 7 rows containing non-finite values (stat_density_ridges).\n\n\n\n\n\n\nggplot(data = ctd.strata, aes(x = temperature, y = strata))+\n  ggridges::geom_density_ridges2(scale = 8,rel_min_height = 0.01)+# scale =80, substantial overlap\n  scale_y_discrete(limits = c(\"Lower\", \"Middle\", \"Upper\"))\n\nPicking joint bandwidth of 0.41\n\n\nWarning: Removed 7 rows containing non-finite values (stat_density_ridges)."
  },
  {
    "objectID": "plotting.html#varying-fill-colors-along-the-x-axis",
    "href": "plotting.html#varying-fill-colors-along-the-x-axis",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.15 Varying fill colors along the x axis",
    "text": "6.15 Varying fill colors along the x axis\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved with the geoms geom_ridgeline_gradient and geom_density_ridges_gradient. Both geoms work just like geom_ridgeline and geom_density_ridges, except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\nHere is a simple example of changing fill colors with geom_ridgeline_gradient:\n\nggplot(data = ctd.strata, aes(x = temperature, y = strata,  fill = strata))+\n  ggridges::geom_density_ridges_gradient(scale = 5,rel_min_height = 0.01)+# scale =5, substantial overlap\n  scale_y_discrete(limits = c(\"Lower\", \"Middle\", \"Upper\"))\n\nPicking joint bandwidth of 0.41\n\n\n\n\n\n\nggplot(data = ctd.strata, aes(x = temperature, y = strata,  fill = ..x..))+\n  ggridges::geom_density_ridges_gradient(scale = 5,rel_min_height = 0.01)+# scale =5, substantial overlap\n  scale_y_discrete(limits = c(\"Lower\", \"Middle\", \"Upper\"))+\n  scale_fill_gradientn(colours = oce::oce.colorsTemperature(120), breaks = seq(14,26,2))+\n  guides(fill = guide_colorbar(title =expression(Temperature~~(degree*C)),\n                               title.position = \"right\",\n                               title.hjust = .5, raster = TRUE,\n                               title.theme = element_text(angle = 90, size = 12),\n                               label.theme = element_text(size = 11),\n                               barheight = 15, barwidth = .95))\n\nPicking joint bandwidth of 0.41"
  },
  {
    "objectID": "plotting.html#metr",
    "href": "plotting.html#metr",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.16 metR",
    "text": "6.16 metR\n\ntransect2 = ctd %>% filter( lat >= -8 &lat < -6 &  pressure < 205)\n\nggplot(data = transect2,\n             aes(x = lon, y = pressure, z = fluorescence))+\n  metR::geom_contour_fill(na.fill = TRUE, bins = 20)+\n  # metR::geom_contour2()+\n  scale_y_reverse(breaks = seq(0, 205,30))+\n  scale_x_continuous(breaks = transect2 %>% distinct(lon) %>% pull(), \n                     labels = metR::LonLabel(transect2 %>% distinct(lon) %>%\n                                               pull()%>%round(digits = 2)))+\n  scale_fill_gradientn(colours = oce::oceColors9A(120), breaks = seq(0,2,.2))+\n  coord_cartesian(expand = FALSE)+\n  guides(fill = guide_colorbar(title =expression(Chlorophyll~concentration~(mgm^{-3})),\n                               title.position = \"right\",\n                               title.hjust = .5, raster = FALSE,\n                               title.theme = element_text(angle = 90, size = 12),\n                               label.theme = element_text(size = 11),\n                               barheight = 15, barwidth = .95))+\n  labs(x = NULL, y = \"Water depth [m]\")+\n  geom_vline(xintercept = transect2 %>% distinct(lon) %>% pull(), \n             linetype = \"dashed\", col = \"ivory\")+\n  theme_bw()+\n  theme(axis.text = element_text(size = 11), axis.title = element_text(size = 12))\n\n\n\n\n\ndepth  = c(10,50,100,200)\nalgoa = NULL\n\nfor (i in seq_along(depth)){\n\nstrata = ctd %>% \n  filter(lon > 39.3 & lon < 40.5 & lat >= -10 & pressure == depth[i]) %>% select(3:9)\n\nLon = strata %>% pull(lon)\nLat = strata %>% pull(lat)\ndata = strata %>% select(4:7)\n\n\n  for (j in seq_along(data)){\n  \n  algoa.interp = strata %$% oce::interpBarnes(x = Lon, y = Lat, z = data[j]%>% pull())\n  \n  algoa.tb = algoa.interp %$% \n    matrix_tb(x = xg, y = yg, data = zg) %>% \n    rename(lon = x, lat = y) %>% \n    mutate(variable = colnames(data[j]), pressure = depth[i])\n  \n  algoa = algoa %>% bind_rows(algoa.tb)\n  }\n}\n\n# algoa  %>% group_by(pressure, variable) %>% summarise(average = mean(value, na.rm = TRUE))\n\n\nggplot()+\n  metR::geom_contour_fill(data = algoa %>% filter(variable == \"fluorescence\"),\n              aes(x = lon, y = lat, z = value), na.fill = TRUE, bins = 20)+\n  scale_fill_gradientn(colours = oce::oceColors9A(120))+\n  scale_y_continuous(breaks = seq(-8.5,-6,2.5), \n                     labels = metR::LatLabel(seq(-8.5,-6,2.5)))+\n  scale_x_continuous(breaks = seq(39.55,40.25,length.out = 3) %>% round(2), \n                     labels = metR::LonLabel(seq(39.55,40.25,length.out = 3)))+\n  facet_wrap(~pressure)+\n    labs(x = NULL, y = NULL)+\n  theme_bw()+\n  theme(axis.text = element_text(size = 11))+\n  coord_cartesian(expand = FALSE)+\n  guides(fill = guide_colorbar(title =expression(Chlorophyll~concentration~(mgm^{-3})),\n                               title.position = \"right\",\n                               title.hjust = .5, raster = FALSE,\n                               title.theme = element_text(angle = 90, size = 12),\n                               label.theme = element_text(size = 11),\n                               barheight = 15, barwidth = .95))\n\n\n\n\n\nggplot()+\n  metR::geom_contour_fill(data = algoa %>% filter(variable == \"temperature\"),\n              aes(x = lon, y = lat, z = value), na.fill = TRUE, bins = 20)+\n  scale_fill_gradientn(colours = oce::oceColors9A(120))+\n  scale_y_continuous(breaks = seq(-8.5,-6,2.5), \n                     labels = metR::LatLabel(seq(-8.5,-6,2.5)))+\n  scale_x_continuous(breaks = seq(39.55,40.25,length.out = 3) %>% round(2), \n                     labels = metR::LonLabel(seq(39.55,40.25,length.out = 3)))+\n  facet_wrap(~pressure)+\n    labs(x = NULL, y = NULL)+\n  theme_bw()+\n  theme(axis.text = element_text(size = 11))+\n  coord_cartesian(expand = FALSE)+\n  guides(fill = guide_colorbar(title =expression(Temperature~(degree*C)),\n                               title.position = \"right\",\n                               title.hjust = .5, raster = FALSE,\n                               title.theme = element_text(angle = 90, size = 12),\n                               label.theme = element_text(size = 11),\n                               barheight = 15, barwidth = .95))\n\n\n\n\n\nggplot()+\n  metR::geom_contour_fill(data = algoa %>% filter(variable == \"oxygen\"),\n              aes(x = lon, y = lat, z = value), na.fill = TRUE, bins = 20)+\n  scale_fill_gradientn(colours = oce::oceColors9A(120))+\n  scale_y_continuous(breaks = seq(-8.5,-6,2.5), \n                     labels = metR::LatLabel(seq(-8.5,-6,2.5)))+\n  scale_x_continuous(breaks = seq(39.55,40.25,length.out = 3) %>% round(2), \n                     labels = metR::LonLabel(seq(39.55,40.25,length.out = 3)))+\n  facet_wrap(~pressure)+\n    labs(x = NULL, y = NULL)+\n  theme_bw()+\n  theme(axis.text = element_text(size = 11))+\n  coord_cartesian(expand = FALSE)+\n  guides(fill = guide_colorbar(title =expression(Dissolved~oxygen~(mgm^{-3})),\n                               title.position = \"right\",\n                               title.hjust = .5, raster = FALSE,\n                               title.theme = element_text(angle = 90, size = 12),\n                               label.theme = element_text(size = 11),\n                               barheight = 15, barwidth = .95))"
  },
  {
    "objectID": "plotting.html#a-grammar-for-graphics",
    "href": "plotting.html#a-grammar-for-graphics",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.17 A grammar for graphics",
    "text": "6.17 A grammar for graphics\nIn this section, we will create some of the most routinely used plots to explore data using the geom_ functions.\nWe will use the following libraries in this post:\n\nreadr\nggplot2\ntibble\ndplyr\n\nWhich are part of the tidyverse. By loading the tidyverse, we also load all the packages mentioned above\n\nrequire(tidyverse)\nrequire(patchwork)\nrequire(magrittr)\n\ntheme_set(theme_bw(base_size = 11))\n\nAll the data sets used in this post can be found here and code can be downloaded from here.\n\noctopus = read_csv(\"assets/octopus_data.csv\")\n\nThe variables representing the X and Y axis can be specified either in ggplot() or in geom_point(). We will learn to modify the appearance of the points in a different post.\n\nggplot(data = octopus, \n       aes(x = tl, y = weight)) + \n  geom_point()\n\n\n\n\nFigure 6.4: Relationship between total length and weight of octopus\n\n\n\n\n\n6.17.1 Regression Line\nYou can fit the regression on the scatterplot with geom_smooth()\n\nlm = ggplot(data = octopus, \n       aes(x = tl, y = weight)) + \n  geom_point(alpha = .2)+\n  geom_smooth(method = \"lm\", se = TRUE, color = \"red\", fill = \"red\")+\n  labs(x = NULL, y = NULL, title = \"linear model\")\n\ngam = ggplot(data = octopus, \n       aes(x = tl, y = weight)) + \n  geom_point(alpha = .2)+\n  geom_smooth(method = \"gam\", se = TRUE, color = \"red\", fill = \"red\")+\n  labs(x = NULL, y = NULL, title = \"GAM\")\n\nloess = ggplot(data = octopus, \n       aes(x = tl, y = weight)) + \n  geom_point(alpha = .2)+\n  geom_smooth(method = \"loess\", se = TRUE, color = \"red\", fill = \"red\")+\n  labs(x = NULL, y = NULL, title = \"LOESS\")\n\nlm + gam + loess\n\n\n\n\nFigure 6.5: Relationship between total length and weight of octopus for Linear, GAM and LOESS models\n\n\n\n\n\n\n6.17.2 Horizontal/ vertical lines\nA segment of horizontal or vertical line can be added on the plot using egg::ggarrange\n\n6.17.2.1 Vertical Line\nFor the vertical line, the x axis intercept must be specified in geom_vline()\n\nggplot(data = octopus, \n       aes(x = tl, y = weight)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_vline(xintercept = 100, linetype = 1, size = .5, col = \"red\")\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\nFigure 6.6: Relationship between total length and weight of octopus and vertical line\n\n\n\n\n\n\n6.17.2.2 Vertical Line\nIn similar manner, for the horizontal line, the y axis intercept must be specified in geom_hline()\n\nggplot(data = octopus, \n       aes(x = tl, y = weight)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_hline(yintercept = 2, linetype = 1, size = .5, col = \"red\")\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\nFigure 6.7: Relationship between total length and weight of octopus and horizontal line"
  },
  {
    "objectID": "plotting.html#aes",
    "href": "plotting.html#aes",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.18 aes()",
    "text": "6.18 aes()\nIn this section, we focus on the aesthetics i.e. color, shape, size, alpha, line type, line width etc. We can map these to variables or specify values for them. If we want to map the above to variables, we have to specify them within the aes() function. We will look at both methods in the following sections.\nExplore aesthetics such as\n\ncolor\nshape\nsize\nfill\nalpha\nwidth\n\n\n6.18.1 Color\nIn ggplot2, when we mention color or colour, it usually refers to the color of the geoms. The fill argument is used to specify the color of the shapes in certain cases. In this section, we will see how we can specify the color for the different geoms we learnt in the previous post.\nFor points, the color argument specifies the color of the point for certain shapes and border for others. The fill argument is used to specify the background for some shapes and will not work with other shapes. Let us look at an example:\n\nggplot(data = octopus, \n       aes(x = tl, y = weight, col = sex)) + \n  geom_point() \n\n\n\n\nFigure 6.8: Relationship between total length and weight of octopus\n\n\n\n\nIf you do not want to map a variable to color, you can specify it separately using the color argument but in this case it should be outside the aes() function.\n\nggplot(data = octopus, \n       aes(x = tl, y = weight, col = sex)) + \n  geom_point(col = \"blue\") \n\n\n\n\nFigure 6.9: Relationship between total length and weight of octopus\n\n\n\n\n\n\n6.18.2 shape\n\nggplot(data = octopus, \n       aes(x = tl, y = weight, shape = sex)) + \n  geom_point() \n\n\n\n\nFigure 6.10: Relationship between total length and weight of octopus\n\n\n\n\nLet us map size of points to a variable. It is advised to map size only to continuous variables and not categorical variables.\n\nggplot(data = octopus, \n       aes(x = tl, y = weight, col = sex, size = dml)) + \n  geom_point() \n\n\n\n\nFigure 6.11: Relationship between total length and weight of octopus"
  },
  {
    "objectID": "plotting.html#axis-and-labels",
    "href": "plotting.html#axis-and-labels",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.19 Axis and labels",
    "text": "6.19 Axis and labels\nIn this section, we learn about about aesthetic and focus on\n\nadd title and subtitle to the plot\nmodify axis labels\nmodify axis range\nremove axis format axis\n\nLet us start with a simple scatter plot. We will continue to use the octopus data set and examine the relationship between total length and body weight using geom_point().\n\noct = ggplot(data = octopus, \n       aes(x = tl, y = weight)) + \n  geom_point()+\n  geom_smooth(method = \"gam\", se = TRUE)\n\nWe add the axis labels, title and subtitle for the plot using the labs()\n\nggplot(data = octopus, \n       aes(x = tl, y = weight)) + \n  geom_point()+\n  geom_smooth(method = \"gam\", se = TRUE) + \n  labs(x = \"Total length (cm)\", y = \"Weight (g)\", \n       title = \"Octopus\", subtitle = \"The total length and body weight of octopus\")\n\n`geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nFigure 6.12: Relationship between total length and weight of octopus"
  },
  {
    "objectID": "plotting.html#axis-range",
    "href": "plotting.html#axis-range",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.20 Axis Range",
    "text": "6.20 Axis Range\nOften times, you may want to modify the range of the axis value. In ggplot2, we can achieve this using scale_function\n\nggplot(data = octopus, \n       aes(x = tl, y = weight)) + \n  geom_point()+\n  geom_smooth(method = \"gam\", se = TRUE) + \n  labs(x = \"Total length (cm)\", y = \"Weight (g)\", \n       title = \"Octopus\", subtitle = \"The total length and body weight of octopus\")+\n  scale_x_continuous(breaks = seq(30,180,30))+\n  scale_y_continuous(breaks = seq(0,5,1))\n\n`geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nFigure 6.13: Relationship between total length and weight of octopus\n\n\n\n\nSometimes the axis label become a reduntat\n\nggplot(data = octopus, \n       aes(x = tl, y = weight)) + \n  geom_point()+\n  geom_smooth(method = \"gam\", se = TRUE) + \n  theme(axis.title = element_blank())\n\n`geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nFigure 6.14: Relationship between total length and weight of octopus"
  },
  {
    "objectID": "plotting.html#text-annotaion",
    "href": "plotting.html#text-annotaion",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.21 Text annotaion",
    "text": "6.21 Text annotaion\nAnnotation help to add custom text to the plot.\n\nggplot(data = octopus, \n       aes(x = tl, y = weight)) + \n  geom_point()+\n  geom_smooth(method = \"gam\", se = TRUE) + \n  annotate(geom = \"text\", x = 20, y = 2.2, label = \"outlier\", color = \"red\")\n\n`geom_smooth()` using formula 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\nFigure 6.15: Relationship between total length and weight of octopus"
  },
  {
    "objectID": "plotting.html#scales",
    "href": "plotting.html#scales",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.22 Scales",
    "text": "6.22 Scales\nWhenever you specify an aesthetic mapping, ggplot2 uses a particular scale to determine the range of values that the data encoding should be mapped to. However, there times you need to customize the scale. ggplot2 has scales_*() function that allows to modify titles, labels, limits, breaks and position of the axis. Each scale can be represented by a function named in the following format: scale_, followed by the name of the aesthetic property (e.g., x or color), followed by an _ and the type of the scale (e.g., continuous or discrete). A continuous scale will handle values such as numeric data (where there is a continuous set of numbers), whereas a discrete scale will handle values such as colors (since there is a small discrete list of distinct colors). In simple language, the x and y-axis of a continuous data is modified with the scale_x_continuous() and scale_y_continuous() functions.\n\nggplot(data = octopus, \n       aes(x = tl, y = weight)) + \n  geom_point()+\n  geom_smooth(method = \"gam\", se = TRUE)+\n  scale_x_continuous(limits = c(50, 150), breaks = seq(50,150,20))+\n  scale_y_continuous(limits = c(0,3), breaks = seq(.5, 3, .5))\n\n\n\n\nFigure 6.16: Relationship between total length and weight of octopus\n\n\n\n\nThe x and y-axis of a continuous data is modified with the scale_x_discrete() and scale_y_continuous() functions.\n\n\n\n\nggplot(data = mafia.chl.season , aes(x = season, y = chl))+\n  geom_boxplot( outlier.colour = \"red\", outlier.shape = 8, outlier.size = 4)+\n  scale_x_discrete(limits = c(\"NE\", \"IN\", \"SE\"))+\n  scale_y_continuous(breaks = seq(0.5,2.5,.4))\n\n\n\n\nFigure 6.17: Chloropphyll concentration by monsoon seasons\n\n\n\n\nwhen the data has been transformed, for instance because of the low value, chlorophyll-a are often stretched with the log-tranformation for visual appeal. But the log-transformed values make no sense about concentration and hence the real values must replace them. We can change the tick labels using the labels argument. When adding labels, tick breaks and labels must have the same length.\n\nggplot(data = mafia.chl.season , aes(x = season, y = chl %>% log()))+\n  geom_boxplot( outlier.colour = \"red\", outlier.shape = 8, outlier.size = 4)+\n  scale_x_discrete(limits = c(\"NE\", \"IN\", \"SE\"), \n                   labels = c(\"Inter\", \"Northeast\", \"Southeast\"))+\n  scale_y_continuous(breaks = seq(-0.5,1,length.out = 5),\n                     labels = seq(0.5,2.6,length.out = 5))\n\n\n\n\nFigure 6.18: Chloropphyll concentration by monsoon seasons\n\n\n\n\nThe position of the axes can be changed using the position argument. For instance, to move the the x-axis to the top of the plot you only need to specify position = top as written in code below;\n\nggplot(data = mafia.chl.season , aes(x = season, y = chl %>% log()))+\n  geom_boxplot( outlier.colour = \"red\", outlier.shape = 8, outlier.size = 4)+\n  scale_x_discrete(position = \"top\",\n                   limits = c(\"NE\", \"IN\", \"SE\"), \n                   labels = c(\"Inter\", \"Northeast\", \"Southeast\"))+\n  scale_y_continuous(breaks = seq(-0.5,1,length.out = 5),\n                     labels = seq(0.5,2.6,length.out = 5))\n\n\n\n\nFigure 6.19: Chloropphyll concentration by monsoon seasons\n\n\n\n\nFill the boxplot with season to specify the colors and arrange the colors manual with scale_fill_manual() function as written below.\n\nggplot(data = mafia.chl.season , aes(x = season, y = chl %>% log(), fill = season))+\n  geom_boxplot( outlier.colour = \"red\", outlier.shape = 8, outlier.size = 4)+\n  scale_x_discrete(position = \"top\",\n                   limits = c(\"NE\", \"IN\", \"SE\"), \n                   labels = c(\"Inter\", \"Northeast\", \"Southeast\"))+\n  scale_y_continuous(breaks = seq(-0.5,1,length.out = 5),\n                     labels = seq(0.5,2.6,length.out = 5))\n\n\n\n\nFigure 6.20: Chloropphyll concentration by monsoon seasons\n\n\n\n\nNote the order of layers matter here: you scale_fill_manual() function must start before scale_x_discrete() function. Otherwise the colours you specify mismatch with legend colors as shown\n\nggplot(data = mafia.chl.season , aes(x = season, y = chl %>% log(), fill = season))+\n  geom_boxplot( outlier.colour = \"red\", outlier.shape = 8, outlier.size = 4)+\n  scale_x_discrete(position = \"top\",\n                   limits = c(\"NE\", \"IN\", \"SE\"), \n                   labels = c(\"Inter\", \"Northeast\", \"Southeast\"))+\n  scale_fill_manual(values = c(\"red\", \"blue\", \"green\"))+\n  scale_y_continuous(breaks = seq(-0.5,1,length.out = 5),\n                     labels = seq(0.5,2.6,length.out = 5))\n\n\n\n\nFigure 6.21: Chloropphyll concentration by monsoon seasons\n\n\n\n\n\n\n\nThe scale_*_reverse() allows to reverse the order of the axis. For instance, when plotting profiles, we reverse y-xis and position the label of x-axis at the top\n\nggplot(data = algoa.average, \n       aes(x = value, y = pressure))+\n  geom_path() + \n  scale_y_reverse(limits = c(800,0))+\n  scale_x_continuous(position = \"top\") +\n  facet_wrap(~variable, scales = \"free_x\", nrow = 1)\n\n\n\n\nFigure 6.22: Chloropphyll concentration by monsoon seasons"
  },
  {
    "objectID": "plotting.html#guides-1",
    "href": "plotting.html#guides-1",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.23 Guides",
    "text": "6.23 Guides\nguides() helps to set, modify and remove legend for a specific aesthetic. It has two functions—guide_legend() or guide_colorbar(). Let make a section plot of the fluorescence with the default options for the legend\n\nsection =ggplot(data = algoa %>% filter(lat < -10),\n       aes(x = lon, y = pressure, z = fluorescence)) + \n  metR::geom_contour_fill(na.fill = TRUE, bins = 60) +\n  metR::scale_x_longitude(ticks = .15) +\n  scale_y_reverse(limits = c(200,0))+\n  scale_fill_gradientn(colours = oce::oce.colors9A(120), \n                       breaks = seq(0.15,1.25, length.out = 6) %>%round(2))+\n  labs(subtitle = paste(\"Section of oxygen along latitude\", metR::LatLabel(-10.54)))+\n  coord_cartesian(expand = TRUE, ylim = c(180,15))\n\nsection\n\n\n\n\nFigure 6.23: Chloropphyll concentration along the longitudinal section of Rufiji Mafia\n\n\n\n\nWe can add the contour labels and remove the legend in a graph\n\nsection +\n  metR::geom_contour2(bins = 4, aes(label = ..level..)) +\n  # metR::geom_text_contour() +\n  guides(fill = FALSE)\n\n\n\n\nFigure 6.24: Chloropphyll concentration along the longitudinal section of Rufiji Mafia overlaid with labelled contour\n\n\n\n\nThe guide_colorbar() modify the look and appearance of the legend to smooth colorbar. for instane the code of lines below highlight the key arguments that one has to specify to modify the legend of colorbar.\n\nsection +  \n  metR::geom_contour2(bins = 4, aes(label = ..level..)) +\n  guides(fill = guide_colorbar(title = expression(Chlorophyll~concentration~(mgm^{-3})), \n                               title.position = \"right\", \n                               title.theme = element_text(angle = 90, size = 13),\n                               title.hjust = .5,\n                               label.theme = element_text(angle = 0, size = 11),\n                               label.position = \"right\",\n                               label.vjust = 0.5,\n                               raster = FALSE,\n                               nbin = 12,\n                               reverse = FALSE,\n                               barwidth = 1.1, \n                               barheight = 10))\n\n\n\n\nFigure 6.25: Chloropphyll concentration along the longitudinal section of Rufiji Mafia\n\n\n\n\nIf you want the legend to appear as individual key, use guide_colorbar() as written in the code below\n\nsection +  \n  metR::geom_contour2(bins = 4, aes(label = ..level..)) +\n  theme(legend.position = \"bottom\") +\n  guides(fill = guide_legend(title = expression(Chlorophyll~concentration~(mgm^{-3})), \n                             title.position = \"top\", \n                             title.theme = element_text(angle = 0, size = 13),\n                             title.hjust = .5,nrow = 1,\n                             reverse = FALSE, \n                             keywidth = 3., keyheight = .8,\n                             direction = \"horizontal\",\n                             label.theme = element_text(angle = 0, size = 11),\n                             label.position = \"bottom\"))\n\n\n\n\nFigure 6.26: Chloropphyll concentration along the longitudinal section of Rufiji Mafia"
  },
  {
    "objectID": "plotting.html#themes",
    "href": "plotting.html#themes",
    "title": "6  Plotting in R with ggplot2",
    "section": "6.24 Themes",
    "text": "6.24 Themes\nThemes in ggplot modify the appearance of all non data compoments in the plot like: axis, legend, panel, plot area, background, margin, facets etc. Let’s create a profile plot of temperature with default theme settings\n\nprofile = ggplot(data = algoa %>% filter(lat < -10), \n       aes(x = temperature, y = pressure, color = station))+\n  geom_path() + \n  scale_y_reverse(limits = c(800,0))+\n  scale_x_continuous(position = \"top\") +\n  labs(y = \"Pressure [m]\",x = expression(Temperature~(degree*C)))\n\nprofile\n\n\n\n\nFigure 6.27: Temperature profile by station of deployment\n\n\n\n\nWe can modify the size and color of axis label with the axis.text() and axis title with axis.title() functions. You can use axis.title.y to modify the Y axis title and to modify the title of both the axis together, use axis.title.\n\nprofile +\n  theme(axis.text = element_text(size =  11, colour = \"black\"), \n        axis.title = element_text(size = 14, colour = \"black\"))\n\n\n\n\nFigure 6.28: Temperature profile by station of deployment\n\n\n\n\nTo modify the appearance of the axis ticks, use the axis.ticks_* argument. You can change the color, size, linetype and length of the ticks using the element_line() function as shown below.\n\nprofile +\n  theme(axis.text = element_text(size =  11, colour = \"black\"), \n        axis.title = element_text(size = 14, colour = \"black\"), \n        axis.ticks.length = unit(.3,  \"cm\"))\n\n\n\n\nFigure 6.29: Temperature profile by station of deployment\n\n\n\n\nThe panel_grid argument is used to modify the appearance of the gridlines. You can change the color, size and linetype of the line using the element_line() function.\n\nprofile +\n  theme(axis.text = element_text(size =  11, colour = \"black\"), \n        axis.title = element_text(size = 14, colour = \"black\"), \n        axis.ticks.length = unit(.3,  \"cm\"),\n        panel.grid = element_line(colour = \"grey60\", linetype = 3))\n\n\n\n\nFigure 6.30: Temperature profile by station of deployment\n\n\n\n\nThe background of the legend can be modified using the legend.background argument. You can change the background color, the border color and line type using element_rect().\n\nprofile +\n  theme(axis.text = element_text(size =  11, colour = \"black\"), \n        axis.title = element_text(size = 14, colour = \"black\"), \n        axis.ticks.length = unit(.3,  \"cm\"),\n        panel.grid = element_line(colour = \"grey60\", linetype = 3),\n        panel.background = element_rect(fill = \"white\", colour = \"black\"))\n\n\n\n\nFigure 6.31: Temperature profile by station of deployment\n\n\n\n\nNow, let us look at modifying the non-data components of a legend.\n\nprofile +\n  theme(axis.text = element_text(size =  11, colour = \"black\"), \n        axis.title = element_text(size = 14, colour = \"black\"), \n        axis.ticks.length = unit(.3,  \"cm\"),\n        panel.grid = element_line(colour = \"grey60\", linetype = 3),\n        panel.background = element_rect(fill = \"white\", colour = \"black\"),\n        legend.key = element_blank(),\n        legend.position = c(.9,.3),\n        legend.background = element_rect(colour = \"black\", fill = \"white\"))\n\n\n\n\nFigure 6.32: Temperature profile by station of deployment\n\n\n\n\nThe appearance of the text can be modified using the legend.text argument. You can change the color, size and font using the element_text() function. The position and direction of the legend can be changed using legend.position() function.\n\nprofile +\n  scale_color_discrete(name = \"Stations\")+\n  theme(axis.text = element_text(size =  11, colour = \"black\"), \n        axis.title = element_text(size = 14, colour = \"black\"), \n        axis.ticks.length = unit(.3,  \"cm\"),\n        panel.grid = element_line(colour = \"grey60\", linetype = 3),\n        panel.background = element_rect(fill = \"white\", colour = \"black\"),\n        legend.key = element_blank(),\n        legend.position = c(.9,.3),\n        legend.background = element_rect(colour = \"black\", fill = \"white\"),\n        legend.text = element_text(size = 11, colour = \"black\"),\n        legend.title = element_text(size = 13, colour = \"black\"))\n\n\n\n\nFigure 6.33: Temperature profile by station of deployment\n\n\n\n\n\n\n\n\nCampitelli, Elio. 2019. metR: Tools for Easier Analysis of Meteorological Fields. https://CRAN.R-project.org/package=metR.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. http://ggplot2.org.\n\n\nWilke, Claus O. 2018. Cowplot: Streamlined Plot Theme and Plot Annotations for ’Ggplot2’. https://CRAN.R-project.org/package=cowplot."
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "7  Exploratory-Data-Analysis-EDA",
    "section": "",
    "text": "Exploratory Data Analysis (EDA) is a method for data analysis that employs visual methods. Using statistical summaries and graphical representations, it is used to identify trends, and patterns, or to test hypotheses.\nUnderstanding the data first and attempting to glean as many insights from it as possible is a smart strategy. Before going hands-on with the data, EDA is all about making sense of it. The first step in using data is to EXPLORE it! This entails creating simple metrics and charts to determine what your data is telling you.\nThe data set used for this analysis was taken from Kaggle. The packages for exploratory data analysis used in this chapter are the packages dplyr (Wickham et al. 2018) and tidyr (Wickham and Henry 2018), and to visualize and explore the data: ggplot2 (Wickham 2016) and metR (Campitelli 2019).\nThe objective of this chapter is to analyze and identify trends and patterns of priority fisheries in Mafia Island, Tanzania and identify which priority fishery is performing well and which one are doing worse. To start with, we need to import the necessary libraries first and then loaded the data set.\n\nrequire(tidyverse)\nrequire(magrittr)\n\ntheme_set(theme_bw(base_size = 11))\n\nLet’s load the CSV file using the read_csv function. We’ll use the name hotel_raw_df for the data frame to indicate this is unprocessed data that we might clean, filter, and modify to prepare a data frame ready for analysis.\n\nmimp = read_csv(\"assets/mimp_cfma_priority.csv\")\n\nRows: 41404 Columns: 13\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr  (6): district, village, landing, gear_type, order, priority\ndbl  (4): fishermen, weight, fish_number, fish_price\ndttm (3): date, going_time, return_time\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmimp\n\n# A tibble: 41,404 x 13\n   district village    landing  date                going_time         \n   <chr>    <chr>      <chr>    <dttm>              <dttm>             \n 1 Mafia    Chunguruma Tumbuju  2009-09-14 00:00:00 1899-12-31 09:00:00\n 2 Mafia    Chunguruma Tumbuju  2009-09-14 00:00:00 1899-12-31 09:00:00\n 3 Mafia    Kiegeani   Utende   2010-01-15 00:00:00 1899-12-31 08:30:00\n 4 Mafia    Miburani   Kitoni   2010-01-29 00:00:00 1899-12-31 10:00:00\n 5 Mafia    Dongo      Magemani 2009-06-17 00:00:00 1899-12-31 10:00:00\n 6 Mafia    Chunguruma Tumbuju  2009-09-19 00:00:00 1899-12-31 12:00:00\n 7 Mafia    Chunguruma Tumbuju  2009-09-19 00:00:00 1899-12-31 12:00:00\n 8 Mafia    Bwejuu     Bwejuu   2009-12-13 00:00:00 1899-12-31 00:00:00\n 9 Mafia    Bwejuu     Bwejuu   2009-12-13 00:00:00 1899-12-31 00:00:00\n10 Mafia    Bwejuu     Bwejuu   2009-12-13 00:00:00 1899-12-31 00:00:00\n# ... with 41,394 more rows, and 8 more variables: return_time <dttm>,\n#   fishermen <dbl>, gear_type <chr>, order <chr>, priority <chr>,\n#   weight <dbl>, fish_number <dbl>, fish_price <dbl>\n\n\nLet’s view some basic information about the data frame. We can achieve that with a glimpse function:\n\nmimp %>% \n  glimpse()\n\nRows: 41,404\nColumns: 13\n$ district    <chr> \"Mafia\", \"Mafia\", \"Mafia\", \"Mafia\", \"Mafia\", \"Mafia\", \"Maf~\n$ village     <chr> \"Chunguruma\", \"Chunguruma\", \"Kiegeani\", \"Miburani\", \"Dongo~\n$ landing     <chr> \"Tumbuju\", \"Tumbuju\", \"Utende\", \"Kitoni\", \"Magemani\", \"Tum~\n$ date        <dttm> 2009-09-14, 2009-09-14, 2010-01-15, 2010-01-29, 2009-06-1~\n$ going_time  <dttm> 1899-12-31 09:00:00, 1899-12-31 09:00:00, 1899-12-31 08:3~\n$ return_time <dttm> 1899-12-31 15:00:00, 1899-12-31 15:00:00, 1899-12-31 13:0~\n$ fishermen   <dbl> 15, 15, 1, 1, 1, 18, 18, 1, 1, 1, 1, 1, 17, 17, 5, 6, 15, ~\n$ gear_type   <chr> \"BEACH SEINE NETS\", \"BEACH SEINE NETS\", \"STICK/SPEAR\", \"ST~\n$ order       <chr> \"DASYATIDAE\", \"LETHRINIDAE\", \"Octopus\", \"BELONIDAE\", \"SPHY~\n$ priority    <chr> \"Elasmobranch\", \"Reef fish\", \"Octopus\", \"Small pelagic\", \"~\n$ weight      <dbl> 30.0, 20.0, 10.0, 7.0, 4.5, 30.0, 10.0, 9.0, 4.0, 6.0, 5.0~\n$ fish_number <dbl> 10, 100, 12, 4, 4, 90, 20, 39, 18, 19, 3, 32, 60, 30, 6, 3~\n$ fish_price  <dbl> 10000, 30000, 15000, 8400, 10500, 13500, 10000, 10800, 480~\n\n\nThe dataset contains 41404 rows and 13 columns. Among the character variables are district, village, landing sites, gear_type, order, and priority. The date and time structures variables includes date, going_time, return_time whereas as weight, fish_number, and fish_price are numerical variables."
  },
  {
    "objectID": "eda.html#data-preparation-and-cleaning",
    "href": "eda.html#data-preparation-and-cleaning",
    "title": "7  Exploratory-Data-Analysis-EDA",
    "section": "7.2 Data Preparation and Cleaning",
    "text": "7.2 Data Preparation and Cleaning\nData preparation is the process of preparing the data by cleaning and transforming raw data befoe analysis. It is an important step before processing and often involves reformatting data, making corrections to data, and combining data sets to enrich data.\nData preparation involves fixing or removing incorrect, corrupted, incorrectly formatted, duplicate, or incomplete data within a dataset. When combining multiple data sources, there are many opportunities for data to be duplicated or mislabeled. If data is incorrect, outcomes and algorithms are unreliable, even though they may look correct."
  },
  {
    "objectID": "eda.html#data-tidying",
    "href": "eda.html#data-tidying",
    "title": "7  Exploratory-Data-Analysis-EDA",
    "section": "7.3 Data tidying",
    "text": "7.3 Data tidying\nIt is often said that 80% of data analysis is spent on the cleaning and preparing data. And it’s not just a first step, but it must be repeated many times over the course of analysis as new problems come to light or new data is collected. To get a handle on the problem, this paper focuses on a small, but important, aspect of data cleaning that I call data tidying: structuring datasets to facilitate analysis.\nThe principles of tidy data provide a standard way to organise data values within a dataset. A standard makes initial data cleaning easier because you don’t need to start from scratch and reinvent the wheel every time. The tidy data standard has been designed to facilitate initial exploration and analysis of the data, and to simplify the development of data analysis tools that work well together. Current tools often require translation. You have to spend time munging the output from one tool so you can input it into another. Tidy datasets and tidy tools work hand in hand to make data analysis easier, allowing you to focus on the interesting domain problem, not on the uninteresting logistics of data.\nFor us being able to compare, we need to standardize the data. First we standardize the landed catches and fetching price by number of fishers and fishing time. Unfortunately, our dataset miss information of the fishing time, but it provide the departure and return time for a particular fishing event. The code below does that.\n\nmimp.clean = mimp %>% \n  # select(going_time, return_time) %>% \n  separate(going_time, into = c(\"day\", \"time_leave\"), sep = \" \")%>% \n  separate(return_time, into = c(\"day\", \"time_return\"), sep = \" \") %>% \n  mutate(time_leave = lubridate::hms(time_leave),\n         time_return = lubridate::hms(time_return),\n         fishing_time = time_return-time_leave,\n         fishing_time_sec = as.numeric(fishing_time),\n         fishing_time_hour = (fishing_time_sec/3600) %>% round(1)) %>% \n  select(-c(time_leave, day, fishing_time, fishing_time_sec, time_return)) %>% \n  relocate(fishing_time_hour,.after = date)\n\nmimp.clean\n\n# A tibble: 41,404 x 12\n   district village    landing date                fishi~1 fishe~2 gear_~3 order\n   <chr>    <chr>      <chr>   <dttm>                <dbl>   <dbl> <chr>   <chr>\n 1 Mafia    Chunguruma Tumbuju 2009-09-14 00:00:00     6        15 BEACH ~ DASY~\n 2 Mafia    Chunguruma Tumbuju 2009-09-14 00:00:00     6        15 BEACH ~ LETH~\n 3 Mafia    Kiegeani   Utende  2010-01-15 00:00:00     4.5       1 STICK/~ Octo~\n 4 Mafia    Miburani   Kitoni  2010-01-29 00:00:00     3         1 STICK/~ BELO~\n 5 Mafia    Dongo      Magema~ 2009-06-17 00:00:00     3         1 STICK/~ SPHY~\n 6 Mafia    Chunguruma Tumbuju 2009-09-19 00:00:00     7        18 STICK/~ CHIR~\n 7 Mafia    Chunguruma Tumbuju 2009-09-19 00:00:00     7        18 STICK/~ GERR~\n 8 Mafia    Bwejuu     Bwejuu  2009-12-13 00:00:00    23         1 DEMA T~ LETH~\n 9 Mafia    Bwejuu     Bwejuu  2009-12-13 00:00:00    23         1 DEMA T~ LETH~\n10 Mafia    Bwejuu     Bwejuu  2009-12-13 00:00:00    23         1 DEMA T~ SCAR~\n# ... with 41,394 more rows, 4 more variables: priority <chr>, weight <dbl>,\n#   fish_number <dbl>, fish_price <dbl>, and abbreviated variable names\n#   1: fishing_time_hour, 2: fishermen, 3: gear_type\n\n\n\nmimp.cpue.income = mimp.clean %>% \n  mutate(cpue_fisher = weight/fishermen, \n         cpue_time = weight/fishing_time_hour, \n         income_fisher = fish_price/fishermen)\n\nThe fishing pattern in Mafia like other areas in the Western Indian Ocean is influenced with seasonal changes in trade winds that form the two distinct northeast (NE) and southeast (SE) monsoon seasons. We can derive the seasonality from the date variable into two steps. First derive the month variable as numeric and then all records that fall between May and September are denoted as SE monsoon season and the remaining months as NE monsoon season as code below illustrates:\n\nmimp.cpue.income.season = mimp.cpue.income %>% \n  mutate(month = lubridate::month(date),\n         season = if_else(month >=5 & month <10, \"SE\", \"NE\")) %>% \n  relocate(season,.after = date)"
  },
  {
    "objectID": "eda.html#summary-of-the-dataset",
    "href": "eda.html#summary-of-the-dataset",
    "title": "7  Exploratory-Data-Analysis-EDA",
    "section": "7.4 Summary of the Dataset",
    "text": "7.4 Summary of the Dataset\nThe box plot is a standardized way of displaying the distribution of numeric data based on the five-number summary:\n\n\nWarning in mask$eval_all_mutate(quo): NAs introduced by coercion\n\n\n\n\n\nFigure 7.1: illustration of five summary number presented in boxplot\n\n\n\n\nIn base R, the most functions for summarizing vector and data frames is summary() and fivenum() for numeric vectors:\n\nmimp.cpue.income.season %>% \n  pull(income_fisher) %>% \n  summary()\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n       0     3000     6300    12069    13333 11000000 \n\n\n\nmimp.cpue.income.season %>% \n  pull(cpue_fisher) %>% \n  summary()\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n   0.000    2.000    4.000    6.373    7.500 1430.000 \n\n\n\nmimp.cpue.income.season %>% \n  pull(cpue_time) %>% \n  summary()\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n  -1.1429    0.4286    0.8696    3.1535    2.0000 2000.0000 \n\n\n\n7.4.1 Skimming Data frames\nBut, the skimr is designed to provide summary statistics about variables in data frames, tibbles, data tables and vectors. It is opinionated in its defaults, but easy to modify.The core function of skimr is skim(), which is designed to work with (grouped) data frames, and will try coerce other objects to data frames if possible. Like summary(), skim()’s method for data frames presents results for every column; the statistics it provides depend on the class of the variable.Results of skim() are printed horizontally, with one section per variable type and one row per variable.\n\nmimp.cpue.income.season %>% \n  skimr::skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n41404\n\n\nNumber of columns\n17\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n7\n\n\nnumeric\n9\n\n\nPOSIXct\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ndistrict\n0\n1.00\n5\n5\n0\n1\n0\n\n\nvillage\n0\n1.00\n5\n10\n0\n15\n0\n\n\nlanding\n0\n1.00\n5\n15\n0\n32\n0\n\n\nseason\n0\n1.00\n2\n2\n0\n2\n0\n\n\ngear_type\n0\n1.00\n5\n20\n0\n17\n0\n\n\norder\n4399\n0.89\n2\n14\n0\n36\n0\n\n\npriority\n5296\n0.87\n4\n13\n0\n6\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nfishing_time_hour\n0\n1\n10.48\n7.10\n-7.00\n6.00\n7.5e+00\n11.00\n2.35e+01\n▁▃▇▁▃\n\n\nfishermen\n0\n1\n3.28\n13.90\n1.00\n1.00\n2.0e+00\n4.00\n1.40e+03\n▇▁▁▁▁\n\n\nweight\n0\n1\n22.63\n144.77\n0.00\n4.00\n7.0e+00\n15.00\n1.20e+04\n▇▁▁▁▁\n\n\nfish_number\n0\n1\n63.08\n541.28\n0.00\n6.00\n1.6e+01\n35.00\n3.00e+04\n▇▁▁▁▁\n\n\nfish_price\n0\n1\n34899.47\n221781.68\n0.00\n6000.00\n1.2e+04\n26400.00\n3.30e+07\n▇▁▁▁▁\n\n\ncpue_fisher\n0\n1\n6.37\n16.18\n0.00\n2.00\n4.0e+00\n7.50\n1.43e+03\n▇▁▁▁▁\n\n\ncpue_time\n0\n1\n3.15\n22.58\n-1.14\n0.43\n8.7e-01\n2.00\n2.00e+03\n▇▁▁▁▁\n\n\nincome_fisher\n0\n1\n12068.85\n59879.33\n0.00\n3000.00\n6.3e+03\n13333.33\n1.10e+07\n▇▁▁▁▁\n\n\nmonth\n0\n1\n6.58\n3.45\n1.00\n3.00\n6.0e+00\n10.00\n1.20e+01\n▇▅▅▅▇\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate\n0\n1\n2009-03-12\n2018-11-15\n2011-09-11\n2667\n\n\n\n\n\nA summaryTool package has a nifty dfSummary function, which creates a summary table with statistics, frequencies and graphs for all variables in a data frame. The information displayed is type-specific (character, factor, numeric, date) and also varies according to the number of distinct values. To see the results in RStudio’s Viewer (or in the default Web browser if working in another IDE or from a terminal window), use stview():\n\nmimp.cpue.income.season %>% \n  summarytools::dfSummary(\n          plain.ascii  = FALSE, \n          style        = \"grid\", \n          graph.magnif = 0.75, \n          valid.col    = FALSE,\n          tmp.img.dir  = \"/tmp\"\n  ) %>% \n  summarytools::stview()\n\nA summaryTool package has also nifty descr function that compute and present summary statistics i.e common central tendency statistics and measure of dispersion. It accept a single vector or data frame\n\nmimp.cpue.income.season %>% \n  select(is.numeric) %>% \n  summarytools::descr() %>%\n  print(method = \"render\")\n\nWarning: Predicate functions must be wrapped in `where()`.\n\n  # Bad\n  data %>% select(is.numeric)\n\n  # Good\n  data %>% select(where(is.numeric))\n\ni Please update your code.\nThis message is displayed once per session.\n\n\n\n\nDescriptive Statistics\nmimp.cpue.income.season\nN: 41404\n\n\n  \n    \n      \n      cpue_fisher\n      cpue_time\n      fish_number\n      fish_price\n      fishermen\n      fishing_time_hour\n      income_fisher\n      month\n      weight\n    \n  \n  \n    \n      \n        Mean\n      6.37\n      3.15\n      63.08\n      34899.47\n      3.28\n      10.48\n      12068.85\n      6.58\n      22.63\n    \n    \n      \n        Std.Dev\n      16.18\n      22.58\n      541.28\n      221781.68\n      13.90\n      7.10\n      59879.33\n      3.45\n      144.77\n    \n    \n      \n        Min\n      0.00\n      -1.14\n      0.00\n      0.00\n      1.00\n      -7.00\n      0.00\n      1.00\n      0.00\n    \n    \n      \n        Q1\n      2.00\n      0.43\n      6.00\n      6000.00\n      1.00\n      6.00\n      3000.00\n      3.00\n      4.00\n    \n    \n      \n        Median\n      4.00\n      0.87\n      16.00\n      12000.00\n      2.00\n      7.50\n      6300.00\n      6.00\n      7.00\n    \n    \n      \n        Q3\n      7.50\n      2.00\n      35.00\n      26400.00\n      4.00\n      11.00\n      13333.33\n      10.00\n      15.00\n    \n    \n      \n        Max\n      1430.00\n      2000.00\n      30000.00\n      33000000.00\n      1400.00\n      23.50\n      11000000.00\n      12.00\n      12000.00\n    \n    \n      \n        MAD\n      3.46\n      0.89\n      19.27\n      11860.80\n      1.48\n      2.97\n      6375.18\n      4.45\n      5.93\n    \n    \n      \n        IQR\n      5.50\n      1.57\n      29.00\n      20400.00\n      3.00\n      5.00\n      10333.33\n      7.00\n      11.00\n    \n    \n      \n        CV\n      2.54\n      7.16\n      8.58\n      6.35\n      4.24\n      0.68\n      4.96\n      0.52\n      6.40\n    \n    \n      \n        Skewness\n      47.06\n      41.54\n      28.06\n      90.19\n      63.87\n      1.06\n      153.94\n      -0.03\n      38.43\n    \n    \n      \n        SE.Skewness\n      0.01\n      0.01\n      0.01\n      0.01\n      0.01\n      0.01\n      0.01\n      0.01\n      0.01\n    \n    \n      \n        Kurtosis\n      3300.81\n      2592.00\n      1013.58\n      12210.52\n      4800.50\n      -0.59\n      27623.67\n      -1.29\n      2312.57\n    \n    \n      \n        N.Valid\n      41404\n      41404\n      41404\n      41404\n      41404\n      41404\n      41404\n      41404\n      41404\n    \n    \n      \n        Pct.Valid\n      100.00\n      100.00\n      100.00\n      100.00\n      100.00\n      100.00\n      100.00\n      100.00\n      100.00\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.1.3)2022-10-24\n\n\n\nA descr function allows to transpose results by parsing transpose = TRUE argument, and statistics can be selected using the stats argument:\n\nmimp.cpue.income.season %>% \n  select(is.numeric) %>% \n  summarytools::descr(stats = c(\"mean\", \"sd\"), transpose = TRUE, headings = FALSE) %>%\n  print(method = \"render\")\n\n\n\n\n  \n    \n      \n      Mean\n      Std.Dev\n    \n  \n  \n    \n      \n        cpue_fisher\n      6.37\n      16.18\n    \n    \n      \n        cpue_time\n      3.15\n      22.58\n    \n    \n      \n        fish_number\n      63.08\n      541.28\n    \n    \n      \n        fish_price\n      34899.47\n      221781.68\n    \n    \n      \n        fishermen\n      3.28\n      13.90\n    \n    \n      \n        fishing_time_hour\n      10.48\n      7.10\n    \n    \n      \n        income_fisher\n      12068.85\n      59879.33\n    \n    \n      \n        month\n      6.58\n      3.45\n    \n    \n      \n        weight\n      22.63\n      144.77\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.1.3)2022-10-24\n\n\n\n\n\n7.4.2 Frequencies\nsummarytools package has freq fuction, which generates frequency tablew with counts, proportions and missing data information.\n\n\n7.4.3 Village records\n\nmimp.cpue.income.season %$% \n  summarytools::freq(x = village, plain.ascii = FALSE, style = \"rmarkdown\", headings = FALSE) %>%\n  print(method = \"render\")\n\n\n\n\n  \n    \n      \n      Valid\n      Total\n    \n    \n      village\n      Freq\n      %\n      % Cum.\n      %\n      % Cum.\n    \n  \n  \n    \n      Banja\n      1\n      0.0024\n      0.0024\n      0.0024\n      0.0024\n    \n    \n      Bwejuu\n      12703\n      30.68\n      30.68\n      30.68\n      30.68\n    \n    \n      Bweni\n      2\n      0.0048\n      30.69\n      0.0048\n      30.69\n    \n    \n      Chole\n      1\n      0.0024\n      30.69\n      0.0024\n      30.69\n    \n    \n      Chunguruma\n      1461\n      3.53\n      34.22\n      3.53\n      34.22\n    \n    \n      Dongo\n      4366\n      10.54\n      44.76\n      10.54\n      44.76\n    \n    \n      Juani\n      6601\n      15.94\n      60.71\n      15.94\n      60.71\n    \n    \n      Kanga\n      1087\n      2.63\n      63.33\n      2.63\n      63.33\n    \n    \n      Kiegeani\n      6824\n      16.48\n      79.81\n      16.48\n      79.81\n    \n    \n      Kifinge\n      1\n      0.0024\n      79.82\n      0.0024\n      79.82\n    \n    \n      Kilindoni\n      2205\n      5.33\n      85.14\n      5.33\n      85.14\n    \n    \n      Malimbani\n      1\n      0.0024\n      85.14\n      0.0024\n      85.14\n    \n    \n      Mbarakuni\n      10\n      0.024\n      85.17\n      0.024\n      85.17\n    \n    \n      Miburani\n      5186\n      12.53\n      97.69\n      12.53\n      97.69\n    \n    \n      Utende\n      955\n      2.31\n      100.00\n      2.31\n      100.00\n    \n    \n      <NA>\n      0\n      \n      \n      0.00\n      100.00\n    \n    \n      Total\n      41404\n      100.00\n      100.00\n      100.00\n      100.00\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.1.3)2022-10-24\n\n\n\n\n\n7.4.4 Priority fish\n\nmimp.cpue.income.season %$% \n  summarytools::freq(x = priority, plain.ascii = FALSE, style = \"rmarkdown\", headings = FALSE)%>%\n  print(method = \"render\")\n\n\n\n\n  \n    \n      \n      Valid\n      Total\n    \n    \n      priority\n      Freq\n      %\n      % Cum.\n      %\n      % Cum.\n    \n  \n  \n    \n      Elasmobranch\n      1680\n      4.65\n      4.65\n      4.06\n      4.06\n    \n    \n      Octopus\n      6200\n      17.17\n      21.82\n      14.97\n      19.03\n    \n    \n      Others\n      245\n      0.68\n      22.50\n      0.59\n      19.62\n    \n    \n      Reef fish\n      23463\n      64.98\n      87.48\n      56.67\n      76.29\n    \n    \n      Small pelagic\n      2376\n      6.58\n      94.06\n      5.74\n      82.03\n    \n    \n      Tuna\n      2144\n      5.94\n      100.00\n      5.18\n      87.21\n    \n    \n      <NA>\n      5296\n      \n      \n      12.79\n      100.00\n    \n    \n      Total\n      41404\n      100.00\n      100.00\n      100.00\n      100.00\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.1.3)2022-10-24\n\n\n\n\n\n7.4.5 Gear\n\nmimp.cpue.income.season %$% \n  summarytools::freq(x = gear_type, plain.ascii = FALSE, style = \"rmarkdown\", headings = FALSE)%>%\n  print(method = \"render\")\n\n\n\n\n  \n    \n      \n      Valid\n      Total\n    \n    \n      gear_type\n      Freq\n      %\n      % Cum.\n      %\n      % Cum.\n    \n  \n  \n    \n      BEACH SEINE NETS\n      337\n      0.81\n      0.81\n      0.81\n      0.81\n    \n    \n      CAST NET\n      329\n      0.79\n      1.61\n      0.79\n      1.61\n    \n    \n      DEMA TRAPS\n      10570\n      25.53\n      27.14\n      25.53\n      27.14\n    \n    \n      FENCED TRAP\n      61\n      0.15\n      27.28\n      0.15\n      27.28\n    \n    \n      GILL NET 2 PLY 2\n      1068\n      2.58\n      29.86\n      2.58\n      29.86\n    \n    \n      GILL NET 2.5 PLY 9\n      6332\n      15.29\n      45.16\n      15.29\n      45.16\n    \n    \n      GILL NET 3 PLY 3\n      324\n      0.78\n      45.94\n      0.78\n      45.94\n    \n    \n      GILL NET 3.5 PLY 3.5\n      43\n      0.10\n      46.04\n      0.10\n      46.04\n    \n    \n      GILL NET 4 PLY 4\n      218\n      0.53\n      46.57\n      0.53\n      46.57\n    \n    \n      HAND HELD NETS\n      82\n      0.20\n      46.77\n      0.20\n      46.77\n    \n    \n      HAND LINE\n      10774\n      26.02\n      72.79\n      26.02\n      72.79\n    \n    \n      LONG LINE\n      1486\n      3.59\n      76.38\n      3.59\n      76.38\n    \n    \n      RING NET\n      846\n      2.04\n      78.42\n      2.04\n      78.42\n    \n    \n      SHARK NETS\n      2139\n      5.17\n      83.59\n      5.17\n      83.59\n    \n    \n      SHARK NETS DRIFTING\n      17\n      0.041\n      83.63\n      0.041\n      83.63\n    \n    \n      STICK/SPEAR\n      6699\n      16.18\n       99.81\n      16.18\n       99.81\n    \n    \n      TRAWL\n      79\n      0.19\n      100.00\n      0.19\n      100.00\n    \n    \n      <NA>\n      0\n      \n      \n      0.00\n      100.00\n    \n    \n      Total\n      41404\n      100.00\n      100.00\n      100.00\n      100.00\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.1.3)2022-10-24\n\n\n\n\n\n7.4.6 Missing Data\nOne of summarytools’ main purposes is to help cleaning and preparing data for further analysis. But in some circumstances, we don’t need (or already have) information about missing data. Using report.nas = FALSE makes the output table smaller by one row and two columns:\n\nmimp.cpue.income.season %$% \n  summarytools::freq(x = gear_type, plain.ascii = FALSE, report.nas = FALSE, style = \"rmarkdown\")%>%\n  print(method = \"render\")\n\n\n\nFrequencies\nmimp.cpue.income.season$gear_type\nType: Character\n\n\n  \n    \n      gear_type\n      Freq\n      %\n      % Cum.\n    \n  \n  \n    \n      BEACH SEINE NETS\n      337\n      0.81\n      0.81\n    \n    \n      CAST NET\n      329\n      0.79\n      1.61\n    \n    \n      DEMA TRAPS\n      10570\n      25.53\n      27.14\n    \n    \n      FENCED TRAP\n      61\n      0.15\n      27.28\n    \n    \n      GILL NET 2 PLY 2\n      1068\n      2.58\n      29.86\n    \n    \n      GILL NET 2.5 PLY 9\n      6332\n      15.29\n      45.16\n    \n    \n      GILL NET 3 PLY 3\n      324\n      0.78\n      45.94\n    \n    \n      GILL NET 3.5 PLY 3.5\n      43\n      0.10\n      46.04\n    \n    \n      GILL NET 4 PLY 4\n      218\n      0.53\n      46.57\n    \n    \n      HAND HELD NETS\n      82\n      0.20\n      46.77\n    \n    \n      HAND LINE\n      10774\n      26.02\n      72.79\n    \n    \n      LONG LINE\n      1486\n      3.59\n      76.38\n    \n    \n      RING NET\n      846\n      2.04\n      78.42\n    \n    \n      SHARK NETS\n      2139\n      5.17\n      83.59\n    \n    \n      SHARK NETS DRIFTING\n      17\n      0.041\n      83.63\n    \n    \n      STICK/SPEAR\n      6699\n      16.18\n       99.81\n    \n    \n      TRAWL\n      79\n      0.19\n      100.00\n    \n    \n      Total\n      41404\n      100.00\n      100.00\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.1.3)2022-10-24\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe headings = FALSE parameter suppresses the heading section.\n\n\n\n\n7.4.7 Cross-Tabulations:\nctable() generates cross-tabulations (joint frequencies) for pairs of categorical variables. Using the tobacco simulated data frame, we’ll cross-tabulate the two categorical variables smoker and diseased.\n\nmimp.cpue.income.season %$% \n  summarytools::ctable(x = priority, \n                       y = season, \n                       prop = \"c\", \n                       totals = FALSE, \n                       headings = FALSE)%>%\n  print(method = \"render\")\n\n\n\n\n\n\n\nseason\n\n\n\npriority\n\nNE\nSE\n\n\n\n\n\nElasmobranch\n\n1035\n(\n4.2%\n)\n645\n(\n3.9%\n)\n\n\n\nOctopus\n\n3795\n(\n15.2%\n)\n2405\n(\n14.6%\n)\n\n\n\nOthers\n\n150\n(\n0.6%\n)\n95\n(\n0.6%\n)\n\n\n\nReef fish\n\n14120\n(\n56.7%\n)\n9343\n(\n56.6%\n)\n\n\n\nSmall pelagic\n\n1523\n(\n6.1%\n)\n853\n(\n5.2%\n)\n\n\n\nTuna\n\n1241\n(\n5.0%\n)\n903\n(\n5.5%\n)\n\n\n\n<NA>\n\n3041\n(\n12.2%\n)\n2255\n(\n13.7%\n)\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.1.3)2022-10-24\n\n\n\n\n\n7.4.8 Chi-Square (𝛘2), Odds Ratio and Risk Ratio\nTo display the chi-square statistic, set chisq = TRUE. For 2 x 2 tables, use OR and RR to show odds ratio and risk ratio (also called relative risk), respectively. Those can be set to TRUE, in which case 95% confidence intervals are shown; to use different confidence levels, use for example OR = .90.\n\nmimp.cpue.income.season %>% \n  filter(priority %in% c(\"Reef fish\", \"Octopus\")) %>% \n  drop_na() %$% \n  summarytools::ctable(x = priority, \n                       y = season, \n                       prop = \"r\", \n                       chisq = TRUE,\n                       OR = TRUE,\n                       RR = TRUE,\n                       totals = FALSE, \n                       headings = FALSE)%>%\n  print(method = \"render\")\n\n\n\n\n\n\n\nseason\n\n\n\npriority\n\nNE\nSE\n\n\n\n\n\nOctopus\n\n3795\n(\n61.2%\n)\n2405\n(\n38.8%\n)\n\n\n\nReef fish\n\n14120\n(\n60.2%\n)\n9343\n(\n39.8%\n)\n\n\n\n\n Χ2 = 2.1315   df = 1   p = .1443O.R. (95% C.I.) = 1.04  (0.99 - 1.11)\n        R.R. (95% C.I.) = 1.02  (0.99 - 1.04)\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.1.3)2022-10-24"
  },
  {
    "objectID": "eda.html#visualization",
    "href": "eda.html#visualization",
    "title": "7  Exploratory-Data-Analysis-EDA",
    "section": "7.5 Visualization",
    "text": "7.5 Visualization\n\nmimp.cpue.income.season %>% \n  group_by(village) %>% \n  tally() %>% \n  ggplot(aes(x = reorder(village, n), y = n)) +\n  geom_col()+\n  coord_flip()\n\n\n\n\nFigure 7.2: Bar plot indicate that Bwejuu village has the highest records in the dataset\n\n\n\n\n\nmimp.cpue.income.season %>% \n  group_by(village, season) %>% \n  tally() %>% \n  ggplot(aes(x = reorder(village, n), y = n, fill = season)) +\n  geom_col(position = position_dodge2(width = .9))+\n  coord_flip()\n\n\n\n\nFigure 7.3: Bar plot indicate that Bwejuu village has the highest records in the dataset and the northeast monsoon season dominate across all villages\n\n\n\n\n\nmimp.cpue.income.season %>% \n  drop_na() %>% \n  group_by(priority) %>% \n  tally() %>% \n  ggplot(aes(x = reorder(priority, n), y = n)) +\n  geom_col(position = position_dodge2(width = .9))+\n  coord_flip()\n\n\n\n\nFigure 7.4: Bar plot indicate that there are five prirority fishes and Reef fish has the highest records in the dataset\n\n\n\n\n\nmimp.cpue.income.season %>% \n  drop_na() %>% \n  group_by(priority, season) %>% \n  tally() %>% \n  ggplot(aes(x = reorder(priority, n), y = n, fill = season)) +\n  geom_col(position = position_dodge2(width = .9))+\n  coord_flip()\n\n\n\n\nFigure 7.5: Bar plot indicate that there are five prirority fishes and Reef fish has the highest records in the dataset and the northeast monsoon season dominate across all villages\n\n\n\n\n\n\nmimp.cpue.income.season %>% \n  dplyr::group_by(priority) %>% \n  tidystats::describe_data(column = cpue_fisher, short = FALSE) %>% \n  ungroup() %>% \n  arrange(-median)\n\n# A tibble: 7 x 14\n  var   prior~1 missing     N     M    SD     SE    min   max range median  mode\n  <chr> <chr>     <int> <int> <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl>\n1 cpue~ Small ~       0  2376 12.4  16.9  0.346  0.0217  600   600.  10       14\n2 cpue~ Elasmo~       0  1680 10.7  12.8  0.313  0.111   206.  206.   7       20\n3 cpue~ Octopus       0  6200  6.75 16.1  0.204  0       900   900    5        2\n4 cpue~ Tuna          0  2144 11.8  25.3  0.546  0.1     667.  667.   5        5\n5 cpue~ Reef f~       0 23463  5.20 16.3  0.107  0      1430  1430    3.33     2\n6 cpue~ <NA>          0  5296  4.83  7.11 0.0978 0.05    125   125.   3        2\n7 cpue~ Others        0   245  7.24 27.2  1.74   0.167   300   300.   2.8      3\n# ... with 2 more variables: skew <dbl>, kurtosis <dbl>, and abbreviated\n#   variable name 1: priority\n\n\n\nmimp.cpue.income.season %>% \n  dplyr::group_by(gear_type) %>% \n  tidystats::describe_data(column = fish_price, short = FALSE) %>% \n  ungroup() %>% \n  arrange(-median)\n\n# A tibble: 17 x 14\n   var     gear_~1 missing     N      M     SD     SE   min    max  range median\n   <chr>   <chr>     <int> <int>  <dbl>  <dbl>  <dbl> <dbl>  <dbl>  <dbl>  <dbl>\n 1 fish_p~ RING N~       0   846 4.69e5 8.98e5 30880.   500 1.2 e7 1.20e7 200000\n 2 fish_p~ GILL N~       0   218 6.29e4 4.87e4  3301.  2000 5   e5 4.98e5  52000\n 3 fish_p~ HAND H~       0    82 7.26e4 1.11e5 12216.  2000 8.4 e5 8.38e5  36000\n 4 fish_p~ GILL N~       0   324 4.52e4 4.99e4  2772.  2000 5   e5 4.98e5  30000\n 5 fish_p~ SHARK ~       0    17 3.71e4 2.79e4  6760.  3000 9.6 e4 9.3 e4  28000\n 6 fish_p~ LONG L~       0  1486 3.24e4 4.28e4  1111.  1000 1.2 e6 1.20e6  24000\n 7 fish_p~ BEACH ~       0   337 5.04e4 7.28e4  3968.    90 7.56e5 7.56e5  22500\n 8 fish_p~ GILL N~       0    43 4.30e4 3.74e4  5700.  2500 1.36e5 1.34e5  21000\n 9 fish_p~ GILL N~       0  1068 3.55e4 4.62e4  1413.     6 8   e5 8.00e5  20000\n10 fish_p~ SHARK ~       0  2139 3.06e4 4.90e4  1059.   300 9.95e5 9.95e5  18000\n11 fish_p~ STICK/~       0  6699 4.56e4 7.82e4   956.     0 2.03e6 2.03e6  18000\n12 fish_p~ CAST N~       0   329 3.07e4 3.45e4  1900.    44 2.43e5 2.43e5  17500\n13 fish_p~ FENCED~       0    61 5.38e4 1.03e5 13168.  1800 7   e5 6.98e5  16000\n14 fish_p~ TRAWL         0    79 2.86e4 4.32e4  4857.   200 1.76e5 1.76e5  12000\n15 fish_p~ HAND L~       0 10774 2.36e4 3.21e5  3094.     1 3.3 e7 3.30e7  11400\n16 fish_p~ GILL N~       0  6332 1.97e4 4.00e4   503.     6 1.64e6 1.64e6  11000\n17 fish_p~ DEMA T~       0 10570 1.35e4 2.94e4   286.     0 1.35e6 1.35e6   7000\n# ... with 3 more variables: mode <dbl>, skew <dbl>, kurtosis <dbl>, and\n#   abbreviated variable name 1: gear_type\n\n\n\nmimp.fit = mimp.cpue.income.season %$% \n  lm(fish_price ~ priority)\n\nmimp.fit %>% \n  summary()\n\n\nCall:\nlm(formula = fish_price ~ priority)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n -145553   -19935   -13135    -1135 32978865 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              37001       5554   6.662 2.74e-11 ***\npriorityOctopus          10068       6262   1.608  0.10786    \npriorityOthers           70120      15569   4.504 6.69e-06 ***\npriorityReef fish       -15865       5750  -2.759  0.00579 ** \nprioritySmall pelagic    20486       7257   2.823  0.00476 ** \npriorityTuna            108852       7418  14.675  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 227700 on 36102 degrees of freedom\n  (5296 observations deleted due to missingness)\nMultiple R-squared:  0.01792,   Adjusted R-squared:  0.01778 \nF-statistic: 131.7 on 5 and 36102 DF,  p-value: < 2.2e-16\n\nmimp.fit%>% \n  report::report()\n\nWe fitted a linear model (estimated using OLS) to predict fish_price with\npriority (formula: fish_price ~ priority). The model explains a statistically\nsignificant and very weak proportion of variance (R2 = 0.02, F(5, 36102) =\n131.74, p < .001, adj. R2 = 0.02). The model's intercept, corresponding to\npriority = Elasmobranch, is at 37000.79 (95% CI [26114.48, 47887.10], t(36102)\n= 6.66, p < .001). Within this model:\n\n  - The effect of priority [Octopus] is statistically non-significant and\npositive (beta = 10068.16, 95% CI [-2204.76, 22341.09], t(36102) = 1.61, p =\n0.108; Std. beta = 0.04, 95% CI [-9.60e-03, 0.10])\n  - The effect of priority [Others] is statistically significant and positive\n(beta = 70119.62, 95% CI [39604.65, 1.01e+05], t(36102) = 4.50, p < .001; Std.\nbeta = 0.31, 95% CI [0.17, 0.44])\n  - The effect of priority [Reef fish] is statistically significant and negative\n(beta = -15865.40, 95% CI [-27134.72, -4596.09], t(36102) = -2.76, p = 0.006;\nStd. beta = -0.07, 95% CI [-0.12, -0.02])\n  - The effect of priority [Small pelagic] is statistically significant and\npositive (beta = 20485.69, 95% CI [6262.19, 34709.19], t(36102) = 2.82, p =\n0.005; Std. beta = 0.09, 95% CI [0.03, 0.15])\n  - The effect of priority [Tuna] is statistically significant and positive (beta\n= 1.09e+05, 95% CI [94313.55, 1.23e+05], t(36102) = 14.67, p < .001; Std. beta\n= 0.47, 95% CI [0.41, 0.54])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation."
  },
  {
    "objectID": "eda.html#references",
    "href": "eda.html#references",
    "title": "7  Exploratory-Data-Analysis-EDA",
    "section": "References",
    "text": "References\n\n\n\n\nCampitelli, Elio. 2019. metR: Tools for Easier Analysis of Meteorological Fields. https://CRAN.R-project.org/package=metR.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. http://ggplot2.org.\n\n\nWickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2018. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, and Lionel Henry. 2018. Tidyr: Easily Tidy Data with ’Spread()’ and ’Gather()’ Functions. https://CRAN.R-project.org/package=tidyr."
  },
  {
    "objectID": "maps.html",
    "href": "maps.html",
    "title": "8  Static Maps",
    "section": "",
    "text": "Along with all the geographical data making its way into the public domain, a variety of tools to map that data have also been developed. For a long time R base provides tools to map geographical data—data with latitude and longitude coordinates attached to it. However, mapping in the early days of R was not easy, it was not elegant either. Recently, several packages have been developed for mapping geographical data that align with the ggplot framework. So they allow us to map spatial data in similar ways as other plots with a grammar of graphic principle. For example Edzer Pebesma (2018) developed an awesome sf package for mapping vector data in R. The power of this function lies in the fact that it structure the spatial data in tidy format, allowing for easy manipulation with the tidyverse function and also for plotting with the ggplot2 flavor. The sf package allows you to read in and work with geographical data in a tidy format."
  },
  {
    "objectID": "maps.html#geographical-data-in-a-tidy-format",
    "href": "maps.html#geographical-data-in-a-tidy-format",
    "title": "8  Static Maps",
    "section": "8.1 Geographical data in a tidy format",
    "text": "8.1 Geographical data in a tidy format\nThe sf package allows you to create a simple feature—a data frame with additional columns that hold spatial component called the geometry. This column contains the geometrical nature of the data needed to draw the data. Often the sf object has two classes—the simple feature and the data.frame classes. The data.frame holds attribute information of the dataset and the geometry contains the geographical coordinates. For example, the simple feature displayed below is a dataset of sampling stations, where each row gives the data for each station. The data.frame here holds the first four columns— the id, type, depth and sst, whereas the geometry column include the geometry type, for this case the point and the embedded latitude and longitude geographical coordinates. There different ways to create simple feature in R using the sf package. We will create a few of them later that we will use for mapping examples.\nWe need to load the packages we are going to use in this chapter.\n\nrequire(sf)\nrequire(tidyverse)\n\n\n\nFALSE Simple feature collection with 11 features and 4 fields\nFALSE Geometry type: POINT\nFALSE Dimension:     XY\nFALSE Bounding box:  xmin: 39.50958 ymin: -8.425115 xmax: 42.00623 ymax: -6.414011\nFALSE Geodetic CRS:  WGS 84\nFALSE First 10 features:\nFALSE     id   type depth      sst                   geometry\nFALSE 1  294 marker    29 27.87999 POINT (39.50958 -6.438159)\nFALSE 2  300 marker  -604 27.97999  POINT (39.6318 -6.621774)\nFALSE 3  306 marker  -569 27.97999 POINT (39.65447 -6.746649)\nFALSE 4  312 marker  -485 28.03999 POINT (39.62563 -6.805321)\nFALSE 5  318 marker  -325 28.03999 POINT (39.58374 -6.833973)\nFALSE 6  326 marker  -461 28.03999 POINT (39.66476 -6.837384)\nFALSE 7  414 marker  -505 28.02999 POINT (39.95728 -7.843535)\nFALSE 8  428 marker  -132 28.23999 POINT (39.67712 -8.136846)\nFALSE 9  434 marker  -976 28.16999 POINT (39.74853 -8.425115)\nFALSE 10 456 marker -3311 28.33999 POINT (42.00623 -7.025368)\n\n\n\n8.1.1 Create simple feature from data.frame\n\n\n\nIf you have a regular dataframe, you can convert it into a simple feature object with tools in the sf package. For instance, in the working directory we have a dataset of eleven stations named points.csv. We can simply import this dataset into R session with the read_csv() function. If we print the file, it give about the variables and rows presented in the datasete. There six variables—id, type, depth and sst along with the latitude and longitude coordinates. These stations contains measured variable of sea surface temperature and their maximum depth.\n\nstations = read_csv(\"assets/shp//points.csv\")\nstations\n\n# A tibble: 11 x 6\n     lon   lat    id type   depth   sst\n   <dbl> <dbl> <dbl> <chr>  <dbl> <dbl>\n 1  39.5 -6.44   294 marker    29  27.9\n 2  39.6 -6.62   300 marker  -604  28.0\n 3  39.7 -6.75   306 marker  -569  28.0\n 4  39.6 -6.81   312 marker  -485  28.0\n 5  39.6 -6.83   318 marker  -325  28.0\n 6  39.7 -6.84   326 marker  -461  28.0\n 7  40.0 -7.84   414 marker  -505  28.0\n 8  39.7 -8.14   428 marker  -132  28.2\n 9  39.7 -8.43   434 marker  -976  28.2\n10  42.0 -7.03   456 marker -3311  28.3\n11  41.8 -6.41   462 marker -3248  28.6\n\n\nAthough this dataset contains geographical coordinates in it (latitude and longitude), it’s just a regular data frame. We can use the geographical coordinates in the dataframe to convert it to simple feature with the st_as_sf() function, and specify the columns with the geographical information using the coords parameter.\n\nsimple_feature = stations %>%\n  sf::st_as_sf(coords = c(\"lon\", \"lat\"))\n\nOnce we have the simple feature object, we can set the geographica coordinate system to World Geodetic System of 1984 (WGS84). I prefer using its code, which is easy to punch in instead of the whole text. If we print out the simple feature we just created, it gives the extra information at the top of the print-out, which include the number of features and columls(fields), the geometry type as point, the geographical extent (the bounding box) of and the projection both in epsg code and string.\n\nsimple_feature = simple_feature %>%\n  sf::st_set_crs(4326)\n\n\nggplot()+\n  geom_sf(data = simple_feature, aes(col = sst, size = wior::inverse_hyperbolic((sst))))+\n  scale_colour_gradientn(colors = oce::oce.colors9A(120))\n\n\n\n\n\n\n8.1.2 Importing shapefile\nWhen you create maps, you will often want to import shapefile—a widely used format for storing geographical data in GIS. sf package offers tools to read and load shapefiles into R. Let’s import africa’s country boundary shapefile from the working directory. We use the st_read() function from sf package to read the shapefile boundary layer. Like the simple features we created, the shapefile also display extra information at the top confirming that it’s no longer a shapefile but rather a simple feature.\n\n## read\nafrica = sf::st_read(\"assets/shp/africa.shp\", quiet = TRUE)\nafrica\n\nSimple feature collection with 59 features and 7 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -25.35875 ymin: -34.83983 xmax: 57.80085 ymax: 37.34962\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   COUNT               CNTRY_NAME FIPS_CNTRY LAND_AREA_ REGIONA EMPTY EMPTY2\n1     34                   Angola         AO     124670    <NA>     0      0\n2    114                  Burundi         BY       2783    <NA>     0      0\n3     77                    Benin         BN      11262    <NA>     0      0\n4    301             Burkina Faso         UV      27400    <NA>     0      0\n5     25                 Botswana         BC      58173    <NA>     0      0\n6     51 Central African Republic         CT      62298    <NA>     0      0\n7     51                 Cameroon         CM      47544    <NA>     0      0\n8    186              Ivory Coast         IV      32246    <NA>     0      0\n9     46                    Congo         CF      34200    <NA>     0      0\n10    15               Cape Verde         CV        403    <NA>     0      0\n                         geometry\n1  MULTIPOLYGON (((12.84118 -6...\n2  MULTIPOLYGON (((29.05021 -2...\n3  MULTIPOLYGON (((3.849006 10...\n4  MULTIPOLYGON (((-5.272945 1...\n5  MULTIPOLYGON (((23.14635 -1...\n6  MULTIPOLYGON (((22.03557 4....\n7  MULTIPOLYGON (((9.640797 3....\n8  MULTIPOLYGON (((-6.091862 4...\n9  MULTIPOLYGON (((16.45276 2....\n10 MULTIPOLYGON (((-24.64849 1...\n\n\nSince the layer is for the whole Africa, to reduce the processing time, we must reduce the geographical extent to the area of interest. We use the st_crop() function to chop the area that we want to map and discard the rest.\n\nkimbiji = africa %>% \n  sf::st_crop(xmin = 38.0,\n              xmax = 40.5, \n              ymin = -8, \n              ymax = -5.5)\n\n\n\n8.1.3 Reading other format\nSometimes you have geographical data that are neither in tabular form or shapefile. In that situation, you ought to use the st_layers() function to identify, first the driver used to create the file and, second, the layer name you want to extract. Once you have identified the layer of interest, you can use the st_read() function to import the layer from the file. For example, we have the track file that was recorded with a GPS device. Let’s explore the layer it contains with the `st_layers() function.\n\ntracks = sf::st_layers(\"assets//tracks/Track-181204-075451.gpx\")\ntracks\n\nDriver: GPX \nAvailable layers:\n    layer_name     geometry_type features fields\n1    waypoints             Point        1     19\n2       routes       Line String        0     12\n3       tracks Multi Line String        1     12\n4 route_points             Point        0     21\n5 track_points             Point     1467     24\n\n\nOnce we print, it shows that i’s a GPX format with five layer’s name. We are only interested with the tracks and track_points layers. We can extract them with the st_read() function, by specifying the dsn and the layer. This can be written as;\n\n## obtain track points\ntrack.points = sf::st_read(dsn =\"assets//tracks/Track-181204-075451.gpx\" ,layer = \"track_points\", quiet = TRUE)\n## drop other variable that are not needed\ntrack.points = track.points %>% select(elevation = ele, time, speed)\n## display\ntrack.points\n\nSimple feature collection with 1467 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 39.68927 ymin: -8.033337 xmax: 39.75059 ymax: -7.977127\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   elevation                time    speed                   geometry\n1       -3.7 2018-12-04 07:54:55 1.471591 POINT (39.75051 -7.977127)\n2       -5.0 2018-12-04 07:54:58 1.479312 POINT (39.75052 -7.977157)\n3       -5.6 2018-12-04 07:55:00 1.358867 POINT (39.75052 -7.977185)\n4       -5.8 2018-12-04 07:55:02 1.530269 POINT (39.75052 -7.977215)\n5       -5.9 2018-12-04 07:55:04 1.424751 POINT (39.75052 -7.977243)\n6       -6.1 2018-12-04 07:55:05 1.381000 POINT (39.75052 -7.977262)\n7       -6.2 2018-12-04 07:55:07 1.437619  POINT (39.75052 -7.97729)\n8       -6.3 2018-12-04 07:55:09 0.994958  POINT (39.75051 -7.97731)\n9       -6.3 2018-12-04 07:55:11 1.032018  POINT (39.75051 -7.97733)\n10      -6.4 2018-12-04 07:55:13 1.369676  POINT (39.7505 -7.977353)\n\n\n\ntrack = sf::st_read(dsn =\"assets//tracks/Track-181204-075451.gpx\" ,layer = \"tracks\", quiet = TRUE)\ntrack\n\nSimple feature collection with 1 feature and 12 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 39.68927 ymin: -8.033337 xmax: 39.75059 ymax: -7.977127\nGeodetic CRS:  WGS 84\n                               name  cmt\n1 Tracking android:60fd0ef637a6eb1b <NA>\n                                     desc  src link1_href link1_text link1_type\n1 Tracking recently started 12/4/18 07:54 <NA>       <NA>       <NA>       <NA>\n  link2_href link2_text link2_type number type                       geometry\n1       <NA>       <NA>       <NA>  10193 <NA> MULTILINESTRING ((39.75051 ..."
  },
  {
    "objectID": "maps.html#introduction",
    "href": "maps.html#introduction",
    "title": "8  Static Maps",
    "section": "8.2 Introduction",
    "text": "8.2 Introduction\nA satisfying and important aspect of geographic research is communicating the results in spatial context. With recent advance in technology from satellite, internet and mobile location services, the amount of geographical data has increased significantly. Plenty of data are generated daily with latitude and longitude coordinates attached to it both from satellite observation and social media. To be able to build up a good mental model of the spatial data, you need to invest considerable effort in making your maps as self-explanatory as possible. In this chapter, you’ll learn some of the tools that ggplot2 provides to make elegant maps and graphics (Wickham 2016).\nMaps are great way to understand patterns from data over space. They are scaled down versions of the physical world, and they’re everywhere. R has several systems for making graphs, but ggplot2 is one of the most elegant and most versatile. ggplot2 implements the grammar of graphics, a coherent system for describing and building graphs. The chapter also introduce you to some extended functionalities from sf (Pebesma 2018), cowplot (Wilke 2018), ggsn (ggsn?), ggsci (ggsci?), metR (Campitelli 2019), ggrepel (ggrepel?), gganimate (Pedersen and Robinson 2017) and egg (Auguie 2018) packages. Therefore, this chapter focuses on the tools you need to create good graphics. Rather than loading those extensions here, we’ll refer to their functions explicitly, using the :: notation. This will help make it clear which functions are built into ggplot2, and which come from other packages. Ensure you have these packages in your machine, otherwise install them with install.packages() if you don’t already have them."
  },
  {
    "objectID": "maps.html#static-maps",
    "href": "maps.html#static-maps",
    "title": "8  Static Maps",
    "section": "8.3 Static Maps",
    "text": "8.3 Static Maps\nStatic maps are the most common type of visual output from spatial objects. Fixed images for printed outputs, common formats for static maps include .png and .pdf, for raster and vector outputs, respectively. Initially static maps were the only type of map that R could produce. Things have advanced greatly since sp was released (see (sp?)). Many new techniques for map making have been developed since then. However, a decade later static plotting was still the emphasis of geographic data visualisation in R (Cheshire and Lovelace 2015).\nDespite the innovation of interactive mapping in R, static maps are still the foundation of mapping in R. The base plot() function is often the fastest way to create static maps from vector and raster spatial objects. Sometimes simplicity and speed are priorities, especially during the development phase of a project, and this is where plot() excels. The base R approach is also extensible, with plot() offering dozens of arguments. Another low-level approach is the grid package, which provides functions for low-level control of graphical outputs. This section, however, focus on how to make static maps with ggplot2, emphasizing the important aesthetic and layout options.\n\n8.3.1 The bathmetry data\nggplot2 works with data that are tidy—data frame arranged in such way that observations are in rows and variables are in columns and each value must have its own cell. But, the bathmetry data is from ETOPO1 and came in .asc format. First read the file with the raster::raster() function.\n\n## read the ascii file\ntz.bath = raster::raster(\"assets/raster/wioregio-7753.asc\")\ntz.bath %>% class()\n\n[1] \"RasterLayer\"\nattr(,\"package\")\n[1] \"raster\"\n\n\nWe notice that the file is raster and ggplot2 requires data.frame. To continue, we need to convert the data and tidy in format that is **plot2–readable. Specifically, we need to convert raster file into data frame with raster::as.data.frame(xy = TRUE) and specify the xy = TRUE argument. We then rename the x to lon, y to lat and convert bathmetry values from the double presion to integer and select values within the geographical extend of interest and depth between 0 and 1200 meter deep.\n\n## convert raster to data frame\ntz.bath.df = tz.bath %>% \n  raster::as.data.frame(xy = TRUE) %>%\n  dplyr::as_tibble()\n\n## rename the variable\ntz.bath.df = tz.bath.df %>% \n  dplyr::rename(lon = x, lat = y, depth = 3)%>% \n  dplyr::mutate(depth = as.integer(depth))\n\n## chop the area of interest \noff.kimbiji = tz.bath.df %>% \n  dplyr::filter(lon > 38.5 & lon < 40 & \n           lat > -7.2 & lat < - 6 & \n           depth > -1200& depth < 0  )\n\nThe bathmetry file now contain three variables, the lon, lat and depth as seen in table @ref(tab:tab91)\n\noff.kimbiji %>%\n  dplyr::sample_n(10) %>%\n  knitr::kable(col.names = c(\"Longitude\", \"Latitude\", \"Depth (meters)\"), digits = 3,\n               caption = \"Ten randomly selected points of bathmetry values off Kimbiji, Tanzania\", align = \"c\")%>%\n  kableExtra::column_spec(column = 2:3, width = \"3cm\")%>%\n  kableExtra::add_header_above(c(\"Coordinate (Degree)\" = 2,\"\"))\n\n\n\nTen randomly selected points of bathmetry values off Kimbiji, Tanzania\n \n\nCoordinate (Degree)\n\n\n  \n    Longitude \n    Latitude \n    Depth (meters) \n  \n \n\n  \n    39.067 \n    -6.033 \n    -6 \n  \n  \n    39.850 \n    -6.683 \n    -548 \n  \n  \n    39.517 \n    -6.600 \n    -407 \n  \n  \n    39.967 \n    -6.833 \n    -149 \n  \n  \n    39.500 \n    -6.867 \n    -25 \n  \n  \n    39.717 \n    -6.267 \n    -669 \n  \n  \n    39.567 \n    -7.050 \n    -46 \n  \n  \n    39.300 \n    -6.750 \n    -15 \n  \n  \n    39.017 \n    -6.400 \n    -1 \n  \n  \n    39.700 \n    -6.700 \n    -616"
  },
  {
    "objectID": "maps.html#basemap",
    "href": "maps.html#basemap",
    "title": "8  Static Maps",
    "section": "8.4 Basemap",
    "text": "8.4 Basemap\nWe also need basemap—country boundary layer. We use the st_read() function from sf package to read the shapefile boundary layer. Since the layer is for the whole Africa, to reduce the processing time for ploting the map of africa, we use the st_crop() function to chop the area of interest.\n\nkimbiji = africa %>% sf::st_crop(xmin = 38.0, xmax = 40.5, ymin = -8, ymax = -5.5)"
  },
  {
    "objectID": "maps.html#creating-contour-map",
    "href": "maps.html#creating-contour-map",
    "title": "8  Static Maps",
    "section": "8.5 Creating contour map",
    "text": "8.5 Creating contour map\nOnce we have the data ready, we can tools in ggplot2 and add-on packages to create the bathmetry map off–Kimbiji located between longitude 38.5°E and 40.1°E and latitude 7.2°S and `r metR::LatLabel(-6.0). The code block below was used to create (fig901?).\n\n\n\n\n\nMap of Off-Kimbiji showing contour lines. The grey lines are contour at 50 m interval and the black line are contoured at 200 m intervals\n\n\n\n\nThere are fourteen lined of codes in the chunk to make figure @ref(fig:fig901). That’s a lot! Don’t get intimidated, I will explain in detail how each line of code work together to make this figure. As before, you start plotting ggplot2 with the ggplot() function as the first line. Surprisingly, the ggplot() is empty without any argument specified. When mapping with geom_sf() function in ggplot2 package, you are advised to leave the ggplot() function empty. This will allow the geom_sf() to label the axes with the appropriate geographical labelling for longitude and latitude. The second line of gode add a simple feature with a geom_sf() function from sf package. Note however, I specified the geom_sf() to fill the boundary layer with grey of 90 shade and the stroke with black colour.\n\nmap = ggplot()+\n  geom_sf(data = kimbiji, fill = \"grey90\", col = \"grey40\")\nmap \n\n\n\n\nnote that ggplot2 plot the map with default aesthetic settings. The plot background is filled with gray color and without stroke but the grids are white colored. The third line add the contour lines spaced at 50 meter intervals. Instead of using geom_contour() from ggplot2, the geom_contour2() from metR package was used. They both serve the same task.\n\nmap = map +\n  geom_sf(data = kimbiji, fill = \"grey90\", col = \"grey40\")+\n  metR::geom_contour2(data = off.kimbiji, \n               aes(x = lon, y = lat, z=depth), binwidth = 50, col = \"grey\")\nmap\n\n\n\n\nLike the third line, the fourth line add contour lines, but instead of spacing them into meters, these are spaced at 200 meters interval and are black in color.\n\nmap = map +\n  metR::geom_contour2(data = off.kimbiji, \n               aes(x = lon, y = lat, z=depth), binwidth = 200)\nmap\n\n\n\n\nThe fifth line add the label on contour spaced at 200 meter interval with geom_text_contour() function from metR package. Here is where you will find the useful of package like metR that extends the ggplot2, for which the current version (2.3.1.1) is unable.\n\nmap = map +\n  metR::geom_contour2(data = off.kimbiji, \n               aes(x = lon, y = lat, z=depth, label = ..level..), binwidth = 200, skip = 0)\nmap\n\n\n\n\nThe sixth line zoom the map to only the geographical extent we are interested with using the coord_sf() function from sf package. We could also use the coord_cartesin() to limit the area.\n\nmap = map +\n  coord_sf(xlim = c(39.2, 39.8), ylim = c(-7, -6.3))\nmap\n\n\n\n\nWe got a glimpse of the map now, let us use theme to make some changes. The background was set to white with panel.background = element_rect(fill = \"white\"), and removed grids with panel.grid = element_line(colour = NA) and change the font size of the axis label to 11 points with axis.text = element_text(size = 11). The theme_bw() just set the border of the plot to black with solid line.\n\nmap = map +\n  theme_bw()+\n  theme(panel.background = element_rect(fill = \"white\"),\n        panel.grid = element_line(colour = NA),\n        axis.text = element_text(size = 11))\nmap\n\n\n\n\nThe good thing to start making maps is with an understanding of the map elements. A static map can be composed of many different map elements. These include main map body, legend, title, scale indicator, orientation indicator, inset map and source or ancillary information. By increasing the font size of axis textual label to 11, the axes are cluttered. adding the scale can improve the labelling. scale_x_continuous(breaks = seq(39.2, 39.8, .2)) in line 9 force ggplot2 to label the x–axis four letter that are spaced with 0.2 latitude and scale_y_continuous(breaks = seq(-6.95, -6.35, length.out = 4)) in line 10 label four digits of longitude.\n\nmap = map+\n  scale_x_continuous(breaks = seq(39.2, 39.8, .2))+\n  scale_y_continuous(breaks = seq(-6.95, -6.35, length.out = 4))\n\nmap\n\n\n\n\nBecause the axes are abbreviated with longitude and latitude symbol, line 11 in the code remove the axes title label. Line 12 to 14 add textual label on the map with the annotate() function.\n\nmap = map +\n  theme(axis.title = element_blank())+\n  annotate(geom = \"text\", x = 39.28, y = -6.48, label = \"Zanzibar \\nChannel\")+\n  annotate(geom = \"text\", x = 39.5, y = -6.37, label = \"Unguja \\nIsland\")+\n  annotate(geom = \"text\", x = 39.3, y = -6.91, label = \"Dar es Salaam\")\n\nmap\n\n\n\n\nClose look of figure @ref(fig:fig901), the north arrrow and the scale bar are missing. The last two lines of our code inset the scalebar and north arrow on map using the annotation_scale() and ggspatial::annotation_north_arrow() functions from ggspatial package.\nIn a nutshell, making this map using ggplot2 and ancillary extensions used fiften line codes and hundred of arguments. This are very common task of making maps with the combination of tools from different packages.\n\nmap +\n  ggspatial::annotation_scale(height = unit(.35, \"cm\"), pad_x = unit(.5, \"cm\"),\n                              tick_height = unit(3, \"cm\"), pad_y = unit(.5, \"cm\"), text_cex = .85)+\n  ggspatial::annotation_north_arrow(location = \"tr\", width = unit(.75, \"cm\"), height = unit(1, \"cm\"))\n\n\n\n\nmetR package has geom_contour_fill() function that draw filled contour lines and geom_contour_tanaka(), which illunate contours with varying brithtness to create an illusion of relief. The code chunk to create highlighted filled contour using metR function can be written as;\n\nggplot()+\n  metR::geom_contour_fill(data = off.kimbiji, \n               aes(x = lon, y = lat, z=depth), na.fill = TRUE, show.legend = FALSE)+\n  metR::geom_contour_tanaka(data = off.kimbiji, \n               aes(x = lon, y = lat, z=depth))+\n  metR::geom_text_contour(data = off.kimbiji, aes(x = lon, y = lat, z=depth), \n                          rotate = TRUE, check_overlap = TRUE, size = 3.0)+\n  geom_sf(data = kimbiji, fill = \"grey90\", col = \"grey40\")+\n  coord_sf(xlim = c(39.2, 39.8), ylim = c(-7, -6.3))+\n  theme_bw()+\n  theme(panel.background = element_rect(fill = \"white\"),\n        panel.grid = element_line(colour = NA),\n        axis.text = element_text(size = 11))+\n  scale_x_continuous(breaks = seq(39.2, 39.8, .2))+\n  scale_y_continuous(breaks = seq(-6.95, -6.35, length.out = 4))+\n  scale_fill_gradientn(colours = oce::oce.colorsGebco(120))+\n  labs(x = NULL, y = NULL)+\n  annotate(geom = \"text\", x = 39.28, y = -6.48, label = \"Zanzibar \\nChannel\")+\n  annotate(geom = \"text\", x = 39.5, y = -6.37, label = \"Unguja \\nIsland\")+\n  annotate(geom = \"text\", x = 39.3, y = -6.91, label = \"Dar es Salaam\")+\n  ggspatial::annotation_scale(height = unit(.35, \"cm\"), pad_x = unit(.5, \"cm\"),\n                              tick_height = unit(3, \"cm\"), pad_y = unit(.5, \"cm\"), text_cex = .85)+\n  ggspatial::annotation_north_arrow(location = \"tr\", width = unit(.75, \"cm\"), height = unit(1, \"cm\"))"
  },
  {
    "objectID": "maps.html#inset-maps",
    "href": "maps.html#inset-maps",
    "title": "8  Static Maps",
    "section": "8.6 Inset maps",
    "text": "8.6 Inset maps\nAn inset map is a smaller map rendered within or next to the main map. It could serve many different purposes, including showing the relative position of the study area in regional area. In figure @ref(fig:fig9011) is the map showing the contour interval off-kimbiji, Tanzania. The inset map show the area of Kimbiji in the Western Indian Ocean Region. The chunk below was used to create figure @ref(fig:fig911). In a nutshell, we assign the study area map as main.map and the regional map as inset.map and then we used function from the cowplot package to combine the two maps.\n\nmain.map = ggplot()+\n  geom_sf(data = kimbiji, fill = \"grey90\", col = \"grey40\")+\n  metR::geom_contour2(data = off.kimbiji, \n               aes(x = lon, y = lat, z=depth), binwidth = 50, col = \"grey\")+\n  metR::geom_contour2(data = off.kimbiji, \n               aes(x = lon, y = lat, z=depth), binwidth = 200)+\n  metR::geom_text_contour(data = off.kimbiji, \n               aes(x = lon, y = lat, z=depth), \n               binwidth = 200, rotate = FALSE)+\n  coord_sf(xlim = c(39.2, 39.8), ylim = c(-7, -6.3))+\n  theme_bw()+\n  theme(panel.background = element_rect(fill = \"white\"),\n        panel.grid = element_line(colour = NA),\n        axis.text = element_text(size = 11))+\n  scale_x_continuous(breaks = seq(39.2, 39.8, .2))+\n  scale_y_continuous(breaks = seq(-6.95, -6.35, length.out = 4))+\n  labs(x = NULL, y = NULL)+\n  annotate(geom = \"text\", x = 39.28, y = -6.48, label = \"Zanzibar \\nChannel\")+\n  annotate(geom = \"text\", x = 39.5, y = -6.37, label = \"Unguja \\nIsland\")+\n  annotate(geom = \"text\", x = 39.3, y = -6.91, label = \"Dar es Salaam\")+\n  ggspatial::annotation_scale(location = \"bl\")+\n  ggspatial::annotation_north_arrow(location = \"tr\")\n\nworld = spData::world\naoi = data.frame(lon = c(38.5, 40, 40, 38.5, 38.5), \n                 lat = c(-8, -8, -6, -6, -8))\n\ninset.map = ggplot()+\n  geom_sf(data = world, fill = \"grey90\", col = 1)+\n  coord_sf(xlim = c(37, 45), ylim = c(-12,-1))+\n  geom_path(data = aoi, aes(x = lon, y = lat), size = 1.2)+\n  theme_bw()+\n  theme(plot.background = element_blank(),\n        axis.text = element_blank(),\n        axis.ticks = element_blank(), panel.grid = element_line(colour = \"white\")) +\n  labs(x = NULL, y = NULL)\n\ncowplot::ggdraw()+\n  cowplot::draw_plot(plot = main.map, x = 0, y = 0, width = 1, height = 1, scale = 1)+\n  cowplot::draw_plot(plot = inset.map, x = .558, y = .05, width = .3,height = .3)\n\n\n\n\nFigure 8.1: The main map with the inset map showing the positon of the study areas in the region\n\n\n\n\n\nmain.map = ggplot()+\n  metR::geom_contour_fill(data = off.kimbiji, \n               aes(x = lon, y = lat, z=depth), na.fill = TRUE, show.legend = FALSE)+\n  metR::geom_contour_tanaka(data = off.kimbiji, \n               aes(x = lon, y = lat, z=depth))+\n  metR::geom_text_contour(data = off.kimbiji, \n               aes(x = lon, y = lat, z=depth), rotate = TRUE, check_overlap = TRUE, size = 3.4)+\n  geom_sf(data = kimbiji, fill = \"grey90\", col = \"grey40\")+\n  coord_sf(xlim = c(39.2, 39.8), ylim = c(-7, -6.3))+\n  theme_bw()+\n  theme(panel.background = element_rect(fill = \"white\"),\n        panel.grid = element_line(colour = NA),\n        axis.text = element_text(size = 11))+\n  scale_x_continuous(breaks = seq(39.2, 39.8, .2))+\n  scale_y_continuous(breaks = seq(-6.95, -6.35, length.out = 4))+\n  scale_fill_gradientn(colours = oce::oce.colorsGebco(120))+\n  labs(x = NULL, y = NULL)+\n  annotate(geom = \"text\", x = 39.28, y = -6.48, label = \"Zanzibar \\nChannel\")+\n  annotate(geom = \"text\", x = 39.5, y = -6.37, label = \"Unguja \\nIsland\")+\n  annotate(geom = \"text\", x = 39.3, y = -6.91, label = \"Dar es Salaam\")+\n  ggspatial::annotation_scale(location = \"bl\")+\n  ggspatial::annotation_north_arrow(location = \"tr\", width = unit(.75, \"cm\"))\n\nworld = spData::world\naoi = data.frame(lon = c(38.5, 40, 40, 38.5, 38.5), \n                 lat = c(-8, -8, -6, -6, -8))\n\ninset.map = ggplot()+\n  geom_sf(data = world, fill = \"grey90\", col = 1)+\n  coord_sf(xlim = c(37, 45), ylim = c(-12,-1))+\n  geom_path(data = aoi, aes(x = lon, y = lat), size = 1.2)+\n  theme_bw()+\n  theme(plot.background = element_blank(),\n        axis.text = element_blank(),\n        axis.ticks = element_blank(), panel.grid = element_line(colour = \"white\")) +\n  labs(x = NULL, y = NULL)\n\ncowplot::ggdraw()+\n  cowplot::draw_plot(plot = main.map, x = 0, y = 0, width = 1, height = 1, scale = 1)+\n  cowplot::draw_plot(plot = inset.map, x = .558, y = .05, width = .3,height = .3)\n\n\n\n\nFigure 8.2: The main map with the inset map showing the positon of the study areas in the region\n\n\n\n\n\n8.6.1 Choropleth maps\nChloropleth maps use color or shading on predefined areas to map values of a numeric or categorical variable in that area. For example we are interested to map the different coral reefs in Jibondo Island, Mafia, Tanzania. First we import the data into R using the st_read() function from sf package (Pebesma 2018)\n\njibondo.reefs = sf::st_read(dsn = \"assets/shp//jibondo_reefs.shp\",quiet = TRUE)\n\nThe jibondo.reefs file is simple feature (equivalent to shapefile) with sixteeen polygons in four groups—coastal-shallow areas, islands, reef flat and submerged reefs. We use the variable type to map the different coastal features in Jibondo. The code used to make (Figure 8.3) is written as:\n\nrequire(RColorBrewer)\n\nggplot()+\n  geom_sf(data = jibondo.reefs, aes(fill = type)) +\n  coord_sf(xlim = c(39.57, 39.88), ylim = c(-8.15,-7.88)) +\n  geom_sf_text(data = jibondo.reefs, aes(label = mwamba), check_overlap = TRUE) +\n  theme_bw() %+%\n  theme(axis.text = element_text(size = 11), legend.position = c(.8,.18)) +\n  scale_fill_brewer(palette = \"Accent\") +\n  metR::scale_x_longitude(ticks = 0.1) +\n  metR::scale_y_latitude(ticks = 0.08) +\n  guides(fill = guide_legend(title = \"Reef Type\",\n                             title.position =  \"top\",\n                             keywidth = 1.1,\n                             ncol = 1))\n\n\n\n\nFigure 8.3: Reefs and non-reeef features in Jibondo Island, Mafia\n\n\n\n\nThe variable used to make (Figure 8.4) is a categorical, but we can also map continuous variables. For this case, we want to map the catch per unit effort (CPUE) of octopus at each reef to identify octopus catches at different reefs as seen in figure\n\nggplot()+\n  geom_sf(data = jibondo.reefs, \n          aes(fill = cpue %>%round(2) %>% as.factor()))+\n  coord_sf(xlim = c(39.57, 39.88), ylim = c(-8.15,-7.88))+\n  geom_sf_text(data = jibondo.reefs, aes(label = mwamba), check_overlap = TRUE) +\n  theme_bw() %+%\n  theme(axis.text = element_text(size = 11), legend.position = c(.9,.25)) +\n  # scale_fill_brewer(palette = \"Accent\") +\n  ggsci::scale_fill_d3()+\n  metR::scale_x_longitude(ticks = 0.1) +\n  metR::scale_y_latitude(ticks = 0.08)+\n  guides(fill = guide_legend(title.position =  \"top\",\n                             keywidth = 1.1,\n                             ncol = 1, \n                             title = \"CPUE\"))\n\n\n\n\nFigure 8.4: Reefs and non-reeef features in Jibondo Island, Mafia\n\n\n\n\nFinally let’s map the the spatial patterns of sea surface temperature anomaly. We plot the departure of sea surface temperature from zonal average mean. Let’s import the dataset from the workspace. For more information on how to compute the zonal departure see chapter…\n\ntemperature.anomaly = read_csv(\"assets//shp/sst_anomaly.csv\")\n\n\n\n\n\n \n\nCoordinate (Degree)\n\n\n\n  \n    Latitude \n    Longitude \n    Depth \n    Anomaly \n  \n \n\n  \n    -50.5 \n    151.5 \n    0 \n    2.46 \n  \n  \n    5.5 \n    167.5 \n    0 \n    0.95 \n  \n  \n    15.5 \n    155.5 \n    0 \n    1.11 \n  \n  \n    -35.5 \n    -174.5 \n    0 \n    -0.10 \n  \n  \n    -5.5 \n    88.5 \n    0 \n    1.28 \n  \n  \n    30.5 \n    -23.5 \n    0 \n    -0.60 \n  \n  \n    -75.5 \n    -30.5 \n    0 \n    -0.13 \n  \n  \n    -0.5 \n    -113.5 \n    0 \n    -3.11 \n  \n  \n    25.5 \n    -151.5 \n    0 \n    -0.71 \n  \n  \n    70.5 \n    -167.5 \n    0 \n    -1.21 \n  \n\n\n\n\n\n\nggplot() +\n  metR::geom_contour_fill(data = temperature.anomaly,\n                          aes(x = lon, y = lat, z = anomaly), na.fill = T) +\n  geom_sf(data =  spData::world, col = NA, fill = \"grey40\")+\n  coord_sf(xlim = c(-180,178), ylim = c(-90,85), clip = \"on\", expand = FALSE)+\n  scale_fill_gradientn(colours = oce::oce.colors9A(120), breaks = seq(-6,6,2))+\n  theme_bw() +\n  theme(legend.position = \"right\", panel.background = element_blank(),\n        axis.text = element_text(size = 11, colour = \"black\"), \n        legend.text = element_text(size = 10),\n        legend.title = element_text(size = 11))+\n  guides(fill = guide_colorbar(title = expression(Temperature~anomaly~(degree*C)),\n                               title.position = \"right\", \n                               title.hjust = 0.5, \n                               title.theme = element_text(angle = 90),\n                               label.theme = element_text(size = 10),\n                               direction = \"vertical\",\n                               reverse = FALSE, raster = FALSE,\n                               barwidth = unit(.4, \"cm\"),\n                               barheight = unit(6.5, \"cm\")))+\n  metR::scale_y_latitude(ticks = 30) + \n  metR::scale_x_longitude(ticks = 45)+\n  labs(x = NULL, y = NULL)\n\n\n\n\nFigure 8.5: Departure of the sea surfae temprature at each location from the zonally averaged field\n\n\n\n\n\n\n\n\nAuguie, Baptiste. 2018. Egg: Extensions for ’Ggplot2’: Custom Geom, Plot Alignment, Symmetrised Scale, and Fixed Panel Size. https://CRAN.R-project.org/package=egg.\n\n\nCampitelli, Elio. 2019. metR: Tools for Easier Analysis of Meteorological Fields. https://CRAN.R-project.org/package=metR.\n\n\nPebesma, Edzer. 2018. Sf: Simple Features for r. https://CRAN.R-project.org/package=sf.\n\n\nPedersen, Thomas Lin, and David Robinson. 2017. Gganimate: A Grammar of Animated Graphics. http://github.com/thomasp85/gganimate.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. http://ggplot2.org.\n\n\nWilke, Claus O. 2018. Cowplot: Streamlined Plot Theme and Plot Annotations for ’Ggplot2’. https://CRAN.R-project.org/package=cowplot."
  },
  {
    "objectID": "mapsDynamic.html",
    "href": "mapsDynamic.html",
    "title": "9  Animated maps",
    "section": "",
    "text": "A web map is an interactive display of geographic information, in the form of a web page, that you can use to tell stories and answer questions. In the past, most digital geographic information was confined to specialized software on desktop PCs and could not be easily shared. With the advent of web mapping, geographical information can be shared, visualized, and edited in the browser. The most important advantage to this is accessibility: a web map, just like any website, can be reached by anyone from any device that has an internet browser and an internet connection.\nWeb maps are interactive. The term interactive implies that the viewer can interact with the map. This can mean selecting different map data layers or features to view, zooming into a particular part of the map that you are interested in, inspecting feature properties, editing existing content, or submitting new content, and so on.\nWeb maps are also said to be powered by the web, rather than just digital maps on the web. This means that the map is usually not self-contained; in other words, it depends on the internet. At least some of the content displayed on a web maps is usually loaded from other locations on the web, such as a tile server (Section 6.5.10.2).\nWeb maps are useful for various purposes, such as data visualization in journalism (and elsewhere), displaying real-time spatial data, powering spatial queries in online catalogs and search tools, providing computational tools, reporting, and collaborative mapping."
  },
  {
    "objectID": "mapsDynamic.html#what-is-leaflet",
    "href": "mapsDynamic.html#what-is-leaflet",
    "title": "9  Animated maps",
    "section": "9.2 What is Leaflet?",
    "text": "9.2 What is Leaflet?\nLeaflet is an open-source JavaScript library for building interactive web maps (Cheng, Karambelkar, and Xie 2018). Leaflet was initially released in 2011 (Table 6.1). It is lightweight, relatively simple, and flexible. Leaflet is probably the most popular open-source web-mapping library at the moment. As the Leaflet home page puts it, the guiding principle behind this library is simplicity:\n“Leaflet doesn’t try to do everything for everyone. Instead it focuses on making the basic things work perfectly.”\nAdvanced functionality is still available through Leaflet plugins. Towards the end of the book, we will learn about two Leaflet plugins: Leaflet.heat (Section 12.6) and Leaflet.draw (Section 13.3).\n\nrequire(tidyverse)\nrequire(leaflet)\nrequire(tmap)\nrequire(tidyterra)\n\ntmap_mode(mode = \"view\")\n\n\nraster.files = list.files(\"assets//raster/wc2.1_10m_tavg/\", pattern = \".tif\", full.names = TRUE)\n\n\nmonths = c(\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \n           \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\")\n\nclimatology.temperature = list()\n\nfor (i in 1:length(raster.files)){\n  \n  \n  climatology.temperature[[i]] = raster.files[i] %>% \n    raster::raster() %>%\n    # wior::raster_tb() %>%\n    raster::as.data.frame(xy = TRUE) %>%\n    rename(lon = 1, lat = 2, z = 3) %>% \n    mutate(month = months[i])\n}\n\nclimatology.temperature = climatology.temperature %>% \n  bind_rows() \n\n\n9.2.1 Creating a basic web map\nIn this section, we will learn to create a basic web map using Leaflet. The map is going to contain a single background (tile) layer, initially zoomed-in on the Ben-Gurion University. The final result is shown in Figure 6.5.\n\nrequire(leaflet)\n\n\n## read the file\njan.raster = raster.files[1] %>%\n  raster::raster()%>%\n  raster::projectRaster(crs = 4326)\n\n## create color pallet\npal = colorNumeric(c(\"#7f007f\", \"#0000ff\",  \"#007fff\", \"#00ffff\", \"#00bf00\", \"#7fdf00\",\n\"#ffff00\", \"#ff7f00\", \"#ff3f00\", \"#ff0000\", \"#bf0000\"), raster::values(jan.raster),  na.color = \"transparent\")\n\n\n## interactive map of temperature\nleaflet() %>%\n  addTiles() %>%\n  setView(lng = 5, lat = 20, zoom = 2) %>% \n  addRasterImage(x = jan.raster, colors = pal, opacity = .8)  %>%\n  addLegend(pal = pal, values = raster::values(jan.raster),\n    title = \"Temperature\")\n\n\n\n\n\nFigure 9.1: Interactive map showing a spatial variation of global land surface temperature for January\n\n\n\n\n## read the file\naug.raster = raster.files[8] %>%\n  raster::raster() %>%\n  raster::projectRaster(crs = 4326)\n\naug.raster[aug.raster< -15] = NA\n\n## create color pallet\npal = colorNumeric(c(\"#7f007f\", \"#0000ff\",  \"#007fff\", \"#00ffff\", \"#00bf00\", \"#7fdf00\",\n\"#ffff00\", \"#ff7f00\", \"#ff3f00\", \"#ff0000\", \"#bf0000\"), raster::values(aug.raster),  na.color = \"transparent\")\n\n\n## interactive map of temperature\nleaflet() %>%\n  addTiles() %>%  \n  setView(lng = 5, lat = 20, zoom = 2) %>% \n  addRasterImage(x = aug.raster, colors = pal, opacity = .6)  %>%\n  addLegend(pal = pal, values = raster::values(aug.raster),\n    title = \"Temperature\")\n\n\n\n\nFigure 9.2: Interactive map showing a spatial variation of global land surface temperature for August\n\n\n\n\nrast.temp = raster.files[1:12] %>% \n  terra::rast() %>% \n  rename(Jan = 1)%>% \n  rename(Feb = 2)%>% \n  rename(Mar = 3)%>% \n  rename(Apr = 4)%>% \n  rename(May = 5)%>% \n  rename(Jun = 6)%>% \n  rename(Jul = 7)%>% \n  rename(Aug = 8)%>% \n  rename(Sep = 9)%>% \n  rename(Oct = 10)%>% \n  rename(Nov = 11)%>% \n  rename(Dec = 12)\n\n\nggplot() +\n  geom_spatraster(data = rast.temp)+\n  facet_wrap(~lyr, nrow = 4)+\n  scale_fill_whitebox_c(\n    palette = \"muted\",\n    na.value = \"white\")+\n  scale_fill_gradientn(colours = oce::oce.colors9A(120))+\n  theme_minimal() +\n  theme(strip.background = element_blank())\n\n\n\n\nFigure 9.3: Climatology of temperature\n\n\n\n\n\nafrica = spData::world %>% filter(continent == \"Africa\") %>% terra::vect()\n\n\nafrica.temp = rast.temp %>% \n  terra::crop(africa) %>% \n  terra::mask(africa)\n\nggplot() +\n  geom_spatraster(data = africa.temp)+\n  metR::geom_contour2()+\n  facet_wrap(~lyr, nrow = 3)+\n  scale_fill_whitebox_c(\n    palette = \"muted\",\n    na.value = \"white\")+\n  scale_fill_gradientn(colours = oce::oce.colors9A(120))+\n  theme_minimal() +\n  theme(strip.background = element_blank())"
  },
  {
    "objectID": "mapsDynamic.html#for-web",
    "href": "mapsDynamic.html#for-web",
    "title": "9  Animated maps",
    "section": "9.3 for web",
    "text": "9.3 for web\n\nafrica = spData::world %>% filter(continent == \"Africa\") %>% terra::vect()\n\n# surface temperaature (degree)\ntemp.files = list.files(\"assets/raster/wc2.1_10m_tavg/\", pattern = \".tif\", full.names = TRUE)\n\nrast.temp = temp.files[1:12] %>% \n  terra::rast() %>% \n  rename(Jan = 1)%>% \n  rename(Feb = 2)%>% \n  rename(Mar = 3)%>% \n  rename(Apr = 4)%>% \n  rename(May = 5)%>% \n  rename(Jun = 6)%>% \n  rename(Jul = 7)%>% \n  rename(Aug = 8)%>% \n  rename(Sep = 9)%>% \n  rename(Oct = 10)%>% \n  rename(Nov = 11)%>% \n  rename(Dec = 12)\n\ntemperature = rast.temp %>% \n  terra::crop(africa) %>% \n  terra::mask(africa)\n\n# surface wind speed (m/s)\nwind.files = list.files(\"assets/raster/wc2.1_10m_wind/\", pattern = \".tif\", full.names = TRUE)\n\nrast.wind = temp.files[1:12] %>% \n  terra::rast() %>% \n  rename(Jan = 1)%>% \n  rename(Feb = 2)%>% \n  rename(Mar = 3)%>% \n  rename(Apr = 4)%>% \n  rename(May = 5)%>% \n  rename(Jun = 6)%>% \n  rename(Jul = 7)%>% \n  rename(Aug = 8)%>% \n  rename(Sep = 9)%>% \n  rename(Oct = 10)%>% \n  rename(Nov = 11)%>% \n  rename(Dec = 12)\n\nwind = rast.wind %>% \n  terra::crop(africa) %>% \n  terra::mask(africa)\n\n# water vapour (kPa)\ntemp.files = list.files(\"assets/raster/wc2.1_10m_vapr/\", pattern = \".tif\", full.names = TRUE)\n\nrast.water = temp.files[1:12] %>% \n  terra::rast() %>% \n  rename(Jan = 1)%>% \n  rename(Feb = 2)%>% \n  rename(Mar = 3)%>% \n  rename(Apr = 4)%>% \n  rename(May = 5)%>% \n  rename(Jun = 6)%>% \n  rename(Jul = 7)%>% \n  rename(Aug = 8)%>% \n  rename(Sep = 9)%>% \n  rename(Oct = 10)%>% \n  rename(Nov = 11)%>% \n  rename(Dec = 12)\n\nwatervapor = rast.water %>% \n  terra::crop(africa) %>% \n  terra::mask(africa)\n\n# solar radiations\ntemp.files = list.files(\"assets/raster/wc2.1_10m_srad/\", pattern = \".tif\", full.names = TRUE)\n\nrast.radiation = temp.files[1:12] %>% \n  terra::rast() %>% \n  rename(Jan = 1)%>% \n  rename(Feb = 2)%>% \n  rename(Mar = 3)%>% \n  rename(Apr = 4)%>% \n  rename(May = 5)%>% \n  rename(Jun = 6)%>% \n  rename(Jul = 7)%>% \n  rename(Aug = 8)%>% \n  rename(Sep = 9)%>% \n  rename(Oct = 10)%>% \n  rename(Nov = 11)%>% \n  rename(Dec = 12)\n\n\n\nradition = rast.radiation %>% \n  terra::crop(africa) %>% \n  terra::mask(africa)\n\n\ntemp.data = temperature %>% \n  select(data = Jul)\n\ntemp.tb = temp.data %>% \n  terra::as.data.frame(xy = TRUE)\n\n\ndata.stats = temp.tb %>%  \n  select(data) %>% \n    ggpubr::get_summary_stats(type = \"common\")\n\ntemp.tb %>% \n  sample_n(5000) %>% \n  ggplot(aes(x = data))+\n  geom_histogram(bins = 30, color = \"ivory\", fill = \"cyan4\", alpha = .4)+\n  geom_vline(xintercept = data.stats$median, color = \"red\", linetype = 2, lwd = 1.3)\n\n\n\ntm_shape(shp = temp.data)+\n  tm_raster(col = \"values\", style = \"fisher\", \n            palette = oce::oce.colorsJet(120), n = 60, \n            title = \"Temperature <br> Degree Celcius\",  \n            midpoint = data.stats$median, \n            legend.show = FALSE)\n\n\n9.3.1 What are tile layers?\n\n9.3.1.1 Overview\nTile layers are a fundamental technology behind web maps. They comprise the background layer in most web maps, thus helping the viewer to locate the foreground layers in geographical space. The word tile in tile layers comes from the fact that the layer is split into individual rectangular tiles. Tile layers come in two forms, which we are going to cover next: raster tiles (Section 6.5.10.2) and vector tiles (Section 6.5.10.3).\n\n\n9.3.1.2 Raster tiles\nThe oldest and simplest tile layer type is where tiles are raster images, also known as raster tiles. With raster tiles, tile layers are usually composed of PNG images. Traditionally, each PNG image is 256×256 pixels in size. A separate collection of tiles is required for each zoom level the map can be viewed on, with increasing numbers of tiles needed to cover a (global) extent in higher zoom levels. Conventionally, at each sequential zoom level, all of the tiles are divided into four “new” ones (Figure 6.2). For example, for covering the world at zoom level 0, we need just one tile. When we go to zoom level 1, that individual tile is split to 2×2=4 separate tiles. When we go further to zoom level 2, each of the four tiles is also split to four, so that we already have 4×4=16 separate tiles, and so on. In general, a global tile layer at zoom level z contains 2z×2z=4z tiles. At the default maximal zoom level in a Leaflet map (19), we need 274,877,906,944 tiles to cover the earth54!\n\n\n9.3.1.3 Vector tiles\nA more recent tile layer technology is where tiles are vector layers, rather than PNG images, referred to as vector tiles. Vector tiles are distinguished by the ability to rotate the map while the labels keep their horizontal orientation, and by the ability to zoom in or out smoothly—without the strict division to discrete zoom levels that raster tile layers have (Figure 6.2). Major advantages of vector tiles are their smaller size and flexible styling. For example, Google Maps made the transition from raster to vector tiles in 2013.\nThe Leaflet library does not natively support vector tiles, though there is a plugin called Leaflet.VectorGrid for that. Therefore, in this book we will restrict ourselves to using raster tiles as background layers. There are other libraries specifically built around vector tile layers, such as the Google Maps API and Mapbox GL JS, which we mentioned previously (Section 6.4). The example-06-01.html shows a web map with a vector tile layer built with Mapbox GL JS (Figure 6.4). This is the only non-Leaflet web-map example that we are going to see in the book; it is provided for demonstration and comparison of raster and vector tiles.\n\n\n9.3.1.4 Adding a tile layer\nWe now go back to discussing Leaflet and raster tile layers. Where can we get a tile layer from? There are many tile layers prepared and provided by several organizations, available on dedicated servers (Section 6.5.12) that you can add to your maps. Most of them are based on OpenStreetMap data (Section 13.2), because it is the most extensive free database of map data with global coverage. The tile layer we use in the following examples, and the one that the tile shown in Figure 6.3 comes from, is developed and maintained by OpenStreetMap itself. It is the default tile layer displayed on the https://www.openstreetmap.org/ website.\n\n\n\n\nCheng, Joe, Bhaskar Karambelkar, and Yihui Xie. 2018. Leaflet: Create Interactive Web Maps with the JavaScript ’Leaflet’ Library. https://CRAN.R-project.org/package=leaflet."
  }
]